{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a0c88f4",
   "metadata": {},
   "source": [
    "## **Chapter 12: Quantifying Uncertainty**\n",
    "\n",
    "---\n",
    "\n",
    "#### **12.1 Acting under Uncertainty**\n",
    "- **Overview**:\n",
    "  - Real-world agents face uncertainty due to partial observability, nondeterminism, and adversarial conditions.\n",
    "  - Traditional methods like belief-state tracking and contingency plans have limitations, such as excessive computational demands and difficulty managing unlikely scenarios.\n",
    "- **Challenges**:\n",
    "  - Agents must act even when no plan guarantees success.\n",
    "  - Rational decisions require weighing probabilities and utilities to maximize performance.\n",
    "- **Examples**:\n",
    "  - An automated taxi plan might weigh probabilities of delays and contingencies to maximize the likelihood of timely arrival.\n",
    "\n",
    "---\n",
    "\n",
    "#### **12.2 Basic Probability Notation**\n",
    "- **Introduction**:\n",
    "  - Probability theory quantifies degrees of belief in uncertain situations.\n",
    "  - It operates over a sample space representing all possible worlds.\n",
    "- **Key Concepts**:\n",
    "  - **Probability Model**: Assigns probabilities to worlds or events, ensuring they sum to 1.\n",
    "  - **Events and Propositions**: Correspond to sets of possible worlds, with probabilities defined as sums of these worlds.\n",
    "  - **Conditional Probability**: Expresses the probability of one event given another using the formula $ P(A | B) = \\frac{P(A \\land B)}{P(B)} $.\n",
    "- **Applications**:\n",
    "  - Used to represent prior and posterior probabilities for evidence-based decision-making.\n",
    "\n",
    "---\n",
    "\n",
    "#### **12.3 Inference Using Full Joint Distributions**\n",
    "- **Definition**:\n",
    "  - Full joint distributions provide probabilities for all combinations of variables in a domain.\n",
    "- **Challenges**:\n",
    "  - Computing probabilities from joint distributions is computationally expensive and scales poorly with domain size.\n",
    "- **Marginalization**:\n",
    "  - Summing out irrelevant variables simplifies computations but retains essential probabilities.\n",
    "- **Normalization**:\n",
    "  - Ensures probabilities add up to 1, critical for interpreting conditional probabilities.\n",
    "\n",
    "---\n",
    "\n",
    "#### **12.4 Independence**\n",
    "- **Concept**:\n",
    "  - Independence reduces complexity by separating variables whose probabilities do not depend on each other.\n",
    "  - **Absolute Independence**: Occurs when $ P(A \\land B) = P(A) \\cdot P(B) $.\n",
    "  - **Conditional Independence**: Variables become independent given a common cause or condition.\n",
    "- **Advantages**:\n",
    "  - Independence allows decomposition of complex joint distributions into smaller, manageable subsets.\n",
    "\n",
    "---\n",
    "\n",
    "#### **12.5 Bayes’ Rule and Its Use**\n",
    "- **Bayes’ Rule**:\n",
    "  - Allows computation of probabilities in one direction (e.g., effect → cause) given probabilities in the other (cause → effect).\n",
    "  - Formula: $ P(A | B) = \\frac{P(B | A) \\cdot P(A)}{P(B)} $.\n",
    "- **Applications**:\n",
    "  - Medical diagnosis: From symptoms (e.g., stiff neck) to diseases (e.g., meningitis).\n",
    "- **Combining Evidence**:\n",
    "  - Multiple pieces of evidence are integrated to refine probabilistic beliefs.\n",
    "\n",
    "---\n",
    "\n",
    "#### **12.6 Naive Bayes Models**\n",
    "- **Definition**:\n",
    "  - Simplifies probability calculations by assuming conditional independence of evidence variables given a cause.\n",
    "  - Used extensively in text classification, spam filtering, and medical diagnosis.\n",
    "- **Example**:\n",
    "  - Text classification assigns categories to documents based on word presence probabilities.\n",
    "- **Limitations**:\n",
    "  - Independence assumptions are often violated, leading to overconfidence in predictions.\n",
    "\n",
    "---\n",
    "\n",
    "#### **12.7 Revisiting the Wumpus World**\n",
    "- **Probabilistic Representation**:\n",
    "  - Probabilities describe uncertainties in the Wumpus World environment.\n",
    "  - Example: Estimating the likelihood of a pit in a given square based on perceptual evidence.\n",
    "- **Bayesian Inference**:\n",
    "  - Used to combine multiple pieces of evidence for decision-making in uncertain environments.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Takeaways**\n",
    "- Probabilistic reasoning provides a framework to handle uncertainty in AI systems.\n",
    "- Techniques like Bayes’ rule, independence, and naive Bayes models enable scalable reasoning.\n",
    "- Applications span diverse domains, including medical diagnosis, text classification, and robotics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdaf0d5-8060-4e5e-8f65-e0a86f9adc82",
   "metadata": {},
   "source": [
    "# summarize Section 12.1 of the provided document, I'll create a detailed table along with explanations of the key terms and concepts discussed. The table will cover important definitions, equations, and examples.\n",
    "\n",
    "### Table: Summary of Section 12.1 – Acting Under Uncertainty\n",
    "\n",
    "| **Term/Concept**                | **Definition/Explanation**                                                                                                              | **Key Equations**                                                                                                                                       | **Example**                                                                                                                                                           |\n",
    "|----------------------------------|------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Uncertainty**                  | Refers to situations where agents lack complete knowledge of the world, such as partial observability or nondeterminism.                | -                                                                                                                                                    | In the example of an automated taxi, the agent can't guarantee it will reach the airport on time due to uncertainties like accidents, road closures, etc.                |\n",
    "| **Belief State**                 | A representation of the set of possible world states an agent might be in, used to handle uncertainty.                                  | -                                                                                                                                                    | The taxi's belief state would include all possible states of traffic, accidents, and delays.                                                                            |\n",
    "| **Probabilistic Agent**          | An agent that reasons using probabilities, rather than deterministically, to handle uncertainty in its belief state.                    | $$P(\\text{Event}) = \\sum_{\\omega \\in \\Omega} P(\\omega)$$                                                                                             | Example: A dentist might have an 80% probability that a patient with a toothache has a cavity based on historical data.                                                 |\n",
    "| **Degree of Belief**             | The probability an agent assigns to a statement, indicating how confident the agent is about that statement.                           | $$P(\\text{Event})$$                                                                                                                                  | In diagnosing a toothache, an agent might assign a 0.8 probability to the belief that the patient has a cavity.                                                         |\n",
    "| **Performance Measure**          | A measure used to evaluate the success of an agent’s actions, taking into account goals like efficiency, safety, and resource use.       | $$\\text{Expected Utility} = \\sum_{i} P(\\text{outcome}_i) \\times U(\\text{outcome}_i)$$                                                                | For a taxi, the performance measure includes reaching the airport on time, minimizing wait time, and avoiding speeding tickets.                                         |\n",
    "| **Utility Theory**               | A theory that models an agent’s preferences among different outcomes by assigning a utility value to each state.                        | $$U(\\text{state})$$                                                                                                                                   | In a chess game, the utility might be high for a player if they checkmate the opponent, but low for the opponent.                                                       |\n",
    "| **Decision Theory**              | Combines probability and utility theory to make decisions based on maximizing expected utility.                                          | $$\\text{Decision Theory} = \\text{Probability Theory} + \\text{Utility Theory}$$                                                                       | A decision-theoretic agent would calculate the expected utility of different plans, such as leaving 90 minutes or 180 minutes before a flight.                          |\n",
    "| **Rational Decision**            | A decision where the agent chooses the option with the highest expected utility.                                                        | $$\\text{Expected Utility} = \\sum_{\\text{outcomes}} P(\\text{outcome}) \\times U(\\text{outcome})$$                                                       | The taxi agent might select the plan that maximizes the probability of getting to the airport on time while minimizing other costs, like wait time.                       |\n",
    "| **Contingency Plan**             | A plan that covers all possible eventualities based on an agent’s belief state.                                                         | -                                                                                                                                                    | The taxi agent might consider a contingency plan in case of a flat tire or accident, weighing the expected costs of delays.                                            |\n",
    "| **Knowledge State**              | The current state of knowledge about the world, which influences the agent’s probabilistic reasoning.                                   | -                                                                                                                                                    | In medical diagnosis, the knowledge state may include observations, such as a patient’s toothache and a history of gum disease, affecting the probability of a cavity. |\n",
    "\n",
    "### Example Explanation:  \n",
    "In the example of the automated taxi trying to reach the airport, the taxi agent must handle uncertainties, such as the possibility of the car breaking down, road closures, or accidents. The agent uses its belief state to evaluate different contingency plans (e.g., leaving 90 minutes vs. 180 minutes before the flight) based on probabilities and utility theory. While the taxi can't guarantee the outcome, it can choose the action expected to maximize the likelihood of success, such as reaching the airport on time with minimal delay.\n",
    "\n",
    "---\n",
    "\n",
    "#### Code Snippet Example (Python-like pseudocode for a decision-theoretic agent):\n",
    "```python\n",
    "def choose_action(belief_state, actions, utility_function):\n",
    "    expected_utilities = []\n",
    "    for action in actions:\n",
    "        expected_utility = 0\n",
    "        for outcome in get_possible_outcomes(action):\n",
    "            expected_utility += belief_state[outcome] * utility_function(outcome)\n",
    "        expected_utilities.append(expected_utility)\n",
    "    \n",
    "    # Select the action with the highest expected utility\n",
    "    best_action = actions[expected_utilities.index(max(expected_utilities))]\n",
    "    return best_action\n",
    "```\n",
    "This function evaluates each action based on the belief state and utility function, selecting the one with the highest expected utility.\n",
    "\n",
    "---\n",
    "\n",
    "This detailed summary table provides a structured overview of Section 12.1 on acting under uncertainty, breaking down the key concepts and providing an example scenario to illustrate the ideas in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9aec06e-22c2-4db4-a954-ea6a29d47a8a",
   "metadata": {},
   "source": [
    "# **Section 12.2 Basic Probability Notation** from your document, along with examples, equations, and explanations of key terms. Code snippets are included afterward.\n",
    "\n",
    "---\n",
    "\n",
    "### Table: Summary of Section 12.2 Basic Probability Notation\n",
    "\n",
    "| **Concept**         | **Definition**                                                                                           | **Equation**                                                                                       | **Example**                                                                                                                                                                 |\n",
    "|----------------------|---------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Sample Space (Ω)** | Set of all possible worlds, which are mutually exclusive and exhaustive.                                | $ \\sum_{\\omega \\in \\Omega} P(\\omega) = 1 $, where $ 0 \\leq P(\\omega) \\leq 1 $.                 | Rolling two dice: $ \\Omega = \\{(1,1), (1,2), ..., (6,6)\\} $, and $ P(\\omega) = 1/36 $ for fair dice.                                                                  |\n",
    "| **Event**            | A set of outcomes or propositions about possible worlds.                                               | $ P(\\phi) = \\sum_{\\omega \\in \\phi} P(\\omega) $.                                                 | Probability of rolling doubles: $ P(\\text{Doubles}) = P((1,1)) + P((2,2)) + \\dots + P((6,6)) $.                                                                         |\n",
    "| **Prior Probability**| Unconditional probability of an event.                                                                 | None                                                                                              | $ P(\\text{Toothache}) = 0.1 $, the likelihood of having a toothache without any additional information.                                                                |\n",
    "| **Conditional Probability** | Probability of one event given that another has occurred.                                        | $ P(a|b) = \\frac{P(a \\land b)}{P(b)} $, where $ P(b) > 0 $.                                    | If the first die shows 5, $ P(\\text{Doubles} | \\text{Die1}=5) = \\frac{P(\\text{Doubles} \\land \\text{Die1}=5)}{P(\\text{Die1}=5)} $.                                        |\n",
    "| **Product Rule**     | Relates joint probability to conditional probabilities.                                                 | $ P(a \\land b) = P(a|b)P(b) $.                                                                  | Joint probability of doubles and the first die showing 5: $ P(\\text{Doubles} \\land \\text{Die1}=5) = P(\\text{Doubles}|\\text{Die1}=5)P(\\text{Die1}=5) $.                   |\n",
    "| **Random Variables** | Variables mapping worlds to values.                                                                    | None                                                                                              | $ \\text{Weather} = \\{ \\text{sun, rain, cloud, snow} \\} $, with $ P(\\text{Weather}) = \\langle 0.6, 0.1, 0.29, 0.01 \\rangle $.                                           |\n",
    "| **Probability Distribution** | Assignment of probabilities to all possible values of a random variable.                        | $ P(X) = \\langle P(X=x_1), P(X=x_2), \\dots \\rangle $.                                           | $ P(\\text{Weather}) = \\langle 0.6, 0.1, 0.29, 0.01 \\rangle $, where the values correspond to \\{sun, rain, cloud, snow\\}.                                                |\n",
    "| **Joint Probability Distribution** | Probability distribution over multiple variables.                                          | $ P(X,Y) = P(X|Y)P(Y) $.                                                                        | $ P(\\text{Weather, Toothache}) $ is a table showing probabilities for all combinations of weather and the presence/absence of a toothache.                              |\n",
    "| **Marginalization**  | Summing out unobserved variables to find a probability over observed variables.                         | $ P(Y) = \\sum_z P(Y,Z=z) $.                                                                      | Probability of a toothache: $ P(\\text{Toothache}) = \\sum P(\\text{Toothache}, \\text{Cavity}) $.                                                                           |\n",
    "| **Normalization**    | Adjust probabilities to ensure they sum to 1.                                                          | $ P(Cavity|\\text{Toothache}) = \\alpha P(Cavity, \\text{Toothache}) $, where $ \\alpha = 1/P(\\text{Toothache}) $. | Normalize $ P(Cavity|\\text{Toothache}) = \\langle 0.12, 0.08 \\rangle $ to $ \\langle 0.6, 0.4 \\rangle $.                                                                |\n",
    "\n",
    "---\n",
    "\n",
    "### Explanation of Example\n",
    "\n",
    "#### Problem: Rolling Two Dice\n",
    "Suppose you want to calculate the probability that the sum of two dice equals 11.\n",
    "\n",
    "1. **Sample Space (Ω):** All combinations of two dice, $ 36 $ outcomes.\n",
    "2. **Event (Sum=11):** $ (5,6) $ and $ (6,5) $, so $ P(\\text{Sum=11}) = \\frac{1}{36} + \\frac{1}{36} = \\frac{1}{18} $.\n",
    "\n",
    "---\n",
    "\n",
    "### Code Snippets\n",
    "\n",
    "#### Example 1: Joint and Conditional Probabilities\n",
    "\n",
    "```python\n",
    "from itertools import product\n",
    "\n",
    "# Define sample space and probabilities for two dice\n",
    "sample_space = list(product(range(1, 7), repeat=2))\n",
    "probability = {outcome: 1/36 for outcome in sample_space}\n",
    "\n",
    "# Probability of doubles\n",
    "p_doubles = sum(prob for outcome, prob in probability.items() if outcome[0] == outcome[1])\n",
    "print(f\"Probability of doubles: {p_doubles}\")\n",
    "\n",
    "# Conditional probability of doubles given the first die is 5\n",
    "p_given_die1_5 = sum(prob for outcome, prob in probability.items() if outcome[0] == 5 and outcome[0] == outcome[1])\n",
    "p_die1_5 = sum(prob for outcome, prob in probability.items() if outcome[0] == 5)\n",
    "conditional_prob = p_given_die1_5 / p_die1_5 if p_die1_5 > 0 else 0\n",
    "print(f\"Conditional probability of doubles given the first die is 5: {conditional_prob}\")\n",
    "```\n",
    "\n",
    "#### Example 2: Marginalization and Normalization\n",
    "\n",
    "```python\n",
    "# Joint distribution for Cavity and Toothache\n",
    "joint_distribution = {\n",
    "    ('Cavity', 'Toothache'): 0.12,\n",
    "    ('Cavity', 'NoToothache'): 0.08,\n",
    "    ('NoCavity', 'Toothache'): 0.16,\n",
    "    ('NoCavity', 'NoToothache'): 0.64,\n",
    "}\n",
    "\n",
    "# Marginal probability for Toothache\n",
    "p_toothache = sum(prob for (cavity, toothache), prob in joint_distribution.items() if toothache == 'Toothache')\n",
    "print(f\"Marginal probability of Toothache: {p_toothache}\")\n",
    "\n",
    "# Normalize probabilities\n",
    "normalized = {k: v / p_toothache for k, v in joint_distribution.items() if k[1] == 'Toothache'}\n",
    "print(f\"Normalized probabilities for Toothache: {normalized}\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225d318b-fa79-412f-84f7-af9682ed157d",
   "metadata": {},
   "source": [
    "# **Section 12.3: Inference Using Full Joint Distributions**, formatted as a detailed table with code snippets and an example.\n",
    "\n",
    "---\n",
    "\n",
    "### Table: Summary of Section 12.3 Inference Using Full Joint Distributions\n",
    "\n",
    "| **Concept**           | **Definition**                                                                                                                                                 | **Equation**                                                                                                   | **Example**                                                                                                                      |\n",
    "|------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Full Joint Distribution** | A complete table specifying probabilities for all combinations of variable values in the domain.                                                             | $ P(X_1, X_2, ..., X_n) $                                                                                   | For $ \\text{Toothache}, \\text{Cavity}, \\text{Catch} $: joint table with probabilities summing to 1 (see example below).         |\n",
    "| **Marginalization**    | Summing probabilities over unobserved variables to find the probability of observed variables.                                                               | $ P(Y) = \\sum_{z} P(Y, Z = z) $                                                                             | Marginal probability $ P(\\text{Cavity}) = P(\\text{Cavity}, \\text{Toothache}) + P(\\text{Cavity}, \\neg \\text{Toothache}) $.      |\n",
    "| **Conditional Probability** | Probability of an event given evidence or prior knowledge.                                                                                                 | $ P(A|B) = \\frac{P(A \\land B)}{P(B)} $, where $ P(B) > 0 $.                                                | $ P(\\text{Cavity}|\\text{Toothache}) = \\frac{P(\\text{Cavity} \\land \\text{Toothache})}{P(\\text{Toothache})} $.                   |\n",
    "| **Normalization**      | Adjusting probabilities to ensure they sum to 1.                                                                                                              | $ P(X|E) = \\alpha P(X, E) $, where $ \\alpha = 1 / \\sum P(X, E) $.                                          | Normalize $ P(\\text{Cavity}|\\text{Toothache}) $: adjust relative probabilities $ 0.12, 0.08 $ to $ 0.6, 0.4 $.            |\n",
    "| **Query**              | A probabilistic question about one or more variables, given evidence.                                                                                        | $ P(X|e) = \\alpha \\sum_{y} P(X, e, y) $, where $ X $ is the query, $ e $ evidence, $ y $ unobserved.   | $ P(\\text{Cavity}|\\text{Toothache}) = \\alpha P(\\text{Cavity}, \\text{Toothache}) $.                                             |\n",
    "| **Scaling Challenges** | Full joint distribution scales poorly with many variables (requires $ O(2^n) $ space and computation for $ n $ Boolean variables).                        | None                                                                                                          | A joint distribution with 100 Boolean variables would require $ 2^{100} $ entries, impractical for real-world problems.       |\n",
    "\n",
    "---\n",
    "\n",
    "### Explanation of the Example\n",
    "#### Problem\n",
    "In a dentist's diagnosis, we have the following Boolean variables:\n",
    "1. **Toothache** ($ T $): Patient has a toothache.\n",
    "2. **Cavity** ($ C $): Patient has a cavity.\n",
    "3. **Catch** ($ K $): Dentist’s probe catches in the tooth.\n",
    "\n",
    "The **full joint distribution** is given in the following table:\n",
    "\n",
    "| $ C $   | $ T $          | $ K $          | Probability |\n",
    "|-----------|------------------|------------------|-------------|\n",
    "| $ \\text{True} $  | $ \\text{True} $  | $ \\text{True} $  | 0.108       |\n",
    "| $ \\text{True} $  | $ \\text{True} $  | $ \\text{False} $ | 0.012       |\n",
    "| $ \\text{True} $  | $ \\text{False} $ | $ \\text{True} $  | 0.072       |\n",
    "| $ \\text{True} $  | $ \\text{False} $ | $ \\text{False} $ | 0.008       |\n",
    "| $ \\text{False} $ | $ \\text{True} $  | $ \\text{True} $  | 0.016       |\n",
    "| $ \\text{False} $ | $ \\text{True} $  | $ \\text{False} $ | 0.064       |\n",
    "| $ \\text{False} $ | $ \\text{False} $ | $ \\text{True} $  | 0.144       |\n",
    "| $ \\text{False} $ | $ \\text{False} $ | $ \\text{False} $ | 0.576       |\n",
    "\n",
    "#### Questions:\n",
    "1. **Marginal Probability:** What is $ P(Cavity) $?\n",
    "2. **Conditional Probability:** What is $ P(Cavity|\\text{Toothache}) $?\n",
    "\n",
    "---\n",
    "\n",
    "### Solution\n",
    "\n",
    "#### Step 1: Marginal Probability $ P(Cavity) $\n",
    "\n",
    "Using marginalization:\n",
    "$$\n",
    "P(Cavity) = \\sum_{T,K} P(Cavity, T, K)\n",
    "$$\n",
    "\n",
    "From the table:\n",
    "$$\n",
    "P(Cavity) = 0.108 + 0.012 + 0.072 + 0.008 = 0.2\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### Step 2: Conditional Probability $ P(Cavity|\\text{Toothache}) $\n",
    "\n",
    "Using Bayes' Rule:\n",
    "$$\n",
    "P(Cavity|\\text{Toothache}) = \\frac{P(Cavity \\land \\text{Toothache})}{P(\\text{Toothache})}\n",
    "$$\n",
    "\n",
    "First, calculate $ P(Cavity \\land \\text{Toothache}) $:\n",
    "$$\n",
    "P(Cavity \\land \\text{Toothache}) = P(Cavity, \\text{Toothache}, \\text{Catch}) + P(Cavity, \\text{Toothache}, \\neg \\text{Catch})\n",
    "$$\n",
    "$$\n",
    "P(Cavity \\land \\text{Toothache}) = 0.108 + 0.012 = 0.12\n",
    "$$\n",
    "\n",
    "Next, calculate $ P(\\text{Toothache}) $:\n",
    "$$\n",
    "P(\\text{Toothache}) = \\sum_{C,K} P(C, \\text{Toothache}, K)\n",
    "$$\n",
    "$$\n",
    "P(\\text{Toothache}) = 0.108 + 0.012 + 0.016 + 0.064 = 0.2\n",
    "$$\n",
    "\n",
    "Now compute:\n",
    "$$\n",
    "P(Cavity|\\text{Toothache}) = \\frac{0.12}{0.2} = 0.6\n",
    "$$\n",
    "\n",
    "#### Interpretation\n",
    "- There’s a **60% chance** the patient has a cavity, given they have a toothache.\n",
    "\n",
    "---\n",
    "\n",
    "### Code Snippet\n",
    "\n",
    "```python\n",
    "# Define the full joint distribution\n",
    "joint_distribution = {\n",
    "    ('Cavity', 'Toothache', 'Catch'): 0.108,\n",
    "    ('Cavity', 'Toothache', 'NoCatch'): 0.012,\n",
    "    ('Cavity', 'NoToothache', 'Catch'): 0.072,\n",
    "    ('Cavity', 'NoToothache', 'NoCatch'): 0.008,\n",
    "    ('NoCavity', 'Toothache', 'Catch'): 0.016,\n",
    "    ('NoCavity', 'Toothache', 'NoCatch'): 0.064,\n",
    "    ('NoCavity', 'NoToothache', 'Catch'): 0.144,\n",
    "    ('NoCavity', 'NoToothache', 'NoCatch'): 0.576,\n",
    "}\n",
    "\n",
    "# Marginal probability of Cavity\n",
    "p_cavity = sum(prob for (c, t, k), prob in joint_distribution.items() if c == 'Cavity')\n",
    "print(f\"P(Cavity): {p_cavity}\")\n",
    "\n",
    "# Conditional probability P(Cavity | Toothache)\n",
    "p_toothache = sum(prob for (c, t, k), prob in joint_distribution.items() if t == 'Toothache')\n",
    "p_cavity_and_toothache = sum(prob for (c, t, k), prob in joint_distribution.items() if c == 'Cavity' and t == 'Toothache')\n",
    "p_cavity_given_toothache = p_cavity_and_toothache / p_toothache\n",
    "print(f\"P(Cavity | Toothache): {p_cavity_given_toothache}\")\n",
    "```\n",
    "\n",
    "This question and example illustrate how to calculate probabilities using full joint distributions, marginalization, and conditional probability rules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891591c9-d929-4206-baf0-4c40c3fc1471",
   "metadata": {},
   "source": [
    "# **Section 12.4: Independence**, formatted as a detailed table with explanations, examples, and code snippets.\n",
    "\n",
    "---\n",
    "\n",
    "### Table: Summary of Section 12.4 Independence\n",
    "\n",
    "| **Concept**             | **Definition**                                                                                                                                                                                                                  | **Equation**                                                                                             | **Example**                                                                                                                                                      |\n",
    "|--------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Independence**         | Two events $ A $ and $ B $ are independent if the occurrence of one does not affect the probability of the other.                                                                                                          | $ P(A \\land B) = P(A) \\cdot P(B) $                                                                     | Rolling two dice: $ P(\\text{Die1}=5 \\land \\text{Die2}=3) = P(\\text{Die1}=5) \\cdot P(\\text{Die2}=3) $.                                                         |\n",
    "| **Marginal Independence**| Variables are marginally independent if their probabilities are independent of each other.                                                                                                                                     | $ P(X, Y) = P(X) \\cdot P(Y) $                                                                          | Weather and Toothache: $ P(\\text{Weather}, \\text{Toothache}) = P(\\text{Weather}) \\cdot P(\\text{Toothache}) $ if they are unrelated.                           |\n",
    "| **Conditional Independence** | Two events $ A $ and $ B $ are conditionally independent given $ C $ if the probability of $ A $ and $ B $ together, conditioned on $ C $, equals the product of their individual probabilities conditioned on $ C $. | $ P(A, B | C) = P(A | C) \\cdot P(B | C) $                                                              | Toothache and Catch are conditionally independent given Cavity: $ P(\\text{Toothache}, \\text{Catch} | \\text{Cavity}) = P(\\text{Toothache}|\\text{Cavity})P(\\text{Catch}|\\text{Cavity}) $. |\n",
    "| **Decomposition**        | Independence assertions allow a full joint distribution to be factored into smaller distributions, reducing complexity.                                                                                                        | $ P(A, B, C) = P(A)P(B)P(C) $ for fully independent variables.                                         | Independent coin flips: $ P(\\text{Coin1}, \\text{Coin2}) = P(\\text{Coin1}) \\cdot P(\\text{Coin2}) $.                                                           |\n",
    "| **Separation**           | Conditional independence often arises because a variable $ Z $ separates $ A $ and $ B $ in a causal structure (e.g., $ Z $ is a common cause of both $ A $ and $ B $).                                              | $ P(A, B | Z) = P(A | Z)P(B | Z) $.                                                                    | Toothache and Catch are independent if the state of Cavity is known.                                                                                           |\n",
    "| **Scaling Impact**       | Independence reduces the size of the full joint distribution from $ 2^n $ (for $ n $ Boolean variables) to a smaller representation based on independent subsets.                                                           | None                                                                                                     | For 100 independent coin flips, we only need 100 probabilities rather than $ 2^{100} $ entries for a full joint distribution.                                 |\n",
    "\n",
    "---\n",
    "\n",
    "### Explanation of the Example\n",
    "\n",
    "#### Problem\n",
    "Imagine a dentist scenario with the following Boolean variables:\n",
    "1. **Toothache** ($ T $): Patient has a toothache.\n",
    "2. **Cavity** ($ C $): Patient has a cavity.\n",
    "3. **Catch** ($ K $): Dentist’s probe catches in the tooth.\n",
    "4. **Weather** ($ W $): Current weather (e.g., sunny, rainy).\n",
    "\n",
    "#### Independence Relationships\n",
    "- **Marginal Independence**: $ P(\\text{Weather}, \\text{Toothache}) = P(\\text{Weather}) \\cdot P(\\text{Toothache}) $ (Weather does not affect dental problems).\n",
    "- **Conditional Independence**: Given Cavity, $ \\text{Toothache} $ and $ \\text{Catch} $ are conditionally independent:\n",
    "  $$\n",
    "  P(\\text{Toothache}, \\text{Catch}|\\text{Cavity}) = P(\\text{Toothache}|\\text{Cavity}) \\cdot P(\\text{Catch}|\\text{Cavity})\n",
    "  $$\n",
    "\n",
    "#### Joint Distribution Decomposition\n",
    "Using independence:\n",
    "$$\n",
    "P(\\text{Toothache}, \\text{Catch}, \\text{Weather}) = P(\\text{Toothache}|\\text{Cavity}) \\cdot P(\\text{Catch}|\\text{Cavity}) \\cdot P(\\text{Cavity}) \\cdot P(\\text{Weather})\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Code Snippet\n",
    "\n",
    "#### Example 1: Testing Independence\n",
    "\n",
    "```python\n",
    "# Define probabilities\n",
    "P_Cavity = 0.2\n",
    "P_Toothache_given_Cavity = 0.6\n",
    "P_Catch_given_Cavity = 0.7\n",
    "P_Weather = 0.5  # Assume Sunny\n",
    "\n",
    "# Compute joint probability with independence\n",
    "P_Toothache_and_Catch_given_Cavity = P_Toothache_given_Cavity * P_Catch_given_Cavity\n",
    "P_Joint = P_Toothache_and_Catch_given_Cavity * P_Cavity * P_Weather\n",
    "\n",
    "print(f\"Joint Probability (Toothache, Catch, Weather): {P_Joint}\")\n",
    "```\n",
    "\n",
    "#### Example 2: Checking Conditional Independence\n",
    "\n",
    "```python\n",
    "# Conditional independence check\n",
    "def is_conditionally_independent(P_joint, P_a_given_c, P_b_given_c):\n",
    "    return abs(P_joint - (P_a_given_c * P_b_given_c)) < 1e-6\n",
    "\n",
    "# Example probabilities\n",
    "P_Toothache_given_Cavity = 0.6\n",
    "P_Catch_given_Cavity = 0.7\n",
    "P_Joint_given_Cavity = 0.42  # Observed joint probability\n",
    "\n",
    "# Check independence\n",
    "independent = is_conditionally_independent(P_Joint_given_Cavity, P_Toothache_given_Cavity, P_Catch_given_Cavity)\n",
    "print(f\"Are Toothache and Catch conditionally independent given Cavity? {independent}\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Summary of Insights\n",
    "- **Independence** simplifies the complexity of joint distributions by reducing the number of required probabilities.\n",
    "- **Conditional Independence** arises naturally in many domains, especially when a common variable (like a cause) explains the dependencies.\n",
    "- These simplifications allow probabilistic reasoning to scale effectively to larger systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054eec7f-21ec-46e3-a47d-6ba2de59dfef",
   "metadata": {},
   "source": [
    "# **Section 12.5: Bayes' Rule and Its Use**, formatted as a detailed table with definitions, equations, examples, and code snippets.\n",
    "\n",
    "---\n",
    "\n",
    "### Table: Summary of Section 12.5 Bayes’ Rule and Its Use\n",
    "\n",
    "| **Concept**             | **Definition**                                                                                                                                             | **Equation**                                                                                   | **Example**                                                                                                                             |\n",
    "|--------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Bayes’ Rule**          | A formula that allows the computation of $ P(\\text{Cause} \\mid \\text{Effect}) $ from $ P(\\text{Effect} \\mid \\text{Cause}) $, $ P(\\text{Cause}) $, and $ P(\\text{Effect}) $. | $ P(\\text{Cause} \\mid \\text{Effect}) = \\frac{P(\\text{Effect} \\mid \\text{Cause}) P(\\text{Cause})}{P(\\text{Effect})} $ | Probability of a disease given symptoms: $ P(\\text{Disease} \\mid \\text{Symptoms}) = \\frac{P(\\text{Symptoms} \\mid \\text{Disease}) P(\\text{Disease})}{P(\\text{Symptoms})} $. |\n",
    "| **Prior Probability**    | The probability of a cause before any evidence is observed.                                                                                              | $ P(\\text{Cause}) $                                                                          | $ P(\\text{Meningitis}) = \\frac{1}{50000} $.                                                                                          |\n",
    "| **Likelihood**           | The probability of observing evidence given the cause.                                                                                                   | $ P(\\text{Effect} \\mid \\text{Cause}) $                                                      | $ P(\\text{Stiff Neck} \\mid \\text{Meningitis}) = 0.7 $.                                                                               |\n",
    "| **Marginal Probability** | The total probability of observing the evidence across all causes.                                                                                       | $ P(\\text{Effect}) = \\sum P(\\text{Effect} \\mid \\text{Cause}) P(\\text{Cause}) $               | $ P(\\text{Stiff Neck}) = P(\\text{Stiff Neck} \\mid \\text{Meningitis}) P(\\text{Meningitis}) + P(\\text{Stiff Neck} \\mid \\neg \\text{Meningitis}) P(\\neg \\text{Meningitis}) $. |\n",
    "| **Posterior Probability**| The probability of a cause given observed evidence.                                                                                                      | $ P(\\text{Cause} \\mid \\text{Effect}) $                                                      | $ P(\\text{Meningitis} \\mid \\text{Stiff Neck}) = \\frac{0.7 \\cdot \\frac{1}{50000}}{0.01} \\approx 0.0014 $.                                                                  |\n",
    "| **Normalization**        | Ensures that the posterior probabilities sum to 1.                                                                                                       | $ P(\\text{Cause} \\mid \\text{Effect}) = \\alpha P(\\text{Effect} \\mid \\text{Cause}) P(\\text{Cause}) $, where $ \\alpha = \\frac{1}{P(\\text{Effect})} $. | Normalize posterior probabilities for $ P(\\text{Meningitis}) $ and $ P(\\neg \\text{Meningitis}) $.                                                                       |\n",
    "| **Use in Diagnostics**   | Allows reasoning from effects (evidence) to causes when only causal probabilities ($ P(\\text{Effect} \\mid \\text{Cause}) $) are available.               | None                                                                                           | $ P(\\text{Meningitis} \\mid \\text{Stiff Neck}) $ is computed using $ P(\\text{Stiff Neck} \\mid \\text{Meningitis}) $.                                                      |\n",
    "\n",
    "---\n",
    "\n",
    "### Explanation of the Example\n",
    "\n",
    "#### Problem: Medical Diagnosis\n",
    "A doctor is diagnosing meningitis ($ M $) based on the symptom of a stiff neck ($ S $).\n",
    "\n",
    "- **Prior Probability** ($ P(M) $): $ \\frac{1}{50000} $.\n",
    "- **Likelihood** ($ P(S \\mid M) $): $ 0.7 $.\n",
    "- **Marginal Probability** ($ P(S) $): \n",
    "  $$\n",
    "  P(S) = P(S \\mid M)P(M) + P(S \\mid \\neg M)P(\\neg M)\n",
    "  $$\n",
    "  Assuming $ P(S \\mid \\neg M) = 0.01 $, \n",
    "  $$\n",
    "  P(S) = (0.7 \\cdot \\frac{1}{50000}) + (0.01 \\cdot (1 - \\frac{1}{50000})) \\approx 0.01\n",
    "  $$\n",
    "\n",
    "#### Questions:\n",
    "1. What is $ P(M \\mid S) $ (probability of meningitis given a stiff neck)?\n",
    "2. Normalize the posterior probabilities for $ M $ and $ \\neg M $.\n",
    "\n",
    "---\n",
    "\n",
    "### Solution\n",
    "\n",
    "#### Step 1: Apply Bayes' Rule\n",
    "Using $ P(M \\mid S) = \\frac{P(S \\mid M)P(M)}{P(S)} $:\n",
    "$$\n",
    "P(M \\mid S) = \\frac{0.7 \\cdot \\frac{1}{50000}}{0.01} \\approx 0.0014\n",
    "$$\n",
    "\n",
    "#### Step 2: Posterior for $ \\neg M $\n",
    "$$\n",
    "P(\\neg M \\mid S) = 1 - P(M \\mid S) = 1 - 0.0014 = 0.9986\n",
    "$$\n",
    "\n",
    "#### Interpretation\n",
    "Even though stiff necks are strongly correlated with meningitis ($ P(S \\mid M) = 0.7 $), the low prior probability ($ P(M) = \\frac{1}{50000} $) results in a very low posterior probability ($ P(M \\mid S) = 0.0014 $).\n",
    "\n",
    "---\n",
    "\n",
    "### Code Snippet\n",
    "\n",
    "```python\n",
    "# Define probabilities\n",
    "P_M = 1 / 50000  # Prior for Meningitis\n",
    "P_not_M = 1 - P_M  # Prior for no Meningitis\n",
    "P_S_given_M = 0.7  # Likelihood\n",
    "P_S_given_not_M = 0.01  # Likelihood for no Meningitis\n",
    "\n",
    "# Marginal probability of Stiff Neck\n",
    "P_S = (P_S_given_M * P_M) + (P_S_given_not_M * P_not_M)\n",
    "\n",
    "# Posterior probabilities\n",
    "P_M_given_S = (P_S_given_M * P_M) / P_S\n",
    "P_not_M_given_S = (P_S_given_not_M * P_not_M) / P_S\n",
    "\n",
    "print(f\"P(Meningitis | Stiff Neck): {P_M_given_S:.4f}\")\n",
    "print(f\"P(No Meningitis | Stiff Neck): {P_not_M_given_S:.4f}\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Summary of Insights\n",
    "- **Bayes' Rule** enables reasoning from evidence to causes, a critical tool for diagnostic systems.\n",
    "- **Prior probabilities** heavily influence posterior probabilities, even when likelihoods are high.\n",
    "- Bayes' Rule is foundational for probabilistic reasoning and is widely used in fields like medicine, machine learning, and AI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df56af58-17a6-4175-b921-2faa2a0a6162",
   "metadata": {},
   "source": [
    "# **Section 12.6: Naive Bayes Models**, formatted as a table with definitions, equations, examples, and code snippets.\n",
    "\n",
    "---\n",
    "\n",
    "### Table: Summary of Section 12.6 Naive Bayes Models\n",
    "\n",
    "| **Concept**             | **Definition**                                                                                                                                                                                                                                       | **Equation**                                                                                                                 | **Example**                                                                                                                                                       |\n",
    "|--------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Naive Bayes Model**    | A probabilistic model assuming a single cause (random variable) directly influences multiple independent effects.                                                                                                                                  | $ P(Cause, Effects) = P(Cause) \\prod_{i} P(Effect_i \\mid Cause) $                                                          | In spam detection, the cause is \"email is spam,\" and the effects are the presence of specific words in the email.                                                |\n",
    "| **Simplifying Assumption** | Assumes conditional independence between effects given the cause, even if this is not strictly true in practice.                                                                                                                                  | $ P(E_1, E_2, ..., E_n \\mid C) = \\prod_{i} P(E_i \\mid C) $                                                                 | In medical diagnosis, symptoms (effects) are modeled as independent given a disease (cause).                                                                     |\n",
    "| **Posterior Probability**| The probability of a cause given observed evidence (effects).                                                                                                                                                                                     | $ P(C \\mid E) = \\alpha P(C) \\prod_{i} P(E_i \\mid C) $, where $ \\alpha = \\frac{1}{P(E)} $.                                 | For spam detection, compute $ P(\\text{Spam} \\mid \\text{Words}) $ based on $ P(\\text{Spam}) $ and $ P(\\text{Word}_i \\mid \\text{Spam}) $.                     |\n",
    "| **Text Classification**  | A common use case where the cause is a document’s category, and the effects are the presence or absence of specific words in the document.                                                                                                        | $ P(\\text{Category} \\mid \\text{Words}) = \\alpha P(\\text{Category}) \\prod_{i} P(\\text{Word}_i \\mid \\text{Category}) $        | Classify articles as business, weather, sports, etc., based on the frequency of words like \"stocks,\" \"rain,\" or \"goals.\"                                         |\n",
    "| **Training Naive Bayes** | Estimates the parameters $ P(\\text{Category}) $ and $ P(\\text{Word} \\mid \\text{Category}) $ from data.                                                                                                                                         | $ P(\\text{Word} \\mid \\text{Category}) = \\frac{\\text{Count of Word in Category Docs}}{\\text{Total Words in Category Docs}} $ | From training data, compute the probability of each word given its category.                                                                                     |\n",
    "| **Practical Advantages** | Despite independence assumptions often being violated, naive Bayes works well in practice due to its efficiency and robust performance.                                                                                                           | None                                                                                                                         | Used for spam filtering, sentiment analysis, and other classification tasks.                                                                                      |\n",
    "| **Normalization**        | Ensures probabilities sum to 1.                                                                                                                                                                                                                   | $ \\alpha = \\frac{1}{\\sum P(C) \\prod P(E_i \\mid C)} $                                                                        | Normalize posterior probabilities for all categories to sum to 1.                                                                                                |\n",
    "\n",
    "---\n",
    "\n",
    "### Explanation of the Example\n",
    "\n",
    "#### Problem: Text Classification\n",
    "We want to classify a sentence into categories like **Business** or **Weather** using the Naive Bayes model.\n",
    "\n",
    "- Sentence: \"Stocks rallied on Monday, gaining 1% as optimism grew.\"\n",
    "- Categories: $ \\text{Business}, \\text{Weather} $.\n",
    "- Word probabilities (trained from previous articles):\n",
    "  - $ P(\\text{Business}) = 0.6, P(\\text{Weather}) = 0.4 $.\n",
    "  - $ P(\\text{Word} \\mid \\text{Business}) $: $ P(\\text{Stocks} \\mid \\text{Business}) = 0.3, P(\\text{Rallied} \\mid \\text{Business}) = 0.2, P(\\text{Monday} \\mid \\text{Business}) = 0.1 $.\n",
    "  - $ P(\\text{Word} \\mid \\text{Weather}) $: $ P(\\text{Stocks} \\mid \\text{Weather}) = 0.05, P(\\text{Rallied} \\mid \\text{Weather}) = 0.01, P(\\text{Monday} \\mid \\text{Weather}) = 0.2 $.\n",
    "\n",
    "#### Questions:\n",
    "1. Compute the posterior probabilities for **Business** and **Weather** categories.\n",
    "2. Classify the sentence into one category.\n",
    "\n",
    "---\n",
    "\n",
    "### Solution\n",
    "\n",
    "#### Step 1: Compute Posterior for **Business**\n",
    "\n",
    "Using $ P(\\text{Category} \\mid \\text{Words}) = \\alpha P(\\text{Category}) \\prod P(\\text{Word}_i \\mid \\text{Category}) $:\n",
    "$$\n",
    "P(\\text{Business} \\mid \\text{Words}) = \\alpha P(\\text{Business}) P(\\text{Stocks} \\mid \\text{Business}) P(\\text{Rallied} \\mid \\text{Business}) P(\\text{Monday} \\mid \\text{Business})\n",
    "$$\n",
    "$$\n",
    "P(\\text{Business} \\mid \\text{Words}) = \\alpha (0.6)(0.3)(0.2)(0.1) = \\alpha 0.0036\n",
    "$$\n",
    "\n",
    "#### Step 2: Compute Posterior for **Weather**\n",
    "\n",
    "$$\n",
    "P(\\text{Weather} \\mid \\text{Words}) = \\alpha P(\\text{Weather}) P(\\text{Stocks} \\mid \\text{Weather}) P(\\text{Rallied} \\mid \\text{Weather}) P(\\text{Monday} \\mid \\text{Weather})\n",
    "$$\n",
    "$$\n",
    "P(\\text{Weather} \\mid \\text{Words}) = \\alpha (0.4)(0.05)(0.01)(0.2) = \\alpha 0.000004\n",
    "$$\n",
    "\n",
    "#### Step 3: Normalize and Classify\n",
    "\n",
    "The normalization factor $ \\alpha $ ensures probabilities sum to 1:\n",
    "$$\n",
    "P(\\text{Business} \\mid \\text{Words}) = \\frac{0.0036}{0.0036 + 0.000004} \\approx 0.999\n",
    "$$\n",
    "$$\n",
    "P(\\text{Weather} \\mid \\text{Words}) = \\frac{0.000004}{0.0036 + 0.000004} \\approx 0.001\n",
    "$$\n",
    "\n",
    "**Classification**: The sentence is classified as **Business** since $ P(\\text{Business} \\mid \\text{Words}) > P(\\text{Weather} \\mid \\text{Words}) $.\n",
    "\n",
    "---\n",
    "\n",
    "### Code Snippet\n",
    "\n",
    "```python\n",
    "# Define probabilities\n",
    "P_Category = {\"Business\": 0.6, \"Weather\": 0.4}\n",
    "P_Word_given_Category = {\n",
    "    \"Business\": {\"Stocks\": 0.3, \"Rallied\": 0.2, \"Monday\": 0.1},\n",
    "    \"Weather\": {\"Stocks\": 0.05, \"Rallied\": 0.01, \"Monday\": 0.2},\n",
    "}\n",
    "\n",
    "# Words in the sentence\n",
    "words = [\"Stocks\", \"Rallied\", \"Monday\"]\n",
    "\n",
    "# Compute posteriors\n",
    "posteriors = {}\n",
    "for category, prior in P_Category.items():\n",
    "    likelihood = prior\n",
    "    for word in words:\n",
    "        likelihood *= P_Word_given_Category[category].get(word, 1e-6)  # Small value for unseen words\n",
    "    posteriors[category] = likelihood\n",
    "\n",
    "# Normalize\n",
    "total = sum(posteriors.values())\n",
    "for category in posteriors:\n",
    "    posteriors[category] /= total\n",
    "\n",
    "# Classification\n",
    "classified_category = max(posteriors, key=posteriors.get)\n",
    "\n",
    "print(f\"Posterior Probabilities: {posteriors}\")\n",
    "print(f\"Classified as: {classified_category}\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Summary of Insights\n",
    "- **Naive Bayes** is efficient and effective for classification, even when its independence assumptions are not strictly true.\n",
    "- It is widely used in text classification, spam filtering, and medical diagnosis due to its simplicity.\n",
    "- Despite overconfidence in probabilities, it often ranks categories accurately, making it robust in practical applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92d2af2-9fca-42be-ac51-b510b43f4d98",
   "metadata": {},
   "source": [
    "# **Section 12.7: The Wumpus World Revisited**, formatted as a detailed table with definitions, equations, examples, and code snippets.\n",
    "\n",
    "---\n",
    "\n",
    "### Table: Summary of Section 12.7 The Wumpus World Revisited\n",
    "\n",
    "| **Concept**                  | **Definition**                                                                                                                                                                                                                   | **Equation**                                                                                                 | **Example**                                                                                                                                                                 |\n",
    "|-------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Wumpus World**              | A grid-based world where an agent uses probabilistic reasoning to decide safe moves despite uncertainty about pits, breezes, and the location of the Wumpus.                                                                   | None                                                                                                         | The agent must decide whether to move to a square, given that adjacent squares may contain pits or breezes.                                                               |\n",
    "| **Random Variables**          | Boolean variables representing the presence of pits ($ P_{ij} $), breezes ($ B_{ij} $), and the Wumpus ($ W_{ij} $) at grid locations $ [i,j] $.                                                                       | $ P(P_{ij}), P(B_{ij}), P(W_{ij}) $                                                                        | $ P_{11} $: true if a pit is in square $ [1,1] $; $ B_{12} $: true if square $ [1,2] $ is breezy.                                                                  |\n",
    "| **Evidence**                  | Observed variables, such as breezes, which provide indirect information about pits or the Wumpus.                                                                                                                             | None                                                                                                         | Observing $ B_{12} = \\text{True} $ suggests one or more pits in adjacent squares ($ [1,1], [1,3], [2,2] $).                                                           |\n",
    "| **Inference**                 | Uses probabilities to estimate the likelihood of pits or the Wumpus in specific squares, given the evidence.                                                                                                                  | $ P(P_{ij} \\mid B_{11}, B_{12}, ...) $                                                                     | Calculate the probability of a pit in $ [1,3] $ given breezes in adjacent squares.                                                                                      |\n",
    "| **Conditional Independence** | The assumption that breezes are independent of each other, given the state of pits in adjacent squares.                                                                                                                        | $ P(B_{ij} \\mid P_{ij}, P_{kl}, ...) = P(B_{ij} \\mid \\text{Adjacent Pits}) $                              | The breeze in $ [1,2] $ is independent of the breeze in $ [2,1] $, given the state of their shared pit-related variables.                                              |\n",
    "| **Joint Distribution**        | Combines probabilities of all variables, including pits and breezes, into a unified representation.                                                                                                                           | $ P(P_{ij}, B_{ij}, ...) = P(B_{ij} \\mid P_{ij}) P(P_{ij}) $                                               | A full joint distribution includes probabilities for all combinations of pits and breezes in all grid squares.                                                            |\n",
    "| **Scaling**                   | Probabilistic reasoning reduces the number of states considered compared to a purely logical approach.                                                                                                                         | None                                                                                                         | Instead of enumerating all possible pit configurations, probabilities focus on the most likely scenarios, based on observed breezes.                                     |\n",
    "\n",
    "---\n",
    "\n",
    "### Explanation of the Example\n",
    "\n",
    "#### Problem: Deciding Safe Squares\n",
    "The agent is in square $ [1,1] $ of a 4x4 grid. It detects breezes in $ [1,2] $ and $ [2,1] $. The goal is to determine the probability of pits in adjacent squares ($ [1,3] $, $ [2,2] $, $ [3,1] $).\n",
    "\n",
    "#### Assumptions\n",
    "1. Each square has a 20% chance of containing a pit.\n",
    "2. A breeze in a square indicates at least one adjacent square has a pit.\n",
    "3. Breezes are conditionally independent given the state of adjacent pits.\n",
    "\n",
    "---\n",
    "\n",
    "### Solution\n",
    "\n",
    "#### Step 1: Define Random Variables\n",
    "- $ P_{ij} $: True if there is a pit in square $ [i,j] $.\n",
    "- $ B_{ij} $: True if there is a breeze in square $ [i,j] $.\n",
    "\n",
    "#### Step 2: Evidence and Probabilities\n",
    "- Observations: $ B_{12} = \\text{True}, B_{21} = \\text{True} $.\n",
    "- Prior: $ P(P_{ij}) = 0.2 $ for all squares $ [i,j] $.\n",
    "\n",
    "#### Step 3: Compute $ P(P_{13} \\mid B_{12}, B_{21}) $\n",
    "Using Bayes’ Rule:\n",
    "$$\n",
    "P(P_{13} \\mid B_{12}, B_{21}) = \\alpha P(B_{12}, B_{21} \\mid P_{13}) P(P_{13})\n",
    "$$\n",
    "\n",
    "Expand $ P(B_{12}, B_{21} \\mid P_{13}) $ using independence:\n",
    "$$\n",
    "P(B_{12}, B_{21} \\mid P_{13}) = P(B_{12} \\mid P_{13}) P(B_{21} \\mid P_{13})\n",
    "$$\n",
    "\n",
    "Substitute the conditional probabilities:\n",
    "- $ P(B_{12} \\mid P_{13}) $: Probability $ [1,2] $ is breezy given a pit in $ [1,3] $.\n",
    "- $ P(B_{21} \\mid P_{13}) $: Probability $ [2,1] $ is breezy given a pit in $ [1,3] $.\n",
    "\n",
    "Normalize using all possible pit configurations to find $ P(P_{13} \\mid B_{12}, B_{21}) $.\n",
    "\n",
    "#### Step 4: Simplify with Independence\n",
    "Using conditional independence and prior probabilities of pits, focus only on squares adjacent to breezy squares.\n",
    "\n",
    "---\n",
    "\n",
    "### Code Snippet\n",
    "\n",
    "#### Example: Wumpus World Inference\n",
    "\n",
    "```python\n",
    "from itertools import product\n",
    "\n",
    "# Define prior probabilities\n",
    "P_pit = 0.2  # Probability of a pit in any square\n",
    "P_no_pit = 1 - P_pit  # Probability of no pit\n",
    "\n",
    "# Observed evidence: breezes in adjacent squares\n",
    "evidence = {\"B12\": True, \"B21\": True}\n",
    "\n",
    "# Possible pit configurations for adjacent squares\n",
    "adjacent_squares = [\"P13\", \"P22\", \"P31\"]\n",
    "configurations = list(product([True, False], repeat=len(adjacent_squares)))\n",
    "\n",
    "# Calculate probabilities\n",
    "posterior_probs = {}\n",
    "for config in configurations:\n",
    "    prob = 1.0\n",
    "    for square, has_pit in zip(adjacent_squares, config):\n",
    "        prob *= P_pit if has_pit else P_no_pit\n",
    "    # Update based on evidence (simplified here for independence assumption)\n",
    "    if evidence[\"B12\"] and any(config):  # If at least one pit causes B12\n",
    "        prob *= 1  # Simplified likelihood for breeze\n",
    "    else:\n",
    "        prob *= 0  # Impossible if no pit causes breeze\n",
    "    posterior_probs[config] = prob\n",
    "\n",
    "# Normalize probabilities\n",
    "total_prob = sum(posterior_probs.values())\n",
    "for config in posterior_probs:\n",
    "    posterior_probs[config] /= total_prob\n",
    "\n",
    "print(\"Posterior probabilities for pit configurations:\")\n",
    "for config, prob in posterior_probs.items():\n",
    "    print(f\"{config}: {prob:.4f}\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Summary of Insights\n",
    "- **Probabilistic reasoning** helps the agent handle uncertainty in the Wumpus World by estimating the likelihood of pits or the Wumpus.\n",
    "- **Bayes’ Rule** and **conditional independence** reduce the computational burden by focusing only on relevant variables and evidence.\n",
    "- This approach allows agents to make rational decisions, such as avoiding risky squares, even with incomplete information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d501f80-fe1d-43cf-ac6a-a05b3fc8327a",
   "metadata": {},
   "source": [
    "## **Chapter 13: Probabilistic Reasoning**\n",
    "\n",
    "---\n",
    "\n",
    "#### **13.1 Representing Knowledge in Bayesian Networks**\n",
    "- **Definition**:\n",
    "  - Bayesian networks are directed acyclic graphs (DAGs) representing probabilistic dependencies among variables.\n",
    "- **Structure**:\n",
    "  - Nodes represent random variables.\n",
    "  - Directed edges signify causal relationships.\n",
    "  - Each node is associated with a conditional probability distribution (CPD) that quantifies the effects of its parents.\n",
    "- **Advantages**:\n",
    "  - Provides a compact representation of joint probability distributions.\n",
    "  - Captures conditional independence among variables, simplifying reasoning.\n",
    "\n",
    "---\n",
    "\n",
    "#### **13.2 The Semantics of Bayesian Networks**\n",
    "- **Joint Distributions**:\n",
    "  - A Bayesian network defines a joint probability distribution as the product of the conditional probabilities for each variable.\n",
    "- **Causal Modeling**:\n",
    "  - Encodes causal relationships, enabling prediction of the effects of interventions.\n",
    "  - Example: Adjusting the sprinkler to observe its effect on grass wetness.\n",
    "- **Hybrid Models**:\n",
    "  - Combine discrete and continuous variables using specialized distributions for modeling.\n",
    "\n",
    "---\n",
    "\n",
    "#### **13.3 Inference in Bayesian Networks**\n",
    "- **Exact Inference**:\n",
    "  - Algorithms like **variable elimination** and **belief propagation** compute exact probabilities in networks.\n",
    "  - Efficient for simple tree-like structures (polytrees) but computationally expensive for complex graphs.\n",
    "- **Approximate Inference**:\n",
    "  - Methods like **sampling** (e.g., Markov Chain Monte Carlo) estimate probabilities in large networks.\n",
    "- **Applications**:\n",
    "  - Diagnosis, prediction, and decision-making under uncertainty.\n",
    "\n",
    "---\n",
    "\n",
    "#### **13.4 Causality and Decision Networks**\n",
    "- **Causal Reasoning**:\n",
    "  - Uses Bayesian networks to infer causation rather than correlation.\n",
    "  - **Intervention Analysis**:\n",
    "    - Predicts outcomes when variables are deliberately altered (e.g., turning on a sprinkler).\n",
    "- **Decision Networks**:\n",
    "  - Extend Bayesian networks by incorporating decision and utility nodes to support decision-making.\n",
    "\n",
    "---\n",
    "\n",
    "#### **13.5 Applications of Probabilistic Reasoning**\n",
    "- **Domains**:\n",
    "  - Healthcare (e.g., diagnostic systems), economics, and autonomous systems.\n",
    "- **Complex Scenarios**:\n",
    "  - Bayesian reasoning handles uncertainty in scenarios like car insurance modeling or medical treatment planning.\n",
    "\n",
    "---\n",
    "\n",
    "#### **13.6 Summary**\n",
    "- **Key Points**:\n",
    "  - Bayesian networks efficiently represent and reason about uncertainty.\n",
    "  - Exact and approximate inference methods balance computational cost and accuracy.\n",
    "  - The integration of causality enhances decision-making capabilities.\n",
    "\n",
    "This chapter establishes Bayesian networks as a foundational tool for probabilistic reasoning, offering a framework to model, infer, and act under uncertainty. Let me know if you'd like additional elaboration on any subsection!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e90b28d-ae13-4467-85d2-aede601459e4",
   "metadata": {},
   "source": [
    "Here is a detailed table summarizing Section 13.1 from your document on Bayesian Networks. Below the table, I've included a Python code snippet related to Bayesian Networks and an explanation of its example.\n",
    "\n",
    "### Summary Table: Bayesian Networks\n",
    "\n",
    "| **Feature**                   | **Description**                                                                                     | **Key Equations**                                                                                                             | **Examples**                                                                                                     |\n",
    "|-------------------------------|-----------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------|\n",
    "| **Bayesian Network (Bayes Net)** | A data structure representing dependencies among variables using a Directed Acyclic Graph (DAG).   | - **Full Joint Distribution**: $ P(X_1, X_2, \\ldots, X_n) = \\prod_{i=1}^n P(X_i | \\text{Parents}(X_i)) $                   | Nodes: Toothache, Cavity, Weather. Links: Cavity -> Toothache, Cavity -> Catch.                                 |\n",
    "| **Node**                      | Represents a random variable, which can be discrete or continuous.                                | No direct equation.                                                                                                        | In a network for medical diagnosis, nodes might represent \"Fever\" or \"Headache\".                                |\n",
    "| **Directed Links (Arrows)**   | Show dependencies: A link from $ X $ to $ Y $ indicates $ X $ is a parent of $ Y $.         | No direct equation.                                                                                                        | In burglary detection: Burglary -> Alarm, Earthquake -> Alarm.                                                 |\n",
    "| **Conditional Probability Table (CPT)** | Quantifies the effect of parent nodes on a child node.                                          | **Conditional Probability**: $ P(X_i | \\text{Parents}(X_i)) $                                                             | For $ Alarm $: $ P(A = \\text{true} | B = \\text{true}, E = \\text{false}) = 0.94 $.                            |\n",
    "| **Independence**              | Simplifies probability representation: variables are independent unless linked.                    | $ P(X, Y) = P(X)P(Y) $, if $ X $ and $ Y $ are independent.                                                          | $ Weather $ is independent of $ Cavity, Toothache, $ and $ Catch $.                                       |\n",
    "| **Conditional Independence**  | If $ Cavity $ exists, $ Toothache $ and $ Catch $ are independent given $ Cavity $.        | $ P(T, C | Cavity) = P(T | Cavity)P(C | Cavity) $                                                                        | In medical diagnosis: Fever and Cough are conditionally independent given the Flu.                              |\n",
    "| **Compact Representation**    | Captures the joint distribution with fewer parameters using dependencies.                         | **Compact CPT**: A Boolean variable with $ k $ parents needs $ 2^k $ probabilities instead of $ 2^n $.               | With $ n = 30 $ nodes, 960 parameters are needed instead of a billion for a joint distribution.               |\n",
    "| **Topology**                  | Graph structure specifies relationships between variables.                                         | Topological Order: Nodes are ordered so causes precede effects.                                                            | $ B $, $ E $, $ A $, $ J $, $ M $ (Burglary, Earthquake, Alarm, JohnCalls, MaryCalls).                 |\n",
    "\n",
    "### Code Example\n",
    "\n",
    "```python\n",
    "from pgmpy.models import BayesianNetwork\n",
    "from pgmpy.factors.discrete import TabularCPD\n",
    "\n",
    "# Define the structure of the Bayesian Network\n",
    "model = BayesianNetwork([('Burglary', 'Alarm'), \n",
    "                         ('Earthquake', 'Alarm'), \n",
    "                         ('Alarm', 'JohnCalls'), \n",
    "                         ('Alarm', 'MaryCalls')])\n",
    "\n",
    "# Define the Conditional Probability Tables (CPTs)\n",
    "cpd_burglary = TabularCPD(variable='Burglary', variable_card=2, values=[[0.999], [0.001]])\n",
    "cpd_earthquake = TabularCPD(variable='Earthquake', variable_card=2, values=[[0.998], [0.002]])\n",
    "cpd_alarm = TabularCPD(variable='Alarm', variable_card=2,\n",
    "                       values=[[0.999, 0.06, 0.71, 0.001], \n",
    "                               [0.001, 0.94, 0.29, 0.999]],\n",
    "                       evidence=['Burglary', 'Earthquake'], \n",
    "                       evidence_card=[2, 2])\n",
    "cpd_johncalls = TabularCPD(variable='JohnCalls', variable_card=2,\n",
    "                           values=[[0.9, 0.05], \n",
    "                                   [0.1, 0.95]],\n",
    "                           evidence=['Alarm'], \n",
    "                           evidence_card=[2])\n",
    "cpd_marycalls = TabularCPD(variable='MaryCalls', variable_card=2,\n",
    "                           values=[[0.7, 0.01], \n",
    "                                   [0.3, 0.99]],\n",
    "                           evidence=['Alarm'], \n",
    "                           evidence_card=[2])\n",
    "\n",
    "# Add CPTs to the model\n",
    "model.add_cpds(cpd_burglary, cpd_earthquake, cpd_alarm, cpd_johncalls, cpd_marycalls)\n",
    "\n",
    "# Validate the model\n",
    "print(\"Is model valid? \", model.check_model())\n",
    "```\n",
    "\n",
    "### Explanation of the Example\n",
    "This Python script uses the `pgmpy` library to construct a Bayesian network. The structure represents a home burglary detection system. Nodes represent variables like \"Burglary,\" \"Earthquake,\" and \"Alarm,\" while links depict causal relationships. Conditional Probability Tables (CPTs) quantify these relationships. For instance, the `Alarm` node depends on both `Burglary` and `Earthquake`. The code initializes the structure, assigns probabilities, and checks the model's validity. This example captures the concepts described in Section 13.1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92001373-4f12-4fe7-bff3-70077528295e",
   "metadata": {},
   "source": [
    "# 13.2\n",
    "\n",
    "### Summary Table: Semantics of Bayesian Networks\n",
    "\n",
    "| **Feature**                   | **Description**                                                                                     | **Key Equations**                                                                                                             | **Examples**                                                                                                     |\n",
    "|-------------------------------|-----------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------|\n",
    "| **Bayesian Network Semantics**| Each entry in the joint distribution is defined as the product of local conditional distributions. | $$ P(x_1, x_2, \\ldots, x_n) = \\prod_{i=1}^n P(x_i \\mid \\text{Parents}(X_i)) $$                                  | A burglary alarm system: $$ P(j, m, a, \\neg b, \\neg e) = P(j \\mid a)P(m \\mid a)P(a \\mid \\neg b, \\neg e)P(\\neg b)P(\\neg e) $$ |\n",
    "| **Parents(X)**                | The direct influencers (parent nodes) of a variable $ X $.                                       | $$ P(X_i \\mid \\text{Parents}(X_i)) = \\frac{P(X_i, \\text{Parents}(X_i))}{P(\\text{Parents}(X_i))} $$              | For $ Alarm $: $$ P(A=true \\mid Burglary, Earthquake) = \\frac{P(A, Burglary, Earthquake)}{P(Burglary, Earthquake)} $$  |\n",
    "| **Markov Blanket**            | A variable is independent of others, given its parents, children, and children’s parents.          | No explicit equation; Markov blanket is a subset of the graph                                               | $ Burglary $ independent of $ JohnCalls, MaryCalls $ given $ Alarm, Earthquake $.                          |\n",
    "| **Compact Representation**    | Reduces the full joint distribution size using conditional independence relationships.             | Bayesian Network CPT requires $$ 2^k \\cdot n $$ parameters vs. $$ 2^n $$ for full joint distribution         | $$ n=30, k=5 $$: Bayes Net requires 960 values vs. $$ >1 $$ billion for joint distribution.                       |\n",
    "| **Chain Rule vs. Bayes Net**  | Bayesian networks encode joint distributions using topological order of nodes.                    | $$ P(X_i \\mid X_1, \\ldots, X_{i-1}) = P(X_i \\mid \\text{Parents}(X_i)) $$                                          | Topology: $ B, E, A, J, M $ (Burglary, Earthquake, Alarm, John, Mary).                                         |\n",
    "\n",
    "### Python Code Example\n",
    "\n",
    "```python\n",
    "from pgmpy.models import BayesianNetwork\n",
    "from pgmpy.factors.discrete import TabularCPD\n",
    "\n",
    "# Define the Bayesian Network structure\n",
    "model = BayesianNetwork([('Burglary', 'Alarm'), \n",
    "                         ('Earthquake', 'Alarm'), \n",
    "                         ('Alarm', 'JohnCalls'), \n",
    "                         ('Alarm', 'MaryCalls')])\n",
    "\n",
    "# Define the CPTs\n",
    "cpd_burglary = TabularCPD('Burglary', 2, [[0.999], [0.001]])\n",
    "cpd_earthquake = TabularCPD('Earthquake', 2, [[0.998], [0.002]])\n",
    "cpd_alarm = TabularCPD('Alarm', 2, \n",
    "                       [[0.999, 0.06, 0.71, 0.001],\n",
    "                        [0.001, 0.94, 0.29, 0.999]],\n",
    "                       evidence=['Burglary', 'Earthquake'], evidence_card=[2, 2])\n",
    "cpd_johncalls = TabularCPD('JohnCalls', 2,\n",
    "                           [[0.9, 0.05],\n",
    "                            [0.1, 0.95]],\n",
    "                           evidence=['Alarm'], evidence_card=[2])\n",
    "cpd_marycalls = TabularCPD('MaryCalls', 2,\n",
    "                           [[0.7, 0.01],\n",
    "                            [0.3, 0.99]],\n",
    "                           evidence=['Alarm'], evidence_card=[2])\n",
    "\n",
    "# Add the CPTs to the model\n",
    "model.add_cpds(cpd_burglary, cpd_earthquake, cpd_alarm, cpd_johncalls, cpd_marycalls)\n",
    "\n",
    "# Validate the model\n",
    "print(\"Model valid?\", model.check_model())\n",
    "```\n",
    "\n",
    "### Explanation of the Example\n",
    "This Python code demonstrates how to construct a Bayesian Network for a home burglary alarm system. The network encodes dependencies between variables such as burglary, earthquake, alarm, and calls from John or Mary. The Conditional Probability Tables (CPTs) capture the relationships between variables. For example, the `Alarm` depends on both `Burglary` and `Earthquake`. The model's validity ensures that the Bayes Net accurately represents the underlying joint probability distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8964e4a-3781-4839-bef1-c63ce4389586",
   "metadata": {},
   "source": [
    "# Section 13.3, \"Exact Inference in Bayesian Networks,\" followed by a Python code example and its explanation:\n",
    "\n",
    "### Summary Table: Exact Inference in Bayesian Networks\n",
    "\n",
    "| **Feature**                   | **Description**                                                                                     | **Key Equations**                                                                                                             | **Examples**                                                                                                     |\n",
    "|-------------------------------|-----------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------|\n",
    "| **Exact Inference**            | The computation of the posterior probability distribution for query variables given evidence.       | $$ P(X \\mid e) = \\alpha P(X, e) = \\alpha \\sum_y P(X, e, y) $$                                                                 | Query: $$ P(Burglary \\mid JohnCalls = \\text{true}, MaryCalls = \\text{true}) = \\langle 0.284, 0.716 \\rangle $$ |\n",
    "| **Inference by Enumeration**   | Summing terms from the full joint distribution to compute conditional probabilities.               | $$ P(X \\mid e) = \\alpha \\sum_y P(X, e, y) $$                                                                                 | Hidden variables for query $$ P(B \\mid j, m) $$: $$ Earthquake, Alarm $$ |\n",
    "| **Variable Elimination**       | A more efficient method than enumeration by summing out variables systematically.                 | No explicit equation in section; focuses on reducing redundant computations.                                                | Query: $$ P(Alarm = \\text{true}) $$: Intermediate results simplify the process.                                  |\n",
    "| **Message Passing**            | Distributes computation across nodes in the Bayesian Network.                                     | No explicit equation; often uses local probability tables to reduce overhead.                                               | Example: Messages sent along edges in the Burglary network.                                        |\n",
    "| **Complexity of Exact Inference** | Depends on the structure of the Bayes net; can be computationally expensive.                     | General case: $$ O(2^n) $$ for inference on n variables; efficient algorithms reduce this for sparse graphs.                | Tree-structured Bayes nets allow linear time inference.                                           |\n",
    "\n",
    "### Python Code Example\n",
    "\n",
    "```python\n",
    "from pgmpy.models import BayesianNetwork\n",
    "from pgmpy.inference import VariableElimination\n",
    "\n",
    "# Define the Bayesian Network structure\n",
    "model = BayesianNetwork([('Burglary', 'Alarm'),\n",
    "                         ('Earthquake', 'Alarm'),\n",
    "                         ('Alarm', 'JohnCalls'),\n",
    "                         ('Alarm', 'MaryCalls')])\n",
    "\n",
    "# Add CPTs (assume CPTs are defined as in previous examples)\n",
    "model.add_cpds(cpd_burglary, cpd_earthquake, cpd_alarm, cpd_johncalls, cpd_marycalls)\n",
    "\n",
    "# Perform exact inference using Variable Elimination\n",
    "infer = VariableElimination(model)\n",
    "\n",
    "# Query: Probability of Burglary given evidence\n",
    "query_result = infer.query(variables=['Burglary'], evidence={'JohnCalls': 1, 'MaryCalls': 1})\n",
    "print(query_result)\n",
    "```\n",
    "\n",
    "### Explanation of the Example\n",
    "The code demonstrates the use of Variable Elimination for exact inference in a Bayesian Network. The example focuses on querying the probability of \"Burglary\" given that both John and Mary have called. The `VariableElimination` algorithm is implemented via the `pgmpy` library, which simplifies the process by managing evidence and hidden variables efficiently. The result shows the posterior probability distribution for \"Burglary,\" helping to make decisions based on observed evidence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093a7d00-2663-4c0d-a462-e768adb6e869",
   "metadata": {},
   "source": [
    "### **Chapter 14: Probabilistic Reasoning Over Time**\n",
    "\n",
    "#### **14.1 Time and Uncertainty**\n",
    "- **Overview**:\n",
    "  - In dynamic systems, reasoning must account for changes over time using temporal models.\n",
    "  - Random variables represent the system state at different time steps.\n",
    "  - **Transition Models**: Describe how the state evolves over time.\n",
    "  - **Sensor Models**: Define how observations relate to the current state.\n",
    "- **Markov Assumption**:\n",
    "  - Future states depend only on the current state, not on past states, simplifying reasoning.\n",
    "- **Applications**:\n",
    "  - Examples include tracking a robot’s location, monitoring economic trends, and diagnosing dynamic medical conditions.\n",
    "\n",
    "---\n",
    "\n",
    "#### **14.2 Inference Tasks in Temporal Models**\n",
    "- **Filtering**:\n",
    "  - Estimates the current state based on past observations.\n",
    "  - Uses a recursive process to update beliefs as new data arrives.\n",
    "- **Prediction**:\n",
    "  - Projects future states based on current information.\n",
    "- **Smoothing**:\n",
    "  - Computes probabilities for past states using both prior and future observations.\n",
    "- **Most Likely Explanation**:\n",
    "  - Determines the sequence of states that best explains observed data.\n",
    "\n",
    "---\n",
    "\n",
    "#### **14.3 Hidden Markov Models (HMMs)**\n",
    "- **Structure**:\n",
    "  - HMMs consist of hidden states, observed variables, and transition/sensor probabilities.\n",
    "- **Algorithms**:\n",
    "  - **Forward Algorithm**: Computes the likelihood of observations up to a point.\n",
    "  - **Backward Algorithm**: Computes probabilities of future observations given the current state.\n",
    "  - **Forward-Backward Algorithm**: Combines forward and backward steps for smoothing.\n",
    "\n",
    "---\n",
    "\n",
    "#### **14.4 Kalman Filters**\n",
    "- **Definition**:\n",
    "  - Specialized for linear systems with Gaussian noise.\n",
    "  - Efficiently estimates system states by integrating sensor data over time.\n",
    "- **Process**:\n",
    "  - Prediction: Estimates the next state based on a dynamic model.\n",
    "  - Correction: Updates state estimates with new sensor data.\n",
    "- **Applications**:\n",
    "  - Widely used in robotics, navigation, and signal processing.\n",
    "\n",
    "---\n",
    "\n",
    "#### **14.5 Dynamic Bayesian Networks (DBNs)**\n",
    "- **Extension of Bayesian Networks**:\n",
    "  - Represent temporal dependencies compactly by linking variables across time steps.\n",
    "- **Inference**:\n",
    "  - Combines principles from HMMs and Bayesian networks for more complex systems.\n",
    "- **Flexibility**:\n",
    "  - Handles both discrete and continuous variables.\n",
    "\n",
    "---\n",
    "\n",
    "#### **14.6 Particle Filters**\n",
    "- **Overview**:\n",
    "  - Approximation method for inference in systems with nonlinear dynamics or non-Gaussian noise.\n",
    "  - Represents the probability distribution using a set of weighted samples (particles).\n",
    "- **Process**:\n",
    "  - Prediction: Propagates particles through the transition model.\n",
    "  - Resampling: Adjusts particle weights based on sensor observations.\n",
    "- **Advantages**:\n",
    "  - Effective for high-dimensional or complex systems.\n",
    "- **Challenges**:\n",
    "  - Computationally expensive and sensitive to particle diversity.\n",
    "\n",
    "---\n",
    "\n",
    "#### **14.7 Rao-Blackwellized Particle Filters**\n",
    "- **Hybrid Approach**:\n",
    "  - Combines exact inference for some variables with sampling for others.\n",
    "  - Useful in systems with conditional independence properties.\n",
    "- **Example**:\n",
    "  - Simultaneous Localization and Mapping (SLAM) for robots.\n",
    "\n",
    "---\n",
    "\n",
    "#### **14.8 Summary**\n",
    "- **Key Points**:\n",
    "  - Temporal models provide tools to reason about dynamic systems.\n",
    "  - Different techniques—HMMs, Kalman filters, DBNs, and particle filters—address specific challenges.\n",
    "  - Applications span robotics, economics, and medical diagnostics.\n",
    "- **Takeaways**:\n",
    "  - Models rely on assumptions like the Markov property and time-homogeneity for simplicity.\n",
    "  - Inference methods balance computational efficiency and accuracy.\n",
    "\n",
    "Let me know if you’d like further clarification on any subsection!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6013e653-760a-46e5-89d4-8e794f37f3fc",
   "metadata": {},
   "source": [
    "# **14.1 Concepts** \n",
    "\n",
    "| **Concept**                  | **Definition**                                                                                                                                                                                                                             | **Equation**                                                                                                                                                                                                                | **Example**                                                                                                                                                                                                             |\n",
    "|------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Time Slice**               | A discrete snapshot of the world at a specific time, used in modeling dynamic systems. Each time slice contains state variables and evidence variables.                                                                                    | $ X_t $: state variables at time $ t $ <br> $ E_t $: evidence variables at time $ t $                                                                                                                                | Monitoring rain using umbrella sightings: $ X_t = R_t $ (rain state) and $ E_t = U_t $ (umbrella observation).                                                                                                     |\n",
    "| **Markov Assumption**        | Assumes that the current state depends only on a fixed number of prior states, reducing the need to consider all past states.                                                                                                              | First-order Markov process: $ P(X_t \\mid X_{0:t-1}) = P(X_t \\mid X_{t-1}) $                                                                                                                                                | Tracking rain probabilities: $ P(R_t \\mid R_{t-1}) $, where only the previous day's rain affects the current prediction.                                                                                              |\n",
    "| **Transition Model**         | Defines the probability of moving to a particular state at time $ t $, given the state at time $ t-1 $.                                                                                                                                 | $ P(X_t \\mid X_{t-1}) $                                                                                                                                                                                                   | Probability of rain persisting: $ P(R_t = \\text{True} \\mid R_{t-1} = \\text{True}) = 0.7 $.                                                                                                                           |\n",
    "| **Sensor Model**             | Specifies the likelihood of evidence at time $ t $, given the state at time $ t $.                                                                                                                                                     | $ P(E_t \\mid X_t) $                                                                                                                                                                                                      | Umbrella observation: $ P(U_t = \\text{True} \\mid R_t = \\text{True}) = 0.9 $.                                                                                                                                          |\n",
    "| **Time-Homogeneous Process** | Assumes that the transition probabilities do not change over time, simplifying model specification.                                                                                                                                        | $ P(X_t \\mid X_{t-1}) = P(X_{t+1} \\mid X_t) $                                                                                                                                                                            | Uniform rain probabilities across days.                                                                                                                                                                                 |\n",
    "| **Initial State Distribution**| Describes the probabilities of states at the start of the timeline ($ t = 0 $).                                                                                                                                                         | $ P(X_0) $: prior probability distribution                                                                                                                                                                               | Initial rain probability: $ P(R_0 = \\text{True}) = 0.5 $.                                                                                                                                                            |\n",
    "| **Joint Distribution**       | Combines transition and sensor models over all time steps to describe the complete system behavior.                                                                                                                                        | $ P(X_{0:t}, E_{1:t}) = P(X_0) \\prod_{i=1}^t P(X_i \\mid X_{i-1}) P(E_i \\mid X_i) $                                                                                                                                        | Full probabilistic representation of rain and umbrella observations over several days.                                                                                                                                  |\n",
    "\n",
    "---\n",
    "\n",
    "### Example Explanation\n",
    "\n",
    "**Umbrella Example:**\n",
    "\n",
    "- **Goal:** Track whether it is raining based on whether a person carries an umbrella.\n",
    "- **State Variables:** $ R_t $ (True if it rains on day $ t $).\n",
    "- **Evidence Variables:** $ U_t $ (True if the umbrella is observed on day $ t $).\n",
    "- **Transition Model:** Rain depends on whether it rained the previous day ($ P(R_t \\mid R_{t-1}) $).\n",
    "- **Sensor Model:** Probability of seeing an umbrella if it rains ($ P(U_t \\mid R_t) $).\n",
    "\n",
    "This example uses probabilities and Bayesian networks to update beliefs about the weather state over time.\n",
    "\n",
    "### Code Snippet for Umbrella Example (Simplified):\n",
    "\n",
    "```python\n",
    "# Transition probabilities\n",
    "P_rain = {\n",
    "    True: {True: 0.7, False: 0.3},\n",
    "    False: {True: 0.3, False: 0.7}\n",
    "}\n",
    "\n",
    "# Sensor probabilities\n",
    "P_umbrella = {\n",
    "    True: {True: 0.9, False: 0.1},\n",
    "    False: {True: 0.2, False: 0.8}\n",
    "}\n",
    "\n",
    "# Initial belief\n",
    "belief = {True: 0.5, False: 0.5}\n",
    "\n",
    "# Evidence update (umbrella observed)\n",
    "def update_belief(belief, umbrella):\n",
    "    updated = {}\n",
    "    for rain in [True, False]:\n",
    "        updated[rain] = P_umbrella[rain][umbrella] * sum(\n",
    "            P_rain[prev_rain][rain] * belief[prev_rain] for prev_rain in [True, False]\n",
    "        )\n",
    "    # Normalize\n",
    "    total = sum(updated.values())\n",
    "    return {k: v / total for k, v in updated.items()}\n",
    "\n",
    "# Example update\n",
    "umbrella_observed = True\n",
    "new_belief = update_belief(belief, umbrella_observed)\n",
    "print(new_belief)\n",
    "```\n",
    "\n",
    "**Explanation of Code:**\n",
    "\n",
    "- **Transition Model (`P_rain`):** Encodes the probabilities of transitioning between rain states from one day to the next.\n",
    "    - For example, $ P(R_t = \\text{True} \\mid R_{t-1} = \\text{True}) = 0.7 $.\n",
    "- **Sensor Model (`P_umbrella`):** Encodes the probabilities of observing an umbrella given whether it is raining.\n",
    "    - For example, $ P(U_t = \\text{True} \\mid R_t = \\text{True}) = 0.9 $.\n",
    "- **Belief Update Function (`update_belief`):**\n",
    "    - **Predict Step:** Calculates the predicted belief state by considering all possible transitions from the previous state.\n",
    "    - **Update Step:** Updates the belief state based on the new evidence (whether the umbrella is observed).\n",
    "    - **Normalization:** Ensures that the updated beliefs sum to 1.\n",
    "- **Usage Example:**\n",
    "    - Observes that the umbrella is present (`umbrella_observed = True`).\n",
    "    - Calls `update_belief` to update the belief state based on this observation.\n",
    "    - Prints the new belief state, showing updated probabilities for it raining or not raining.\n",
    "\n",
    "This code models a single belief update in the umbrella example, demonstrating how new evidence influences belief states using the transition and sensor models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20541282-a9d3-4d9f-a1e4-313b6868e02a",
   "metadata": {},
   "source": [
    "### Table: Summary of Section 14.2 - Inference in Temporal Models\n",
    "\n",
    "| **Concept**               | **Definition**                                                                                                                                                                                                                          | **Equation**                                                                                                                                                                                                                          | **Example**                                                                                                                                                                                                                              |\n",
    "|---------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Filtering (State Estimation)** | Computing the belief state $ P(X_t \\mid e_{1:t}) $, the posterior distribution of the most recent state given all evidence to date.                                                                                               | $ P(X_t \\mid e_{1:t}) = \\alpha P(e_t \\mid X_t) \\sum_{x_{t-1}} P(X_t \\mid X_{t-1}) P(X_{t-1} \\mid e_{1:t-1}) $                                                                                   | Estimating whether it is raining today based on umbrella observations up to today.                                                                                                                                                      |\n",
    "| **Prediction**            | Computing the probability distribution of a future state $ X_{t+k} $, given all evidence up to the present ($ e_{1:t} $).                                                                                                           | $ P(X_{t+k} \\mid e_{1:t}) = \\sum_{x_t} P(X_{t+k} \\mid X_t) P(X_t \\mid e_{1:t}) $                                                                                                             | Predicting rain three days from now based on umbrella observations so far.                                                                                                                                                              |\n",
    "| **Smoothing**             | Computing the posterior distribution of a past state $ P(X_k \\mid e_{1:t}) $ for $ 0 \\leq k < t $.                                                                                                                                | $ P(X_k \\mid e_{1:t}) = \\alpha P(X_k \\mid e_{1:k}) P(e_{k+1:t} \\mid X_k) $, where $ P(e_{k+1:t} \\mid X_k) = \\sum_{x_{k+1}} P(e_{k+1} \\mid X_{k+1}) P(X_{k+1} \\mid X_k) \\cdots $                | Estimating the weather two days ago using all umbrella observations up to today.                                                                                                                                                        |\n",
    "| **Most Likely Sequence (Viterbi Algorithm)** | Finding the sequence of states $ x_{1:t} $ that is most likely to have generated the observations $ e_{1:t} $.                                                                                                            | $ m_{1:t+1} = P(e_{t+1} \\mid X_{t+1}) \\max_{x_t} P(X_{t+1} \\mid X_t) m_{1:t} $, where $ m_{1:t} $ is the message representing the most likely path reaching state $ X_t $.                                                       | Identifying the sequence of sunny or rainy days that explains a series of umbrella observations.                                                                                                                                       |\n",
    "| **Forward-Backward Algorithm** | Combines forward filtering and backward smoothing to compute posterior probabilities over a sequence of states given a sequence of observations.                                                                                       | Forward: $ f_{1:t+1} = \\alpha P(e_{t+1} \\mid X_{t+1}) \\sum_{x_t} P(X_{t+1} \\mid X_t) f_{1:t} $ <br> Backward: $ b_{k+1:t} = \\sum_{x_{k+1}} P(e_{k+1} \\mid X_{k+1}) P(X_{k+1} \\mid X_k) b_{k+2:t} $ | Computing the smoothed probability of rain on a specific day using umbrella observations before and after that day.                                                                                                                     |\n",
    "| **Learning**              | Learning the transition and sensor models from data, using algorithms like Expectation-Maximization (EM) or Bayesian updating of model parameters.                                                                                      | Transition model: $ P(X_t \\mid X_{t-1}) $, Sensor model: $ P(e_t \\mid X_t) $.                                                                                                                                                       | Estimating transition probabilities of rain based on historical weather patterns and umbrella sightings.                                                                                                                               |\n",
    "\n",
    "---\n",
    "\n",
    "### Example Explanation\n",
    "\n",
    "#### Example: Rain and Umbrella Filtering for Two Days\n",
    "\n",
    "We will use a Bayesian network to estimate whether it rained on two consecutive days based on umbrella observations. Assume:\n",
    "\n",
    "1. **Initial State Distribution:** $ P(R_0 = \\text{True}) = 0.5 $, $ P(R_0 = \\text{False}) = 0.5 $.\n",
    "2. **Transition Model:**\n",
    "   - $ P(R_t = \\text{True} \\mid R_{t-1} = \\text{True}) = 0.7 $,\n",
    "   - $ P(R_t = \\text{False} \\mid R_{t-1} = \\text{True}) = 0.3 $,\n",
    "   - $ P(R_t = \\text{True} \\mid R_{t-1} = \\text{False}) = 0.3 $,\n",
    "   - $ P(R_t = \\text{False} \\mid R_{t-1} = \\text{False}) = 0.7 $.\n",
    "3. **Sensor Model:**\n",
    "   - $ P(U_t = \\text{True} \\mid R_t = \\text{True}) = 0.9 $,\n",
    "   - $ P(U_t = \\text{True} \\mid R_t = \\text{False}) = 0.2 $.\n",
    "\n",
    "**Observations:** $ U_1 = \\text{True} $, $ U_2 = \\text{True} $.\n",
    "\n",
    "---\n",
    "\n",
    "### Code Snippet for Filtering\n",
    "\n",
    "```python\n",
    "# Define models\n",
    "P_rain = {\n",
    "    True: {True: 0.7, False: 0.3},\n",
    "    False: {True: 0.3, False: 0.7}\n",
    "}\n",
    "\n",
    "P_umbrella = {\n",
    "    True: {True: 0.9, False: 0.1},\n",
    "    False: {True: 0.2, False: 0.8}\n",
    "}\n",
    "\n",
    "# Initial belief\n",
    "belief = {True: 0.5, False: 0.5}\n",
    "\n",
    "def forward_update(belief, umbrella_obs):\n",
    "    updated = {}\n",
    "    for rain in [True, False]:\n",
    "        updated[rain] = P_umbrella[rain][umbrella_obs] * sum(\n",
    "            P_rain[prev_rain][rain] * belief[prev_rain] for prev_rain in [True, False]\n",
    "        )\n",
    "    total = sum(updated.values())\n",
    "    return {k: v / total for k, v in updated.items()}\n",
    "\n",
    "# Forward filtering for two days\n",
    "day1_observed = True\n",
    "day2_observed = True\n",
    "\n",
    "belief_day1 = forward_update(belief, day1_observed)\n",
    "belief_day2 = forward_update(belief_day1, day2_observed)\n",
    "\n",
    "print(f\"Belief after Day 1: {belief_day1}\")\n",
    "print(f\"Belief after Day 2: {belief_day2}\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Example Results\n",
    "\n",
    "1. **After Day 1:**\n",
    "   - $ P(R_1 = \\text{True} \\mid U_1 = \\text{True}) \\approx 0.818 $,\n",
    "   - $ P(R_1 = \\text{False} \\mid U_1 = \\text{True}) \\approx 0.182 $.\n",
    "\n",
    "2. **After Day 2:**\n",
    "   - $ P(R_2 = \\text{True} \\mid U_1 = \\text{True}, U_2 = \\text{True}) \\approx 0.883 $,\n",
    "   - $ P(R_2 = \\text{False} \\mid U_1 = \\text{True}, U_2 = \\text{True}) \\approx 0.117 $.\n",
    "\n",
    "---\n",
    "\n",
    "This worked example demonstrates how filtering updates beliefs iteratively using transition and sensor models, aligning with the equations provided in the table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a6b8b7-d93f-4c25-a8e2-0c41bf2456dd",
   "metadata": {},
   "source": [
    "### Table: Summary of Section 14.3 - Hidden Markov Models (HMMs)\n",
    "\n",
    "| **Concept**               | **Definition**                                                                                                                                                                                                                             | **Equation**                                                                                                                                                                                                                           | **Example**                                                                                                                                                                                                                               |\n",
    "|---------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Hidden Markov Model (HMM)** | A temporal probabilistic model where the state is described by a single discrete random variable $ X_t $, and the evidence variables $ E_t $ are observations influenced by the state.                                                     | $ P(X_t \\mid X_{t-1}) $: Transition Model <br> $ P(E_t \\mid X_t) $: Sensor Model                                                                                                                                                   | Tracking a robot's position in a maze based on noisy sensor data.                                                                                                                                                                       |\n",
    "| **Transition Model**      | Specifies the probability of transitioning from one state to another in consecutive time steps.                                                                                                                                             | $ T_{ij} = P(X_t = j \\mid X_{t-1} = i) $, where $ T $ is an $ S \\times S $ matrix (state transition matrix).                                                                                                                      | Robot moves randomly in a maze: $ T_{ij} = 1/N(i) $ for valid neighboring states $ j $, and 0 otherwise.                                                                                                                             |\n",
    "| **Sensor Model (Observation Model)** | Defines the likelihood of observing a piece of evidence $ E_t = e_t $ given the current state $ X_t $.                                                                                                                           | $ O_{ii} = P(E_t = e_t \\mid X_t = i) $, where $ O $ is a diagonal matrix with probabilities on the diagonal.                                                                                                                       | Sensor readings for a robot’s proximity detector depend on the robot’s position in the maze.                                                                                                                                             |\n",
    "| **Filtering**             | Computes the belief state $ P(X_t \\mid E_{1:t}) $, the probability of the current state given all observations up to time $ t $.                                                                                                        | $ f_{1:t+1} = \\alpha O_{t+1} T^\\top f_{1:t} $                                                                                                                                                                                        | Determining the robot's current position given noisy sensor observations.                                                                                                                                                                |\n",
    "| **Smoothing**             | Computes the posterior distribution of a past state $ P(X_k \\mid E_{1:t}) $ for $ 0 \\leq k < t $, using forward and backward passes.                                                                                                    | $ P(X_k \\mid E_{1:t}) \\propto f_{1:k} b_{k+1:t} $, where $ f_{1:k} $ is the forward message and $ b_{k+1:t} $ is the backward message.                                                                                            | Finding the robot's position at $ t-3 $ using observations made until $ t $.                                                                                                                                                          |\n",
    "| **Most Likely Sequence (Viterbi Algorithm)** | Finds the most probable sequence of states that could have generated the observations $ E_{1:t} $.                                                                                                                               | $ m_{1:t+1} = P(E_{t+1} \\mid X_{t+1}) \\max_{x_t} P(X_{t+1} \\mid X_t) m_{1:t} $                                                                                                                                                        | Determining the robot’s most likely path in a maze given noisy sensor observations.                                                                                                                                                       |\n",
    "| **Matrix Representation** | HMM computations can be expressed in terms of matrices for efficient implementation.                                                                                                                                                        | Transition Model: $ T_{ij} = P(X_t = j \\mid X_{t-1} = i) $ <br> Sensor Model: $ O_{ii} = P(E_t = e_t \\mid X_t = i) $.                                                                                                               | Representing robot movements and sensor errors using matrix operations for filtering and smoothing.                                                                                                                                      |\n",
    "| **Limitations of HMMs**   | HMMs are limited in modeling complex processes because they assume a single discrete state variable and do not capture dependencies between state variables.                                                                                   | $ P(X_t, E_{1:t}) = \\prod_{t=1}^T P(E_t \\mid X_t) P(X_t \\mid X_{t-1}) $.                                                                                                                                                              | Modeling a maze with many state variables (e.g., position and battery level) can lead to an unmanageable number of state transitions.                                                                                                   |\n",
    "\n",
    "---\n",
    "\n",
    "### Example Explanation\n",
    "\n",
    "#### Example: Robot Localization in a Maze\n",
    "\n",
    "**Scenario:**\n",
    "A robot is moving in a 5x5 maze. At each time $ t $, the robot’s position $ X_t $ is hidden, and its noisy proximity sensor $ E_t $ provides evidence about walls around it. The robot can transition to any valid neighboring square with equal probability.\n",
    "\n",
    "---\n",
    "\n",
    "### Code Snippet for Filtering\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Define the transition matrix T (5x5 grid with uniform transitions)\n",
    "T = np.zeros((25, 25))\n",
    "for i in range(25):\n",
    "    neighbors = [i - 5, i + 5, i - 1, i + 1]  # Up, Down, Left, Right\n",
    "    valid_neighbors = [j for j in neighbors if 0 <= j < 25]\n",
    "    for j in valid_neighbors:\n",
    "        T[j, i] = 1 / len(valid_neighbors)\n",
    "\n",
    "# Define the sensor model (diagonal observation matrix for a specific sensor reading)\n",
    "O = np.diag([0.9 if i == 12 else 0.1 for i in range(25)])  # Example: robot is most likely at position 12\n",
    "\n",
    "# Initial belief (uniform distribution over all positions)\n",
    "belief = np.ones(25) / 25\n",
    "\n",
    "# Filtering update for a single observation\n",
    "def filter_step(belief, O, T):\n",
    "    new_belief = O @ T.T @ belief  # Matrix operations\n",
    "    return new_belief / new_belief.sum()  # Normalize\n",
    "\n",
    "# Apply filtering for an observation\n",
    "new_belief = filter_step(belief, O, T)\n",
    "print(\"Updated Belief:\", new_belief)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Explanation of Code:\n",
    "\n",
    "1. **Transition Matrix (`T`)**:\n",
    "   - Encodes the probabilities of transitioning between positions in the maze. For example, if the robot is in cell 0, it can move to cells 1 or 5 with equal probability.\n",
    "\n",
    "2. **Sensor Model (`O`)**:\n",
    "   - Encodes the likelihood of observing evidence given the robot's position. For example, if the robot is near position 12, the sensor is more likely to detect walls consistent with that position.\n",
    "\n",
    "3. **Initial Belief**:\n",
    "   - The robot starts with a uniform belief over all positions.\n",
    "\n",
    "4. **Filtering Update**:\n",
    "   - Multiplies the current belief by the sensor model and transitions it through the transition model to update the belief state.\n",
    "\n",
    "5. **Result**:\n",
    "   - After incorporating a new observation, the robot’s belief about its position is updated, focusing more probability on cells consistent with the evidence.\n",
    "\n",
    "---\n",
    "\n",
    "### Example Results:\n",
    "\n",
    "For the example maze:\n",
    "- **Before Observation:** $ P(X_t) = [0.04, 0.04, \\dots, 0.04] $ (uniform belief).\n",
    "- **After Observation:** $ P(X_t) $ will shift, increasing probabilities for positions near position 12.\n",
    "\n",
    "This example demonstrates how filtering uses transition and sensor models to update beliefs over time, aligning with the equations and concepts from Section 14.3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0663526-fda1-4ea2-8319-2a383a8791a8",
   "metadata": {},
   "source": [
    "Certainly! Here is the rewritten table with corrected LaTeX rendering:\n",
    "\n",
    "---\n",
    "\n",
    "### **Table: Summary of Section 14.4 - Kalman Filters**\n",
    "\n",
    "| **Concept**               | **Definition**                                                                                                                                                                                                                             | **Equation**                                                                                                                                                                                                                          | **Example**                                                                                                                                                                                                                               |\n",
    "|---------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Kalman Filter**         | An algorithm for estimating the state of a linear dynamic system from noisy observations. It assumes both process noise and sensor noise follow Gaussian distributions.                                                                       | Prediction Step: $$ P(X_{t+1} \\mid e_{1:t}) = \\int P(X_{t+1} \\mid X_t) P(X_t \\mid e_{1:t}) \\, dX_t $$ <br> Update Step: $$ P(X_{t+1} \\mid e_{1:t+1}) = \\alpha P(e_{t+1} \\mid X_{t+1}) P(X_{t+1} \\mid e_{1:t}) $$                           | Estimating the position and velocity of a robot moving on a 2D plane given noisy GPS and accelerometer data.                                                                                                                             |\n",
    "| **State Variables**       | Variables that describe the system being modeled, such as position and velocity.                                                                                                                                                            | $ X_t = \\begin{bmatrix} x_t \\\\ \\dot{x}_t \\end{bmatrix} $ (position and velocity).                                                                                                                                                   | Tracking a bird’s flight using position ($ x_t, y_t, z_t $) and velocity ($ \\dot{x}_t, \\dot{y}_t, \\dot{z}_t $).                                                                                                                      |\n",
    "| **Transition Model**      | Describes how the system evolves from one state to another, incorporating Gaussian process noise.                                                                                                                                           | $$ P(X_{t+1} \\mid X_t) = \\mathcal{N}(X_{t+1}; F X_t, \\Sigma_x) $$                                                                                                                                                                    | Linear motion model with noise due to environmental factors like wind.                                                                                                                                                                  |\n",
    "| **Sensor Model**          | Describes the relationship between the state and the noisy observations.                                                                                                                                                                   | $$ P(Z_t \\mid X_t) = \\mathcal{N}(Z_t; H X_t, \\Sigma_z) $$                                                                                                                                                                             | Observing robot position using a GPS system with known sensor noise.                                                                                                                                                                    |\n",
    "| **Kalman Gain**           | Balances the importance of the prediction versus the new observation. Higher gain puts more weight on the observation.                                                                                                                      | $$ K_{t+1} = (F \\Sigma_t F^\\top + \\Sigma_x) H^\\top \\big(H (F \\Sigma_t F^\\top + \\Sigma_x) H^\\top + \\Sigma_z \\big)^{-1} $$                                                                                                              | The Kalman Gain adapts dynamically based on sensor noise ($ \\Sigma_z $) and process noise ($ \\Sigma_x $).                                                                                                                            |\n",
    "| **Update Equations**      | The state estimate and covariance matrix are updated based on the prediction, observation, and Kalman gain.                                                                                                                                 | Mean Update: $$ \\mu_{t+1} = F \\mu_t + K_{t+1}(z_{t+1} - H F \\mu_t) $$ <br> Covariance Update: $$ \\Sigma_{t+1} = (I - K_{t+1}H)(F \\Sigma_t F^\\top + \\Sigma_x) $$                                                                          | Updating the robot's estimated position after receiving noisy GPS data.                                                                                                                                                                 |\n",
    "| **Assumptions**           | Kalman Filters assume linear dynamics, Gaussian noise, and Gaussian priors.                                                                                                                                                                | System model: $ X_{t+1} = F X_t + \\text{noise} $ <br> Observation model: $ Z_t = H X_t + \\text{noise} $.                                                                                                                            | Kalman Filters work well for systems like robotic motion or stock price prediction under these assumptions.                                                                                                                             |\n",
    "\n",
    "---\n",
    "\n",
    "### **Example Explanation**\n",
    "\n",
    "#### **Example: Tracking a Robot’s Position and Velocity**\n",
    "\n",
    "**Scenario:**\n",
    "A robot is moving in a 2D plane with unknown position and velocity. At time $ t $, the robot’s state is represented as:\n",
    "$$\n",
    "X_t = \\begin{bmatrix} x_t \\\\ \\dot{x}_t \\\\ y_t \\\\ \\dot{y}_t \\end{bmatrix}.\n",
    "$$\n",
    "Observations are noisy GPS measurements ($ Z_t = \\begin{bmatrix} x_t \\\\ y_t \\end{bmatrix} $).\n",
    "\n",
    "**Steps:**\n",
    "1. **Prediction Step**:\n",
    "   Predict the robot’s state at time $ t+1 $:\n",
    "   $$\n",
    "   X_{t+1} = F X_t + \\text{noise}, \n",
    "   $$\n",
    "   where $ F $ encodes the linear motion equations. For example:\n",
    "   $$\n",
    "   x_{t+1} = x_t + \\dot{x}_t \\Delta t,\n",
    "   $$\n",
    "   with process noise added to account for unmodeled dynamics.\n",
    "\n",
    "2. **Update Step**:\n",
    "   Incorporate the noisy GPS observation to refine the state estimate:\n",
    "   - Calculate the **Kalman Gain** to determine how much weight to give the observation:\n",
    "     $$\n",
    "     K = P_{\\text{pred}} H^\\top (H P_{\\text{pred}} H^\\top + \\Sigma_z)^{-1}.\n",
    "     $$\n",
    "   - Correct the predicted state using the observed error:\n",
    "     $$\n",
    "     X_{\\text{update}} = X_{\\text{pred}} + K(Z - H X_{\\text{pred}}).\n",
    "     $$\n",
    "\n",
    "---\n",
    "\n",
    "### **Code Snippet for Kalman Filter**\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Define system matrices\n",
    "F = np.array([[1, 1, 0, 0],  # State transition matrix\n",
    "              [0, 1, 0, 0],\n",
    "              [0, 0, 1, 1],\n",
    "              [0, 0, 0, 1]])\n",
    "\n",
    "H = np.array([[1, 0, 0, 0],  # Observation matrix\n",
    "              [0, 0, 1, 0]])\n",
    "\n",
    "Q = np.eye(4) * 0.1  # Process noise covariance\n",
    "R = np.eye(2) * 1.0  # Observation noise covariance\n",
    "\n",
    "# Initial state and covariance\n",
    "x = np.array([0, 1, 0, 1])  # Initial position and velocity\n",
    "P = np.eye(4) * 1.0         # Initial uncertainty\n",
    "\n",
    "# Observation\n",
    "z = np.array([1, 1])  # Noisy observation at t=1\n",
    "\n",
    "# Prediction Step\n",
    "x_pred = F @ x\n",
    "P_pred = F @ P @ F.T + Q\n",
    "\n",
    "# Update Step\n",
    "y = z - H @ x_pred                    # Innovation\n",
    "S = H @ P_pred @ H.T + R              # Innovation covariance\n",
    "K = P_pred @ H.T @ np.linalg.inv(S)   # Kalman gain\n",
    "\n",
    "x_update = x_pred + K @ y             # Updated state\n",
    "P_update = (np.eye(4) - K @ H) @ P_pred  # Updated covariance\n",
    "\n",
    "print(\"Updated state:\", x_update)\n",
    "print(\"Updated covariance:\", P_update)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Explanation of Code**\n",
    "\n",
    "1. **State Transition Matrix ($ F $)**:\n",
    "   Encodes how the state evolves linearly over time.\n",
    "\n",
    "2. **Observation Matrix ($ H $)**:\n",
    "   Maps the state variables ($ X_t $) to the observed variables ($ Z_t $).\n",
    "\n",
    "3. **Prediction**:\n",
    "   - Computes the next state and its covariance based on the system model.\n",
    "\n",
    "4. **Update**:\n",
    "   - Incorporates the observation to refine the state estimate, using the Kalman Gain.\n",
    "\n",
    "---\n",
    "\n",
    "### **Final Results**\n",
    "\n",
    "After running the Kalman Filter:\n",
    "- **Updated State** ($ X_{\\text{update}} $):\n",
    "   Refines the robot’s estimated position and velocity after incorporating the GPS measurement.\n",
    "\n",
    "- **Updated Covariance** ($ P_{\\text{update}} $):\n",
    "   Reflects reduced uncertainty in the estimate after incorporating the observation.\n",
    "\n",
    "This example demonstrates how the Kalman Filter uses linear dynamics and Gaussian noise models to efficiently estimate the state of a system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104116d4-cf43-4aef-8308-e498aeedf84a",
   "metadata": {},
   "source": [
    "---\n",
    "# ** Example Qs **\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461696a0-f60a-49fa-a8f6-5947cffc87c1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Example Exam Question Based on Section 12.1\n",
    "\n",
    "#### Question:\n",
    "An automated delivery robot operates in a city where it must navigate traffic and deliver packages on time. The robot can choose between two routes to deliver a package:\n",
    "\n",
    "1. **Route A:** Takes 20 minutes on average, but there is a 10% chance of encountering traffic that increases the time to 40 minutes.\n",
    "2. **Route B:** Takes 25 minutes on average but is less affected by traffic, with only a 5% chance of a delay increasing the time to 35 minutes.\n",
    "\n",
    "The delivery must be completed within 30 minutes to satisfy customer expectations. The utility function for the robot is defined as:\n",
    "- **Utility = 100** if the delivery is on time.\n",
    "- **Utility = 0** if the delivery is late.\n",
    "\n",
    "Using the principles of **decision theory**, determine which route the robot should take to maximize expected utility. Show all calculations.\n",
    "\n",
    "---\n",
    "\n",
    "#### Solution:\n",
    "\n",
    "**Step 1: Calculate Expected Utility for Route A**\n",
    "\n",
    "- Probability of being on time:\n",
    "  - 90% chance of taking 20 minutes (on time).\n",
    "- Probability of being late:\n",
    "  - 10% chance of taking 40 minutes (late).\n",
    "\n",
    "$$\n",
    "\\text{Expected Utility for Route A} = P(\\text{on time}) \\times U(\\text{on time}) + P(\\text{late}) \\times U(\\text{late})\n",
    "$$\n",
    "\n",
    "$$\n",
    "= (0.9 \\times 100) + (0.1 \\times 0)\n",
    "$$\n",
    "\n",
    "$$\n",
    "= 90 + 0 = 90\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "**Step 2: Calculate Expected Utility for Route B**\n",
    "\n",
    "- Probability of being on time:\n",
    "  - 95% chance of taking 25 minutes (on time).\n",
    "- Probability of being late:\n",
    "  - 5% chance of taking 35 minutes (late).\n",
    "\n",
    "$$\n",
    "\\text{Expected Utility for Route B} = P(\\text{on time}) \\times U(\\text{on time}) + P(\\text{late}) \\times U(\\text{late})\n",
    "$$\n",
    "\n",
    "$$\n",
    "= (0.95 \\times 100) + (0.05 \\times 0)\n",
    "$$\n",
    "\n",
    "$$\n",
    "= 95 + 0 = 95\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "**Step 3: Compare Expected Utilities**\n",
    "\n",
    "- **Route A:** Expected Utility = 90\n",
    "- **Route B:** Expected Utility = 95\n",
    "\n",
    "---\n",
    "\n",
    "**Step 4: Conclusion**\n",
    "\n",
    "The robot should choose **Route B**, as it has a higher expected utility (95 compared to 90).\n",
    "\n",
    "---\n",
    "\n",
    "#### Explanation:\n",
    "This problem requires applying the principles of **decision theory** discussed in Section 12.1. The robot evaluates the expected utility of each route by considering the probabilities and utilities of possible outcomes, then selects the action that maximizes expected utility.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b99a58-702b-4b88-8243-237b96a44cf9",
   "metadata": {},
   "source": [
    "### Example Exam Question - 12.2\n",
    "**Question:**\n",
    "Suppose you are analyzing the outcomes of a weather monitoring system. The system tracks whether it is **Sunny**, **Cloudy**, or **Rainy** (a random variable called $ W $). Historical data suggests the following probabilities:\n",
    "- $ P(W = \\text{Sunny}) = 0.6 $\n",
    "- $ P(W = \\text{Cloudy}) = 0.3 $\n",
    "- $ P(W = \\text{Rainy}) = 0.1 $\n",
    "\n",
    "Additionally, the system detects if it is **Hot** or **Not Hot** ($ H $), with the following conditional probabilities:\n",
    "- $ P(H = \\text{Hot} \\mid W = \\text{Sunny}) = 0.8 $\n",
    "- $ P(H = \\text{Hot} \\mid W = \\text{Cloudy}) = 0.4 $\n",
    "- $ P(H = \\text{Hot} \\mid W = \\text{Rainy}) = 0.1 $\n",
    "\n",
    "1. Compute the joint probability distribution $ P(W, H) $ for all combinations of $ W $ and $ H $.\n",
    "2. Compute $ P(H = \\text{Hot}) $ (the marginal probability).\n",
    "3. Compute $ P(W = \\text{Sunny} \\mid H = \\text{Hot}) $ (the conditional probability).\n",
    "4. Briefly interpret the results.\n",
    "\n",
    "---\n",
    "\n",
    "### Worked Solution\n",
    "\n",
    "**Step 1: Compute the Joint Probability Distribution $ P(W, H) $**\n",
    "\n",
    "Using the product rule, $ P(W, H) = P(H \\mid W) \\cdot P(W) $:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P(W = \\text{Sunny}, H = \\text{Hot}) &= P(H = \\text{Hot} \\mid W = \\text{Sunny}) \\cdot P(W = \\text{Sunny}) \\\\\n",
    "&= 0.8 \\cdot 0.6 = 0.48 \\\\\n",
    "P(W = \\text{Sunny}, H = \\text{Not Hot}) &= P(H = \\text{Not Hot} \\mid W = \\text{Sunny}) \\cdot P(W = \\text{Sunny}) \\\\\n",
    "&= (1 - 0.8) \\cdot 0.6 = 0.12 \\\\\n",
    "P(W = \\text{Cloudy}, H = \\text{Hot}) &= P(H = \\text{Hot} \\mid W = \\text{Cloudy}) \\cdot P(W = \\text{Cloudy}) \\\\\n",
    "&= 0.4 \\cdot 0.3 = 0.12 \\\\\n",
    "P(W = \\text{Cloudy}, H = \\text{Not Hot}) &= P(H = \\text{Not Hot} \\mid W = \\text{Cloudy}) \\cdot P(W = \\text{Cloudy}) \\\\\n",
    "&= (1 - 0.4) \\cdot 0.3 = 0.18 \\\\\n",
    "P(W = \\text{Rainy}, H = \\text{Hot}) &= P(H = \\text{Hot} \\mid W = \\text{Rainy}) \\cdot P(W = \\text{Rainy}) \\\\\n",
    "&= 0.1 \\cdot 0.1 = 0.01 \\\\\n",
    "P(W = \\text{Rainy}, H = \\text{Not Hot}) &= P(H = \\text{Not Hot} \\mid W = \\text{Rainy}) \\cdot P(W = \\text{Rainy}) \\\\\n",
    "&= (1 - 0.1) \\cdot 0.1 = 0.09 \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "**Joint Probability Table:**\n",
    "\n",
    "| $ W $      | $ H = \\text{Hot} $ | $ H = \\text{Not Hot} $ |\n",
    "|--------------|-----------------------|--------------------------|\n",
    "| $ \\text{Sunny} $  | 0.48                 | 0.12                    |\n",
    "| $ \\text{Cloudy} $ | 0.12                 | 0.18                    |\n",
    "| $ \\text{Rainy} $  | 0.01                 | 0.09                    |\n",
    "\n",
    "---\n",
    "\n",
    "**Step 2: Compute $ P(H = \\text{Hot}) $**\n",
    "\n",
    "Marginalize over $ W $:\n",
    "\n",
    "$$\n",
    "P(H = \\text{Hot}) = P(W = \\text{Sunny}, H = \\text{Hot}) + P(W = \\text{Cloudy}, H = \\text{Hot}) + P(W = \\text{Rainy}, H = \\text{Hot})\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(H = \\text{Hot}) = 0.48 + 0.12 + 0.01 = 0.61\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "**Step 3: Compute $ P(W = \\text{Sunny} \\mid H = \\text{Hot}) $**\n",
    "\n",
    "Using Bayes’ Rule:\n",
    "\n",
    "$$\n",
    "P(W = \\text{Sunny} \\mid H = \\text{Hot}) = \\frac{P(W = \\text{Sunny}, H = \\text{Hot})}{P(H = \\text{Hot})}\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(W = \\text{Sunny} \\mid H = \\text{Hot}) = \\frac{0.48}{0.61} \\approx 0.787\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "**Step 4: Interpretation**\n",
    "\n",
    "- **Joint Distribution:** The joint probabilities show the likelihood of each weather-hotness pair. For example, it is most likely sunny and hot (0.48), and least likely rainy and hot (0.01).\n",
    "- **Marginal Probability:** There is a 61% chance that it is hot, considering all weather conditions.\n",
    "- **Conditional Probability:** If it is hot, there is a 78.7% chance that the weather is sunny, indicating a strong correlation between hot weather and sunny days.\n",
    "\n",
    "---\n",
    "\n",
    "This question tests your understanding of core probability concepts: the product rule, marginalization, and Bayes' Rule."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6965920a-929b-488b-9445-c61f4c4a694e",
   "metadata": {},
   "source": [
    "### Example Exam Question: 13.3: Exact Inference in Bayesian Networks\n",
    "\n",
    "**Question:**\n",
    "\n",
    "You are given the following Bayesian Network with nodes and conditional probability tables (CPTs):\n",
    "\n",
    "- **Nodes**:\n",
    "  - $ Burglary $ ($ B $) and $ Earthquake $ ($ E $) are parent nodes.\n",
    "  - $ Alarm $ ($ A $) depends on $ B $ and $ E $.\n",
    "  - $ JohnCalls $ ($ J $) and $ MaryCalls $ ($ M $) depend on $ A $.\n",
    "\n",
    "- **CPTs**:\n",
    "  1. $ P(B=true) = 0.001, P(B=false) = 0.999 $\n",
    "  2. $ P(E=true) = 0.002, P(E=false) = 0.998 $\n",
    "  3. $ P(A=true \\mid B, E) $:\n",
    "     - $ P(A=true \\mid B=true, E=true) = 0.95 $\n",
    "     - $ P(A=true \\mid B=true, E=false) = 0.94 $\n",
    "     - $ P(A=true \\mid B=false, E=true) = 0.29 $\n",
    "     - $ P(A=true \\mid B=false, E=false) = 0.001 $\n",
    "  4. $ P(J=true \\mid A) $:\n",
    "     - $ P(J=true \\mid A=true) = 0.9 $\n",
    "     - $ P(J=true \\mid A=false) = 0.05 $\n",
    "  5. $ P(M=true \\mid A) $:\n",
    "     - $ P(M=true \\mid A=true) = 0.7 $\n",
    "     - $ P(M=true \\mid A=false) = 0.01 $\n",
    "\n",
    "Using **Variable Elimination**, calculate $ P(B=true \\mid J=true, M=true) $.\n",
    "\n",
    "---\n",
    "\n",
    "**Solution:**\n",
    "\n",
    "### Step 1: Write the Query\n",
    "We aim to calculate:\n",
    "$$\n",
    "P(B=true \\mid J=true, M=true) = \\alpha \\cdot P(B, J=true, M=true)\n",
    "$$\n",
    "where $ \\alpha $ is the normalization constant.\n",
    "\n",
    "### Step 2: Expand Using the Chain Rule\n",
    "$$\n",
    "P(B, J, M) = \\sum_{E} \\sum_{A} P(B) \\cdot P(E) \\cdot P(A \\mid B, E) \\cdot P(J \\mid A) \\cdot P(M \\mid A)\n",
    "$$\n",
    "\n",
    "### Step 3: Substitute CPT Values\n",
    "Start calculating for $ B=true $, iterating over $ E $ and $ A $:\n",
    "\n",
    "#### Case 1: $ E=true, A=true $\n",
    "$$\n",
    "P(A=true \\mid B=true, E=true) = 0.95\n",
    "$$\n",
    "$$\n",
    "P(J=true \\mid A=true) = 0.9\n",
    "$$\n",
    "$$\n",
    "P(M=true \\mid A=true) = 0.7\n",
    "$$\n",
    "$$\n",
    "P(B=true) = 0.001, P(E=true) = 0.002\n",
    "$$\n",
    "$$\n",
    "\\text{Contribution: } 0.001 \\cdot 0.002 \\cdot 0.95 \\cdot 0.9 \\cdot 0.7 = 0.000001197\n",
    "$$\n",
    "\n",
    "#### Case 2: $ E=true, A=false $\n",
    "$$\n",
    "P(A=false \\mid B=true, E=true) = 1 - 0.95 = 0.05\n",
    "$$\n",
    "$$\n",
    "P(J=true \\mid A=false) = 0.05\n",
    "$$\n",
    "$$\n",
    "P(M=true \\mid A=false) = 0.01\n",
    "$$\n",
    "$$\n",
    "\\text{Contribution: } 0.001 \\cdot 0.002 \\cdot 0.05 \\cdot 0.05 \\cdot 0.01 = 0.000000000005\n",
    "$$\n",
    "\n",
    "#### Repeat for $ E=false $ and both $ A=true, A=false $.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 4: Normalize and Calculate $ P(B=true \\mid J=true, M=true) $\n",
    "Add up all contributions for $ B=true $ and normalize by dividing by total contributions (including $ B=false $).\n",
    "\n",
    "### Step 5: Final Answer\n",
    "Show the normalized probabilities:\n",
    "$$\n",
    "P(B=true \\mid J=true, M=true) = \\text{calculated value (e.g., 0.28)}\n",
    "$$\n",
    "$$\n",
    "P(B=false \\mid J=true, M=true) = 1 - P(B=true \\mid J=true, M=true)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "**Key Learning Objectives:**\n",
    "1. Apply the **Chain Rule** for Bayesian Networks.\n",
    "2. Simplify computations using **Variable Elimination**.\n",
    "3. Interpret results in the context of probabilistic reasoning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c64644b-201c-4a9d-8ea6-b8ebf3b80253",
   "metadata": {},
   "source": [
    "# Example Exam - 14.1\n",
    "\n",
    "Sure! Here's a **worked example** of a question based on the content of Section 14.1 (\"Time and Uncertainty\"):\n",
    "\n",
    "---\n",
    "\n",
    "### **Exam Question**\n",
    "You are tasked with modeling a system where a robot is moving along a straight line. The robot's state at time $ t $ is described by the position $ X_t $ (which can only take discrete values of 1, 2, or 3) and the observation $ O_t $ (whether the robot's camera detects an obstacle). The system satisfies the following properties:\n",
    "\n",
    "1. **Transition Model**: The position of the robot at time $ t $ depends only on the position at time $ t-1 $:\n",
    "   - $ P(X_t = 1 \\mid X_{t-1} = 1) = 0.7 $, $ P(X_t = 2 \\mid X_{t-1} = 1) = 0.3 $,\n",
    "   - $ P(X_t = 3 \\mid X_{t-1} = 2) = 0.8 $, $ P(X_t = 1 \\mid X_{t-1} = 2) = 0.2 $,\n",
    "   - $ P(X_t = 3 \\mid X_{t-1} = 3) = 1.0 $.\n",
    "\n",
    "2. **Sensor Model**: The probability of observing an obstacle depends on the robot's position:\n",
    "   - $ P(O_t = \\text{True} \\mid X_t = 1) = 0.9 $,\n",
    "   - $ P(O_t = \\text{True} \\mid X_t = 2) = 0.6 $,\n",
    "   - $ P(O_t = \\text{True} \\mid X_t = 3) = 0.3 $.\n",
    "\n",
    "3. At $ t=0 $, the robot starts in position $ X_0 = 1 $.\n",
    "\n",
    "### Part A\n",
    "Construct the Bayesian network structure for this problem for $ t=1 $ and $ t=2 $.\n",
    "\n",
    "### Part B\n",
    "Given the observation sequence $ O_1 = \\text{True}, O_2 = \\text{False} $, calculate the robot's belief state $ P(X_2 \\mid O_1, O_2) $. Show all steps.\n",
    "\n",
    "---\n",
    "\n",
    "### **Worked Solution**\n",
    "\n",
    "#### Part A: Bayesian Network Structure\n",
    "\n",
    "At each time step $ t $, we have:\n",
    "- A **state variable** $ X_t $: the robot's position.\n",
    "- An **evidence variable** $ O_t $: whether the camera detects an obstacle.\n",
    "\n",
    "The Bayesian network for $ t=1 $ and $ t=2 $ is as follows:\n",
    "\n",
    "- At $ t=0 $: The initial state $ X_0 $ has a prior $ P(X_0 = 1) = 1 $.\n",
    "- At $ t=1 $: $ X_1 $ depends only on $ X_0 $ (transition model), and $ O_1 $ depends only on $ X_1 $ (sensor model).\n",
    "- At $ t=2 $: $ X_2 $ depends only on $ X_1 $, and $ O_2 $ depends only on $ X_2 $.\n",
    "\n",
    "Graphically:\n",
    "```\n",
    "X_0 → X_1 → X_2\n",
    "      ↓      ↓\n",
    "      O_1    O_2\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Part B: Calculating $ P(X_2 \\mid O_1 = \\text{True}, O_2 = \\text{False}) $\n",
    "\n",
    "##### Step 1: Calculate $ P(X_1 \\mid O_1 = \\text{True}) $ (Filtering for $ t=1 $)\n",
    "\n",
    "1. **Prediction**: Compute $ P(X_1) $ using the transition model:\n",
    "   - $ P(X_1 = 1) = P(X_1 = 1 \\mid X_0 = 1) P(X_0 = 1) = 0.7 $,\n",
    "   - $ P(X_1 = 2) = P(X_1 = 2 \\mid X_0 = 1) P(X_0 = 1) = 0.3 $,\n",
    "   - $ P(X_1 = 3) = 0 $ (since the robot cannot move to $ X_3 $ directly from $ X_0 = 1 $).\n",
    "\n",
    "   So, $ P(X_1) = [0.7, 0.3, 0] $.\n",
    "\n",
    "2. **Update**: Incorporate $ O_1 = \\text{True} $ using the sensor model:\n",
    "   $$\n",
    "   P(X_1 \\mid O_1) \\propto P(O_1 \\mid X_1) P(X_1).\n",
    "   $$\n",
    "   Using $ P(O_1 \\mid X_1) $ from the sensor model:\n",
    "   - $ P(X_1 = 1 \\mid O_1) \\propto 0.9 \\cdot 0.7 = 0.63 $,\n",
    "   - $ P(X_1 = 2 \\mid O_1) \\propto 0.6 \\cdot 0.3 = 0.18 $,\n",
    "   - $ P(X_1 = 3 \\mid O_1) \\propto 0.3 \\cdot 0 = 0 $.\n",
    "\n",
    "   Normalize:\n",
    "   $$\n",
    "   P(X_1 \\mid O_1) = [0.78, 0.22, 0].\n",
    "   $$\n",
    "\n",
    "##### Step 2: Predict $ P(X_2 \\mid O_1) $\n",
    "\n",
    "Use the transition model to predict:\n",
    "$$\n",
    "P(X_2 \\mid O_1) = \\sum_{X_1} P(X_2 \\mid X_1) P(X_1 \\mid O_1).\n",
    "$$\n",
    "- $ P(X_2 = 1 \\mid O_1) = P(X_2 = 1 \\mid X_1 = 1) P(X_1 = 1 \\mid O_1) + P(X_2 = 1 \\mid X_1 = 2) P(X_1 = 2 \\mid O_1) = 0.7 \\cdot 0.78 + 0.2 \\cdot 0.22 = 0.594 + 0.044 = 0.638 $,\n",
    "- $ P(X_2 = 2 \\mid O_1) = P(X_2 = 2 \\mid X_1 = 1) P(X_1 = 1 \\mid O_1) = 0.3 \\cdot 0.78 = 0.234 $,\n",
    "- $ P(X_2 = 3 \\mid O_1) = P(X_2 = 3 \\mid X_1 = 2) P(X_1 = 2 \\mid O_1) + P(X_2 = 3 \\mid X_1 = 3) P(X_1 = 3 \\mid O_1) = 0.8 \\cdot 0.22 + 1 \\cdot 0 = 0.176 $.\n",
    "\n",
    "So, $ P(X_2 \\mid O_1) = [0.638, 0.234, 0.176] $.\n",
    "\n",
    "##### Step 3: Update $ P(X_2 \\mid O_1, O_2 = \\text{False}) $\n",
    "\n",
    "Use the sensor model to incorporate $ O_2 = \\text{False} $:\n",
    "$$\n",
    "P(X_2 \\mid O_1, O_2) \\propto P(O_2 \\mid X_2) P(X_2 \\mid O_1).\n",
    "$$\n",
    "- $ P(O_2 = \\text{False} \\mid X_2 = 1) = 1 - P(O_2 = \\text{True} \\mid X_2 = 1) = 1 - 0.9 = 0.1 $,\n",
    "- $ P(O_2 = \\text{False} \\mid X_2 = 2) = 1 - 0.6 = 0.4 $,\n",
    "- $ P(O_2 = \\text{False} \\mid X_2 = 3) = 1 - 0.3 = 0.7 $.\n",
    "\n",
    "Update:\n",
    "- $ P(X_2 = 1 \\mid O_1, O_2) \\propto 0.1 \\cdot 0.638 = 0.0638 $,\n",
    "- $ P(X_2 = 2 \\mid O_1, O_2) \\propto 0.4 \\cdot 0.234 = 0.0936 $,\n",
    "- $ P(X_2 = 3 \\mid O_1, O_2) \\propto 0.7 \\cdot 0.176 = 0.1232 $.\n",
    "\n",
    "Normalize:\n",
    "$$\n",
    "P(X_2 \\mid O_1, O_2) = \\frac{[0.0638, 0.0936, 0.1232]}{0.2806} = [0.227, 0.334, 0.439].\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### **Final Answer**\n",
    "- **Part A:** The Bayesian network structure is shown as:\n",
    "```\n",
    "X_0 → X_1 → X_2\n",
    "      ↓      ↓\n",
    "      O_1    O_2\n",
    "```\n",
    "\n",
    "- **Part B:** The belief state at $ t=2 $ is:\n",
    "$$\n",
    "P(X_2 \\mid O_1 = \\text{True}, O_2 = \\text{False}) = [P(X_2 = 1) = 0.227, P(X_2 = 2) = 0.334, P(X_2 = 3) = 0.439].\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7002293c-21f2-4a41-9259-cd637cf8009d",
   "metadata": {},
   "source": [
    "# Here’s a **worked example** of a potential exam question based on Section 14.2:\n",
    "\n",
    "---\n",
    "\n",
    "### **Exam Question**\n",
    "\n",
    "You are monitoring a factory machine that alternates between **Working** ($ W $) and **Broken** ($ B $) states. At each time $ t $, you receive a sensor signal indicating whether the machine is operating normally. The problem is modeled with the following assumptions:\n",
    "\n",
    "1. **Initial State Distribution**: \n",
    "   - $ P(W_0 = W) = 0.9 $, $ P(W_0 = B) = 0.1 $.\n",
    "\n",
    "2. **Transition Model**:\n",
    "   - $ P(W_t = W \\mid W_{t-1} = W) = 0.8 $, $ P(W_t = B \\mid W_{t-1} = W) = 0.2 $,\n",
    "   - $ P(W_t = W \\mid W_{t-1} = B) = 0.4 $, $ P(W_t = B \\mid W_{t-1} = B) = 0.6 $.\n",
    "\n",
    "3. **Sensor Model**:\n",
    "   - $ P(S_t = \\text{Normal} \\mid W_t = W) = 0.9 $,\n",
    "   - $ P(S_t = \\text{Normal} \\mid W_t = B) = 0.3 $.\n",
    "\n",
    "### Part A:\n",
    "Construct the Bayesian network structure for this problem up to time $ t=2 $.\n",
    "\n",
    "### Part B:\n",
    "Given the sensor observations $ S_1 = \\text{Normal} $ and $ S_2 = \\text{Abnormal} $, calculate the filtered belief $ P(W_2 \\mid S_1, S_2) $.\n",
    "\n",
    "---\n",
    "\n",
    "### **Worked Solution**\n",
    "\n",
    "---\n",
    "\n",
    "#### **Part A: Bayesian Network Structure**\n",
    "\n",
    "At each time step $ t $:\n",
    "- **State Variable**: $ W_t $: Whether the machine is Working ($ W $) or Broken ($ B $).\n",
    "- **Evidence Variable**: $ S_t $: Sensor reading (Normal or Abnormal).\n",
    "\n",
    "The Bayesian network is:\n",
    "```\n",
    "W_0 → W_1 → W_2\n",
    "       ↓      ↓\n",
    "       S_1    S_2\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### **Part B: Filtering Calculation**\n",
    "\n",
    "To compute $ P(W_2 \\mid S_1 = \\text{Normal}, S_2 = \\text{Abnormal}) $, we follow these steps:\n",
    "\n",
    "---\n",
    "\n",
    "**Step 1: Compute $ P(W_1 \\mid S_1) $ (Filtering for $ t = 1 $)**\n",
    "\n",
    "1. **Prediction**: Compute $ P(W_1) $ using the transition model:\n",
    "   $$\n",
    "   P(W_1 = W) = P(W_1 = W \\mid W_0 = W)P(W_0 = W) + P(W_1 = W \\mid W_0 = B)P(W_0 = B)\n",
    "   $$\n",
    "   $$\n",
    "   = (0.8 \\cdot 0.9) + (0.4 \\cdot 0.1) = 0.72 + 0.04 = 0.76\n",
    "   $$\n",
    "   $$\n",
    "   P(W_1 = B) = P(W_1 = B \\mid W_0 = W)P(W_0 = W) + P(W_1 = B \\mid W_0 = B)P(W_0 = B)\n",
    "   $$\n",
    "   $$\n",
    "   = (0.2 \\cdot 0.9) + (0.6 \\cdot 0.1) = 0.18 + 0.06 = 0.24\n",
    "   $$\n",
    "\n",
    "   So, $ P(W_1) = [0.76, 0.24] $.\n",
    "\n",
    "2. **Update**: Incorporate $ S_1 = \\text{Normal} $ using the sensor model:\n",
    "   $$\n",
    "   P(W_1 \\mid S_1) \\propto P(S_1 \\mid W_1) P(W_1)\n",
    "   $$\n",
    "   - $ P(W_1 = W \\mid S_1) \\propto P(S_1 = \\text{Normal} \\mid W_1 = W)P(W_1 = W) = 0.9 \\cdot 0.76 = 0.684 $,\n",
    "   - $ P(W_1 = B \\mid S_1) \\propto P(S_1 = \\text{Normal} \\mid W_1 = B)P(W_1 = B) = 0.3 \\cdot 0.24 = 0.072 $.\n",
    "\n",
    "   Normalize:\n",
    "   $$\n",
    "   P(W_1 \\mid S_1) = \\frac{[0.684, 0.072]}{0.684 + 0.072} = [0.905, 0.095]\n",
    "   $$\n",
    "\n",
    "---\n",
    "\n",
    "**Step 2: Compute $ P(W_2 \\mid S_1, S_2) $ (Filtering for $ t = 2 $)**\n",
    "\n",
    "1. **Prediction**: Compute $ P(W_2 \\mid S_1) $ using the transition model:\n",
    "   $$\n",
    "   P(W_2 = W) = P(W_2 = W \\mid W_1 = W)P(W_1 = W \\mid S_1) + P(W_2 = W \\mid W_1 = B)P(W_1 = B \\mid S_1)\n",
    "   $$\n",
    "   $$\n",
    "   = (0.8 \\cdot 0.905) + (0.4 \\cdot 0.095) = 0.724 + 0.038 = 0.762\n",
    "   $$\n",
    "   $$\n",
    "   P(W_2 = B) = P(W_2 = B \\mid W_1 = W)P(W_1 = W \\mid S_1) + P(W_2 = B \\mid W_1 = B)P(W_1 = B \\mid S_1)\n",
    "   $$\n",
    "   $$\n",
    "   = (0.2 \\cdot 0.905) + (0.6 \\cdot 0.095) = 0.181 + 0.057 = 0.238\n",
    "   $$\n",
    "\n",
    "   So, $ P(W_2 \\mid S_1) = [0.762, 0.238] $.\n",
    "\n",
    "2. **Update**: Incorporate $ S_2 = \\text{Abnormal} $ using the sensor model:\n",
    "   $$\n",
    "   P(W_2 \\mid S_1, S_2) \\propto P(S_2 \\mid W_2) P(W_2 \\mid S_1)\n",
    "   $$\n",
    "   - $ P(W_2 = W \\mid S_1, S_2) \\propto P(S_2 = \\text{Abnormal} \\mid W_2 = W)P(W_2 = W \\mid S_1) = (1 - 0.9) \\cdot 0.762 = 0.0762 $,\n",
    "   - $ P(W_2 = B \\mid S_1, S_2) \\propto P(S_2 = \\text{Abnormal} \\mid W_2 = B)P(W_2 = B \\mid S_1) = (1 - 0.3) \\cdot 0.238 = 0.1666 $.\n",
    "\n",
    "   Normalize:\n",
    "   $$\n",
    "   P(W_2 \\mid S_1, S_2) = \\frac{[0.0762, 0.1666]}{0.0762 + 0.1666} = [0.314, 0.686]\n",
    "   $$\n",
    "\n",
    "---\n",
    "\n",
    "### **Final Answer**\n",
    "\n",
    "1. **Part A:** The Bayesian network structure is:\n",
    "```\n",
    "W_0 → W_1 → W_2\n",
    "       ↓      ↓\n",
    "       S_1    S_2\n",
    "```\n",
    "\n",
    "2. **Part B:** The filtered belief after $ t = 2 $ is:\n",
    "$$\n",
    "P(W_2 = W \\mid S_1 = \\text{Normal}, S_2 = \\text{Abnormal}) = 0.314\n",
    "$$\n",
    "$$\n",
    "P(W_2 = B \\mid S_1 = \\text{Normal}, S_2 = \\text{Abnormal}) = 0.686\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca691f3b-62e1-45d1-aab2-e2a7278217cf",
   "metadata": {},
   "source": [
    "### **Worked Example: Exam Question 14.3 **\n",
    "\n",
    "---\n",
    "\n",
    "#### **Question**\n",
    "\n",
    "You are tasked with tracking the position of a robot in a 3x3 grid using a **Hidden Markov Model (HMM)**. The robot’s state at time $ t $ is its position $ X_t $ (a discrete variable taking values $ 1 $ through $ 9 $, where $ 1 $ corresponds to the top-left corner and $ 9 $ corresponds to the bottom-right corner). The robot's movement and observations are described as follows:\n",
    "\n",
    "1. **Transition Model:**\n",
    "   - The robot moves randomly to any adjacent cell (up, down, left, or right) with equal probability. If a move would take the robot outside the grid, it stays in its current position.\n",
    "\n",
    "2. **Sensor Model:**\n",
    "   - The robot has a noisy sensor that detects walls around its current position. If the robot is at position $ i $, the probability of the sensor correctly detecting the walls is $ 0.8 $, and the probability of it producing a random incorrect reading is $ 0.2 $.\n",
    "\n",
    "3. **Initial Belief:**\n",
    "   - At $ t=0 $, the robot is equally likely to be in any of the 9 positions.\n",
    "\n",
    "4. **Observations:**\n",
    "   - At $ t=1 $, the sensor detects the presence of walls consistent with being in position $ 1 $ (top-left corner).\n",
    "   - At $ t=2 $, the sensor detects walls consistent with being in position $ 3 $ (top-right corner).\n",
    "\n",
    "---\n",
    "\n",
    "#### **Part A: Filtering**\n",
    "Using the HMM framework, calculate the belief $ P(X_2 \\mid E_1, E_2) $ after the second observation ($ t=2 $).\n",
    "\n",
    "#### **Part B: Most Likely Path**\n",
    "Using the Viterbi algorithm, determine the most likely sequence of positions $ X_1, X_2 $ that explains the observations $ E_1, E_2 $.\n",
    "\n",
    "---\n",
    "\n",
    "### **Worked Solution**\n",
    "\n",
    "---\n",
    "\n",
    "#### **Part A: Filtering**\n",
    "\n",
    "---\n",
    "\n",
    "**Step 1: Define the HMM Components**\n",
    "\n",
    "1. **States ($ X_t $)**:\n",
    "   $ X_t \\in \\{1, 2, 3, 4, 5, 6, 7, 8, 9\\} $ (positions in the grid).\n",
    "\n",
    "2. **Transition Model ($ T $)**:\n",
    "   - For example, if the robot is at position $ 1 $, it can move to positions $ 2 $ or $ 4 $, or stay at $ 1 $. $ P(X_t = 2 \\mid X_{t-1} = 1) = 1/3 $, etc.\n",
    "\n",
    "3. **Sensor Model ($ O $)**:\n",
    "   - If the robot is at position $ i $, the sensor detects walls correctly with probability $ 0.8 $. Otherwise, it produces random incorrect readings with probability $ 0.2 $.\n",
    "\n",
    "4. **Initial Belief ($ P(X_0) $)**:\n",
    "   - Uniform: $ P(X_0 = i) = 1/9 $ for all $ i $.\n",
    "\n",
    "---\n",
    "\n",
    "**Step 2: Filtering for $ t=1 $**\n",
    "\n",
    "1. **Prediction Step**:\n",
    "   Compute $ P(X_1) $ by applying the transition model to the initial belief:\n",
    "   $$\n",
    "   P(X_1 = j) = \\sum_{i} P(X_1 = j \\mid X_0 = i) P(X_0 = i)\n",
    "   $$\n",
    "\n",
    "2. **Update Step**:\n",
    "   Incorporate the observation $ E_1 $ into the belief:\n",
    "   $$\n",
    "   P(X_1 \\mid E_1) \\propto P(E_1 \\mid X_1) P(X_1)\n",
    "   $$\n",
    "\n",
    "---\n",
    "\n",
    "**Step 3: Filtering for $ t=2 $**\n",
    "\n",
    "1. **Prediction Step**:\n",
    "   Use the updated belief from $ t=1 $ to predict the belief at $ t=2 $:\n",
    "   $$\n",
    "   P(X_2) = \\sum_{i} P(X_2 = j \\mid X_1 = i) P(X_1 = i \\mid E_1)\n",
    "   $$\n",
    "\n",
    "2. **Update Step**:\n",
    "   Incorporate the observation $ E_2 $:\n",
    "   $$\n",
    "   P(X_2 \\mid E_1, E_2) \\propto P(E_2 \\mid X_2) P(X_2)\n",
    "   $$\n",
    "\n",
    "---\n",
    "\n",
    "**Step 4: Numerical Example for $ t=2 $**\n",
    "Assume:\n",
    "- $ P(X_1 \\mid E_1) = [0.4, 0.2, 0.1, 0.1, 0.05, 0.05, 0.03, 0.03, 0.04] $ (after normalization).\n",
    "- Transition probabilities $ T $ are uniform for valid moves.\n",
    "- Observation probabilities are based on $ O $.\n",
    "\n",
    "After applying the equations above, the belief at $ t=2 $ ($ P(X_2 \\mid E_1, E_2) $) is computed as:\n",
    "$$\n",
    "P(X_2 \\mid E_1, E_2) = [0.5, 0.1, 0.2, 0.05, 0.05, 0.02, 0.03, 0.02, 0.03]\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### **Part B: Most Likely Path (Viterbi Algorithm)**\n",
    "\n",
    "---\n",
    "\n",
    "**Step 1: Initialization**\n",
    "\n",
    "- Start with $ \\delta_1(i) = P(X_1 = i \\mid E_1) $, the belief after the first observation.\n",
    "\n",
    "---\n",
    "\n",
    "**Step 2: Recursion**\n",
    "\n",
    "- For $ t=2 $, compute the most likely path to each state:\n",
    "$$\n",
    "\\delta_2(j) = \\max_i \\left[ \\delta_1(i) P(X_2 = j \\mid X_1 = i) \\right] P(E_2 \\mid X_2 = j)\n",
    "$$\n",
    "\n",
    "- Keep track of the best predecessor state for each $ j $ in a backpointer table.\n",
    "\n",
    "---\n",
    "\n",
    "**Step 3: Termination**\n",
    "\n",
    "- The most likely ending state at $ t=2 $ is:\n",
    "$$\n",
    "\\text{argmax}_j \\, \\delta_2(j)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "**Step 4: Backtracking**\n",
    "\n",
    "- Trace back through the backpointer table to find the most likely sequence $ X_1, X_2 $.\n",
    "\n",
    "---\n",
    "\n",
    "**Numerical Example for Viterbi**\n",
    "\n",
    "Using the beliefs and transition/sensor models, the most likely sequence is:\n",
    "$$\n",
    "X_1 = 1, \\, X_2 = 3\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### **Final Answers**\n",
    "\n",
    "1. **Part A (Filtering):**\n",
    "   The belief at $ t=2 $ is:\n",
    "   $$\n",
    "   P(X_2 \\mid E_1, E_2) = [0.5, 0.1, 0.2, 0.05, 0.05, 0.02, 0.03, 0.02, 0.03]\n",
    "   $$\n",
    "\n",
    "2. **Part B (Most Likely Path):**\n",
    "   The most likely sequence of positions is:\n",
    "   $$\n",
    "   X_1 = 1, \\, X_2 = 3\n",
    "   $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a440496-5788-4f9b-a7b0-46e6d1365086",
   "metadata": {},
   "source": [
    "### **Worked Example: Kalman Filter Exam Question**\n",
    "\n",
    "---\n",
    "\n",
    "### **Question**\n",
    "\n",
    "A car is traveling along a straight road, and its state at time $ t $ is represented by:\n",
    "$$\n",
    "X_t = \\begin{bmatrix} x_t \\\\ \\dot{x}_t \\end{bmatrix},\n",
    "$$\n",
    "where $ x_t $ is the position and $ \\dot{x}_t $ is the velocity. The car's motion and observations are described as follows:\n",
    "\n",
    "1. **Transition Model**:\n",
    "   The car’s position and velocity evolve according to the linear motion model:\n",
    "   $$\n",
    "   X_{t+1} = F X_t + w_t, \\quad w_t \\sim \\mathcal{N}(0, Q),\n",
    "   $$\n",
    "   where $ F = \\begin{bmatrix} 1 & \\Delta t \\\\ 0 & 1 \\end{bmatrix} $, $ Q = \\begin{bmatrix} 0.1 & 0 \\\\ 0 & 0.1 \\end{bmatrix} $, and $ \\Delta t = 1 $.\n",
    "\n",
    "2. **Sensor Model**:\n",
    "   The car's position is observed with noise:\n",
    "   $$\n",
    "   Z_t = H X_t + v_t, \\quad v_t \\sim \\mathcal{N}(0, R),\n",
    "   $$\n",
    "   where $ H = \\begin{bmatrix} 1 & 0 \\end{bmatrix} $ and $ R = 0.5 $.\n",
    "\n",
    "3. **Initial State**:\n",
    "   The car starts with:\n",
    "   $$\n",
    "   X_0 = \\begin{bmatrix} 0 \\\\ 20 \\end{bmatrix}, \\quad P_0 = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}.\n",
    "   $$\n",
    "\n",
    "4. **Observations**:\n",
    "   At $ t=1 $, the observed position is $ Z_1 = 25.5 $.\n",
    "   At $ t=2 $, the observed position is $ Z_2 = 45.2 $.\n",
    "\n",
    "**Tasks:**\n",
    "1. Perform the **Prediction** and **Update** steps of the Kalman Filter for $ t=1 $.\n",
    "2. Compute the predicted state and covariance for $ t=2 $ after the second observation.\n",
    "\n",
    "---\n",
    "\n",
    "### **Worked Solution**\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 1: Prediction for $ t=1 $**\n",
    "\n",
    "The prediction step uses the transition model:\n",
    "$$\n",
    "X_{t+1}^\\text{pred} = F X_t, \\quad P_{t+1}^\\text{pred} = F P_t F^\\top + Q.\n",
    "$$\n",
    "\n",
    "1. **State Prediction**:\n",
    "   $$\n",
    "   X_1^\\text{pred} = F X_0 = \\begin{bmatrix} 1 & 1 \\\\ 0 & 1 \\end{bmatrix} \\begin{bmatrix} 0 \\\\ 20 \\end{bmatrix} = \\begin{bmatrix} 20 \\\\ 20 \\end{bmatrix}.\n",
    "   $$\n",
    "\n",
    "2. **Covariance Prediction**:\n",
    "   $$\n",
    "   P_1^\\text{pred} = F P_0 F^\\top + Q = \\begin{bmatrix} 1 & 1 \\\\ 0 & 1 \\end{bmatrix} \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix} \\begin{bmatrix} 1 & 0 \\\\ 1 & 1 \\end{bmatrix} + \\begin{bmatrix} 0.1 & 0 \\\\ 0 & 0.1 \\end{bmatrix}.\n",
    "   $$\n",
    "   $$\n",
    "   P_1^\\text{pred} = \\begin{bmatrix} 2.1 & 1 \\\\ 1 & 1.1 \\end{bmatrix}.\n",
    "   $$\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 2: Update for $ t=1 $**\n",
    "\n",
    "The update step incorporates the observation $ Z_1 = 25.5 $ using the Kalman Gain:\n",
    "$$\n",
    "K_1 = P_1^\\text{pred} H^\\top (H P_1^\\text{pred} H^\\top + R)^{-1}.\n",
    "$$\n",
    "\n",
    "1. **Kalman Gain**:\n",
    "   $$\n",
    "   K_1 = \\begin{bmatrix} 2.1 & 1 \\\\ 1 & 1.1 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} \\big( \\begin{bmatrix} 1 & 0 \\end{bmatrix} \\begin{bmatrix} 2.1 & 1 \\\\ 1 & 1.1 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} + 0.5 \\big)^{-1}.\n",
    "   $$\n",
    "   $$\n",
    "   K_1 = \\begin{bmatrix} 2.1 \\\\ 1 \\end{bmatrix} \\big( 2.1 + 0.5 \\big)^{-1} = \\begin{bmatrix} 2.1 \\\\ 1 \\end{bmatrix} \\cdot 0.4 = \\begin{bmatrix} 0.84 \\\\ 0.4 \\end{bmatrix}.\n",
    "   $$\n",
    "\n",
    "2. **State Update**:\n",
    "   $$\n",
    "   X_1^\\text{update} = X_1^\\text{pred} + K_1 (Z_1 - H X_1^\\text{pred}).\n",
    "   $$\n",
    "   $$\n",
    "   X_1^\\text{update} = \\begin{bmatrix} 20 \\\\ 20 \\end{bmatrix} + \\begin{bmatrix} 0.84 \\\\ 0.4 \\end{bmatrix} (25.5 - \\begin{bmatrix} 1 & 0 \\end{bmatrix} \\begin{bmatrix} 20 \\\\ 20 \\end{bmatrix}).\n",
    "   $$\n",
    "   $$\n",
    "   X_1^\\text{update} = \\begin{bmatrix} 20 \\\\ 20 \\end{bmatrix} + \\begin{bmatrix} 0.84 \\\\ 0.4 \\end{bmatrix} (25.5 - 20) = \\begin{bmatrix} 20 \\\\ 20 \\end{bmatrix} + \\begin{bmatrix} 4.62 \\\\ 2.2 \\end{bmatrix} = \\begin{bmatrix} 24.62 \\\\ 22.2 \\end{bmatrix}.\n",
    "   $$\n",
    "\n",
    "3. **Covariance Update**:\n",
    "   $$\n",
    "   P_1^\\text{update} = (I - K_1 H) P_1^\\text{pred}.\n",
    "   $$\n",
    "   $$\n",
    "   P_1^\\text{update} = (\\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix} - \\begin{bmatrix} 0.84 \\\\ 0.4 \\end{bmatrix} \\begin{bmatrix} 1 & 0 \\end{bmatrix}) \\begin{bmatrix} 2.1 & 1 \\\\ 1 & 1.1 \\end{bmatrix}.\n",
    "   $$\n",
    "   $$\n",
    "   P_1^\\text{update} = \\begin{bmatrix} 0.16 & 0 \\\\ 0 & 0.6 \\end{bmatrix}.\n",
    "   $$\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 3: Prediction for $ t=2 $**\n",
    "\n",
    "Use the updated state from $ t=1 $ to predict the state at $ t=2 $:\n",
    "1. **State Prediction**:\n",
    "   $$\n",
    "   X_2^\\text{pred} = F X_1^\\text{update} = \\begin{bmatrix} 1 & 1 \\\\ 0 & 1 \\end{bmatrix} \\begin{bmatrix} 24.62 \\\\ 22.2 \\end{bmatrix} = \\begin{bmatrix} 46.82 \\\\ 22.2 \\end{bmatrix}.\n",
    "   $$\n",
    "\n",
    "2. **Covariance Prediction**:\n",
    "   $$\n",
    "   P_2^\\text{pred} = F P_1^\\text{update} F^\\top + Q = \\begin{bmatrix} 1 & 1 \\\\ 0 & 1 \\end{bmatrix} \\begin{bmatrix} 0.16 & 0 \\\\ 0 & 0.6 \\end{bmatrix} \\begin{bmatrix} 1 & 0 \\\\ 1 & 1 \\end{bmatrix} + \\begin{bmatrix} 0.1 & 0 \\\\ 0 & 0.1 \\end{bmatrix}.\n",
    "   $$\n",
    "   $$\n",
    "   P_2^\\text{pred} = \\begin{bmatrix} 0.86 & 0.6 \\\\ 0.6 & 0.7 \\end{bmatrix}.\n",
    "   $$\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 4: Update for $ t=2 $**\n",
    "\n",
    "Repeat the update step with $ Z_2 = 45.2 $:\n",
    "1. **Kalman Gain**:\n",
    "   $$\n",
    "   K_2 = P_2^\\text{pred} H^\\top (H P_2^\\text{pred} H^\\top + R)^{-1}.\n",
    "   $$\n",
    "   $$\n",
    "   K_2 = \\begin{bmatrix} 0.86 \\\\ 0.6 \\end{bmatrix} \\big(0.86 + 0.5\\big)^{-1} = \\begin{bmatrix} 0.86 \\\\ 0.6 \\end{bmatrix} \\cdot 0.7 = \\begin{bmatrix} 0.602 \\\\ 0.42 \\end{bmatrix}.\n",
    "   $$\n",
    "\n",
    "2. **State Update**:\n",
    "   $$\n",
    "   X_2^\\text{update} = X_2^\\text{pred} + K_2 (Z_2 - H X_2^\\text{pred}).\n",
    "   $$\n",
    "   $$\n",
    "   X_2^\\text{update} = \\begin{bmatrix} 46.82 \\\\ 22.2 \\end{bmatrix} + \\begin{bmatrix} 0.602 \\\\ 0.42 \\end{bmatrix} (45.2 - 46.82).\n",
    "   $$\n",
    "   $$\n",
    "   X_2^\\text{update} = \\begin{bmatrix} 46.82 \\\\ 22.2 \\end{bmatrix} + \\begin{bmatrix} -0.963 \\\\ -0.672 \\end{bmatrix} = \\begin{bmatrix} 45.86 \\\\ 21.53 \\end{bmatrix}.\n",
    "   $$\n",
    "\n",
    "---\n",
    "\n",
    "### **Final Answer**\n",
    "\n",
    "1. After $ t=1 $:\n",
    "   - $ X_1^\\text{update} = \\begin{bmatrix} 24.62 \\\\ 22.2 \\end{bmatrix} $,\n",
    "   - $ P_1^\\text{update} = \\begin{bmatrix} 0.16 & 0 \\\\ 0 & 0.6 \\end{bmatrix} $.\n",
    "\n",
    "2. After $ t=2 $:\n",
    "   - $ X_2^\\text{update} = \\begin{bmatrix} 45.86 \\\\ 21.53 \\end{bmatrix} $,\n",
    "   - $ P_2^\\text{update} = \\begin{bmatrix} 0.3 & 0 \\\\ 0 & 0.5 \\end{bmatrix} $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f6617c-b47c-440e-8cba-75f9780313ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
