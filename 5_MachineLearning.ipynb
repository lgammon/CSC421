{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23b000ec",
   "metadata": {},
   "source": [
    "## **Chapter 19: Learning from Examples**\n",
    "\n",
    "---\n",
    "\n",
    "#### **19.1 Forms of Learning**\n",
    "- **Overview**:\n",
    "  - Learning improves an agent’s performance by deriving patterns from data.\n",
    "  - Types of learning:\n",
    "    - **Supervised Learning**: Learns from labeled data (input-output pairs).\n",
    "    - **Unsupervised Learning**: Finds patterns without explicit labels (e.g., clustering).\n",
    "    - **Reinforcement Learning**: Learns optimal actions based on rewards or punishments.\n",
    "- **Key Features**:\n",
    "  - Components of learning include mapping conditions to actions, inferring properties, utility maximization, and adapting goals.\n",
    "\n",
    "---\n",
    "\n",
    "#### **19.2 Supervised Learning**\n",
    "- **Definition**:\n",
    "  - Uses labeled training data to discover a function (hypothesis) that maps inputs to outputs.\n",
    "- **Hypothesis Space**:\n",
    "  - Defines the set of all possible functions the learning algorithm considers.\n",
    "  - Good hypotheses generalize well to unseen data, evaluated on a separate test set.\n",
    "- **Bias-Variance Tradeoff**:\n",
    "  - Balances complexity (bias) and adaptability to data (variance) to avoid underfitting or overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "#### **19.3 Learning Decision Trees**\n",
    "- **Structure**:\n",
    "  - Decision trees represent functions as a series of tests (e.g., “if-then” rules).\n",
    "- **Algorithm**:\n",
    "  - Uses a divide-and-conquer approach to recursively split data based on the most informative attribute (measured by information gain).\n",
    "- **Pruning**:\n",
    "  - Reduces overfitting by simplifying trees, often guided by statistical significance tests.\n",
    "- **Extensions**:\n",
    "  - Can handle missing data, continuous attributes, and regression problems.\n",
    "\n",
    "---\n",
    "\n",
    "#### **19.4 Model Selection and Optimization**\n",
    "- **Model Selection**:\n",
    "  - Chooses the best hypothesis or model based on validation data, often using cross-validation.\n",
    "- **Hyperparameter Tuning**:\n",
    "  - Adjusts parameters controlling the model complexity using grid search, random search, or Bayesian optimization.\n",
    "- **Regularization**:\n",
    "  - Adds a penalty for model complexity to prevent overfitting.\n",
    "- **Loss Functions**:\n",
    "  - Quantify prediction errors; common types include absolute error (L1) and squared error (L2).\n",
    "\n",
    "---\n",
    "\n",
    "#### **19.5 Generalization and Overfitting**\n",
    "- **Concepts**:\n",
    "  - Generalization is the ability of a model to perform well on unseen data.\n",
    "  - Overfitting occurs when a model fits the training data too closely, capturing noise rather than patterns.\n",
    "- **Techniques**:\n",
    "  - Pruning and regularization mitigate overfitting.\n",
    "  - Learning curves assess the impact of training size on performance.\n",
    "\n",
    "---\n",
    "\n",
    "#### **19.6 Summary**\n",
    "- **Key Takeaways**:\n",
    "  - Machine learning enables systems to improve their performance by learning from data.\n",
    "  - Supervised learning relies on labeled data, while unsupervised learning identifies hidden structures.\n",
    "  - Decision trees, model selection, and regularization are essential tools for building robust learning systems.\n",
    "- **Applications**:\n",
    "  - Machine learning is widely used in recommendation systems, natural language processing, and autonomous driving.\n",
    "\n",
    "Let me know if you'd like further details or clarification on any section!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4169f43c-84ac-4087-b9b9-ff0b035691b2",
   "metadata": {},
   "source": [
    "Here’s an explanation of the terms EBL, RBL, KBIL, and ILP and how they contribute to learning systems:\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Explanation-Based Learning (EBL)**\n",
    "- **What It Is**:\n",
    "  - A deductive learning method that uses prior knowledge to analyze a specific example and extract general rules from it.\n",
    "- **How It Works**:\n",
    "  - Given an example, the system:\n",
    "    1. Explains the example using its prior knowledge.\n",
    "    2. Generalizes the explanation into a rule applicable to similar examples.\n",
    "- **Key Feature**:\n",
    "  - EBL focuses on understanding *why* an example is a valid instance of a concept, enabling it to create efficient, task-specific rules.\n",
    "- **Example**:\n",
    "  - A robot learns how to stack blocks by analyzing a successful stacking instance, deriving rules for stability, and applying them to new scenarios.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Relevance-Based Learning (RBL)**\n",
    "- **What It Is**:\n",
    "  - A learning method that identifies and focuses on the most relevant attributes in a dataset, reducing complexity.\n",
    "- **How It Works**:\n",
    "  - Uses prior knowledge to filter out irrelevant attributes, simplifying the hypothesis space.\n",
    "- **Key Feature**:\n",
    "  - RBL improves efficiency by focusing only on key variables that influence the outcome.\n",
    "- **Example**:\n",
    "  - In a medical diagnosis system, RBL identifies that certain symptoms (e.g., fever and rash) are more relevant than others (e.g., eye color) for diagnosing a disease.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Knowledge-Based Inductive Learning (KBIL)**\n",
    "- **What It Is**:\n",
    "  - Combines **inductive reasoning** (learning patterns from data) with **background knowledge** to refine hypotheses.\n",
    "- **How It Works**:\n",
    "  - The system generates hypotheses that are:\n",
    "    1. Consistent with the observed data.\n",
    "    2. Informed by prior knowledge, ensuring they align with known truths.\n",
    "- **Key Feature**:\n",
    "  - KBIL bridges inductive generalization (finding patterns) with deductive reasoning (ensuring consistency with prior knowledge).\n",
    "- **Example**:\n",
    "  - A weather forecasting system uses historical weather data (induction) and physical models of the atmosphere (background knowledge) to predict future weather patterns.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Inductive Logic Programming (ILP)**\n",
    "- **What It Is**:\n",
    "  - A specialized form of KBIL that uses **first-order logic** to represent knowledge and hypotheses, enabling reasoning about relationships between objects.\n",
    "- **How It Works**:\n",
    "  - ILP generates relational rules, moving beyond simple attribute-value mappings.\n",
    "  - Uses two approaches:\n",
    "    - **Top-Down**: Starts with a general rule and specializes it using data.\n",
    "    - **Bottom-Up**: Begins with specific observations and generalizes them into a rule.\n",
    "- **Key Feature**:\n",
    "  - ILP is particularly effective for relational and structured data.\n",
    "- **Example**:\n",
    "  - In bioinformatics, ILP identifies relationships between chemical structures and biological activity, such as rules linking molecular features to toxicity.\n",
    "\n",
    "---\n",
    "\n",
    "### **Why These Techniques Matter**\n",
    "- **Domain-Specific Knowledge**:\n",
    "  - These techniques integrate knowledge about the domain (e.g., physics, biology) into learning systems, allowing for more accurate and meaningful generalizations.\n",
    "- **Efficiency**:\n",
    "  - By using prior knowledge, these methods reduce the hypothesis space, speeding up learning.\n",
    "- **Applications**:\n",
    "  - Automated scientific discovery, medical diagnostics, natural language understanding, and robotics.\n",
    "\n",
    "Let me know if you’d like to delve deeper into any of these techniques!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e77d1e-dbe6-400e-970f-f528ca8520ad",
   "metadata": {},
   "source": [
    "Here's a detailed table summarizing Section 19.1 from Chapter 19 of the uploaded file, accompanied by examples and code snippets to enhance understanding:\n",
    "\n",
    "### **Table: Summary of Section 19.1 - Forms of Learning**\n",
    "\n",
    "| **Aspect**                         | **Details**                                                                                                                                           | **Definitions & Equations**                                                                                                                                                                                                                                                     | **Examples**                                                                                                  |\n",
    "|------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------|\n",
    "| **Learning Objective**             | Improve agent performance through observations of the world.                                                                                         | - **Machine Learning**: Computer learning from data to form models that solve problems.                                                                                                                                                  | **Example**: A self-driving car learns to brake in wet conditions by observing human drivers.              |\n",
    "| **Why Machine Learning?**          | - Cannot pre-program solutions for all scenarios.                                                                                                   | - **Induction**: From observations, derive general rules. $$ E.g., sun rising each day → generalization: the sun will rise tomorrow. $$                                                                                                   | **Stock Prediction**: Learn to adapt from boom to bust markets.                                           |\n",
    "| **Components of Agent Learning**   | Seven components that can be improved through learning:                                                                                             | - **Direct Mapping**: Conditions to actions. <br> - **Inference**: From perceptions to world properties. <br> - **Utility Info**: Desirability of states. <br> - **Action-Value Info**: Desirability of actions. <br> - **Goals**: Desirable states.                            | **Car Example**: Learning braking conditions (mapping), recognizing buses from camera images (inference). |\n",
    "| **Types of Learning**              | - Classification: Finite set of output values (e.g., sunny/cloudy). <br> - Regression: Numerical output values.                                       | **Classification**: Maps to discrete outputs. **Regression**: Numerical or real values. <br> **Equation**: $$ h(x) ≈ f(x) $$ where $ h(x) $ is the hypothesis, $ f(x) $ is the target function.                                                                             | **Classification**: Predict rain or sun tomorrow. **Regression**: Predict temperature value tomorrow.     |\n",
    "| **Feedback Types**                 | - **Supervised Learning**: Learn function from input-output pairs. <br> - **Unsupervised Learning**: Detect patterns. <br> - **Reinforcement Learning**: Learn from rewards/punishments. | **Supervised**: Output is labeled (e.g., \"bus\" vs. \"pedestrian\"). <br> **Unsupervised**: Clustering without labels. <br> **Reinforcement**: Determine actions leading to rewards.                                                                                             | **Supervised**: Image classification for \"cat.\" <br> **Unsupervised**: Clustering animals by similarity.  |\n",
    "\n",
    "---\n",
    "\n",
    "### **Example Explanation**\n",
    "\n",
    "#### **Example: A Self-Driving Car**\n",
    "A self-driving car learns through machine learning by observing human drivers. When braking hard on wet roads, it records the result (sliding or stopping) and adjusts its actions for better performance in future instances. Over time, the car learns an optimal stopping distance for various road conditions, improving its utility.\n",
    "\n",
    "#### **Code Snippet**\n",
    "\n",
    "Here is a Python example of supervised learning using a decision tree to classify whether to wait for a table at a restaurant (concept introduced in Section 19.3):\n",
    "\n",
    "```python\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Example training data (simplified from restaurant example)\n",
    "# Features: [Alternate, Bar, Hungry]\n",
    "# Labels: 1 = Will Wait, 0 = Won't Wait\n",
    "X_train = np.array([\n",
    "    [1, 0, 1],\n",
    "    [1, 1, 0],\n",
    "    [0, 1, 1],\n",
    "    [0, 0, 0]\n",
    "])\n",
    "y_train = np.array([1, 1, 0, 0])\n",
    "\n",
    "# Create and train decision tree classifier\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict for new data\n",
    "X_test = np.array([[0, 1, 0]])  # Test input\n",
    "prediction = model.predict(X_test)\n",
    "print(\"Will Wait\" if prediction[0] == 1 else \"Won't Wait\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "This table and explanation provide a foundational understanding of learning types and processes, supplemented with a practical example and code demonstration. Let me know if you need further sections summarized or deeper insights!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cb1841-0a8b-404e-98bd-0c377cac3881",
   "metadata": {},
   "source": [
    "Here's an in-depth table summarizing Section 19.2 (Supervised Learning) from the uploaded document, complete with definitions, equations, and a worked example with a code snippet.\n",
    "\n",
    "---\n",
    "\n",
    "### **Table: Summary of Section 19.2 - Supervised Learning**\n",
    "\n",
    "| **Aspect**                         | **Details**                                                                                                                                  | **Definitions & Equations**                                                                                                                                                                                                                                     | **Examples**                                                                                                 |\n",
    "|------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------|\n",
    "| **Definition**                     | Supervised learning involves learning a function $ h(x) $ that maps input $ x $ to output $ y $ using labeled training data.           | **Training Set**: $ \\{(x_1, y_1), (x_2, y_2), \\ldots, (x_N, y_N)\\} $, where $ y = f(x) $. <br> **Hypothesis ($ h $)**: Approximation of $ f $.                                                                                 | **Image Classification**: Predict if an image contains a cat (output: \"cat\" or \"no cat\").                   |\n",
    "| **Goal**                           | Minimize error on unseen test data by finding the hypothesis $ h $ that best approximates the true function $ f $.                       | **Equation**: $ h^* = \\text{argmin}_h \\, \\text{Error}(h) $, where $\\text{Error}(h)$ is measured on unseen test data.                                                                                                                  | **Regression**: Predict house prices based on size, location, etc.                                         |\n",
    "| **Hypothesis Space**               | The set of all possible functions $ h $ that the learning algorithm can select from.                                                       | **Example**: Linear hypothesis space ($ h(x) = w_1 x + w_0 $). <br> **Equation**: $ h \\in H $, where $ H $ is the hypothesis space.                                                                                                    | **Linear Regression**: $ h(x) = w_1 x + w_0 $, where $ w_1, w_0 $ are learned from data.               |\n",
    "| **Evaluation Metrics**             | Evaluate hypothesis $ h $ using a separate test set. The ability to generalize to unseen data is crucial.                                 | **Test Set**: Separate data for evaluation. <br> **Generalization**: Ability of $ h $ to perform well on unseen test data.                                                                                                                | **Validation Split**: Use 80% of data for training, 20% for testing.                                       |\n",
    "| **Types of Outputs**               | - **Classification**: Output $ y $ belongs to a finite set of classes. <br> - **Regression**: Output $ y $ is a real-valued number.      | **Classification**: $ y \\in \\{C_1, C_2, \\ldots, C_k\\} $. <br> **Regression**: $ y \\in \\mathbb{R} $.                                                                                                                              | **Classification**: True/False. <br> **Regression**: Predicting temperature tomorrow.                      |\n",
    "| **Learning Process**               | - Define hypothesis space $ H $. <br> - Choose the best hypothesis $ h $ by minimizing training error.                                  | **Training Error**: Error of $ h $ on training data. <br> **Test Error**: Error of $ h $ on unseen test data. <br> **Generalization**: $ h $ performs well on unseen data.                                                          | **Decision Trees**: Learn rules like \"if condition A, then output B.\"                                      |\n",
    "| **Example Problem**                | Predict if a customer will wait for a table at a restaurant based on attributes like waiting time, day, and weather.                        | Attributes: $ x $ includes factors like \"Wait Time,\" \"Day,\" and \"Raining.\" <br> Output: $ y $ is True (will wait) or False (won't wait).                                                                                               | **Training Example**: Input: $ \\text{Day = Friday, Wait Time = 30 min} $; Output: True.                  |\n",
    "| **Key Concepts**                   | **Overfitting**: $ h $ fits training data too closely, failing to generalize. <br> **Underfitting**: $ h $ fails to capture the data patterns. | **Bias-Variance Tradeoff**: Balance between overfitting and underfitting. <br> **Equation**: $ \\text{Error} = \\text{Bias}^2 + \\text{Variance} + \\text{Irreducible Error} $.                                                                 | **Overfitting**: Polynomial model with excessive degree. <br> **Underfitting**: Simple linear model.       |\n",
    "\n",
    "---\n",
    "\n",
    "### **Example Explanation**\n",
    "\n",
    "#### **Scenario: Restaurant Waiting Problem**\n",
    "- **Problem**: Predict whether a customer will wait for a table at a restaurant based on attributes such as wait time, weather, and reservation status.\n",
    "- **Attributes (Input, $ x $)**:  \n",
    "  - Wait Time: 30–60 min.  \n",
    "  - Raining: Yes.  \n",
    "  - Reservation: No.  \n",
    "- **Output (Label, $ y $)**: True (customer will wait).\n",
    "\n",
    "The goal is to use supervised learning to predict $ y $ for new inputs $ x $.\n",
    "\n",
    "---\n",
    "\n",
    "### **Code Snippet: Supervised Learning with Decision Trees**\n",
    "\n",
    "Here is Python code using a decision tree to solve the restaurant waiting problem:\n",
    "\n",
    "```python\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Training data (simplified)\n",
    "# Features: [WaitTime (0: 0-10, 1: 10-30, 2: 30-60, 3: >60), Raining (0: No, 1: Yes), Reservation (0: No, 1: Yes)]\n",
    "# Labels: 1 = Will Wait, 0 = Won't Wait\n",
    "X_train = np.array([\n",
    "    [0, 0, 1],  # 0-10 min, No rain, Reservation made\n",
    "    [2, 1, 0],  # 30-60 min, Raining, No reservation\n",
    "    [1, 0, 0],  # 10-30 min, No rain, No reservation\n",
    "    [3, 1, 1],  # >60 min, Raining, Reservation made\n",
    "])\n",
    "y_train = np.array([1, 0, 0, 1])  # Labels\n",
    "\n",
    "# Initialize decision tree classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict for new data\n",
    "X_test = np.array([[2, 1, 0]])  # 30-60 min, Raining, No reservation\n",
    "prediction = clf.predict(X_test)\n",
    "print(\"Will Wait\" if prediction[0] == 1 else \"Won't Wait\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Output of Code**\n",
    "For the test input $[2, 1, 0]$ (30-60 min, Raining, No reservation), the model predicts:  \n",
    "**Output**: \"Won't Wait.\"\n",
    "\n",
    "---\n",
    "\n",
    "This table and explanation cover key aspects of Section 19.2, with detailed examples and a practical code demonstration to reinforce the concepts. Let me know if you want further elaboration or another example!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e985d036-623a-4e2f-987b-416462be6bd5",
   "metadata": {},
   "source": [
    "Here’s an in-depth summary of Section 19.3 (Learning Decision Trees) organized into a detailed table. It includes definitions, equations, examples, and a code snippet to complement the explanation.\n",
    "\n",
    "---\n",
    "\n",
    "### **Table: Summary of Section 19.3 - Learning Decision Trees**\n",
    "\n",
    "| **Aspect**                         | **Details**                                                                                                                                               | **Definitions & Equations**                                                                                                                                                                                                                                                                     | **Examples**                                                                                             |\n",
    "|------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------|\n",
    "| **Definition**                     | A decision tree is a structure used to represent a function mapping input attributes to an output (decision).                                             | **Decision Tree**: Recursive partitioning of data using attribute-based splits to reach a classification or regression outcome. <br> **Nodes**: Decision points in the tree. <br> **Leaves**: Terminal nodes containing the output value.                                                        | **Example**: Predict whether a customer will wait for a restaurant table based on input attributes.     |\n",
    "| **Components**                     | - Root Node: The starting point of the tree. <br> - Branches: Possible values for the attributes being tested. <br> - Leaf Nodes: Contain output values. | - **Path**: A conjunction of attribute-value pairs from root to leaf. <br> **Equation**: $ \\text{Output} \\iff (\\text{Path}_1 \\lor \\text{Path}_2 \\lor \\ldots) $, where $ \\text{Path}_i = (\\text{Attr}_1 = v_1 \\land \\text{Attr}_2 = v_2 \\land \\ldots) $.                                           | **Path Example**: $ \\text{If Patrons = Full} \\land \\text{WaitTime} = \\text{10-30 min}, \\text{then Yes} $. |\n",
    "| **Learning Algorithm**             | Decision trees are learned using a greedy divide-and-conquer algorithm (e.g., ID3, CART).                                                                 | **Algorithm Steps**: 1. Select the most important attribute to split the data (maximize information gain). <br> 2. Partition the data. <br> 3. Recursively build subtrees until all data is classified or stopping criteria is met.                                                                 | **Split Example**: First split on \"Patrons,\" then split on \"WaitTime.\"                                 |\n",
    "| **Information Gain**               | Used to select the best attribute for splitting the data.                                                                                                 | **Entropy**: $ H(V) = -\\sum P(v_k) \\log_2 P(v_k) $. <br> **Information Gain**: $ \\text{Gain}(A) = H(\\text{Output}) - \\text{Remainder}(A) $, where $ \\text{Remainder}(A) = \\sum \\frac{p_k + n_k}{p + n} B\\left(\\frac{p_k}{p_k + n_k}\\right) $.                                                 | **Attribute Example**: \"Patrons\" gives highest information gain in the restaurant problem.             |\n",
    "| **Overfitting & Pruning**          | Decision trees can overfit the training data if they are too complex. Pruning reduces this risk.                                                          | **Pruning**: Simplifies the tree by removing branches that have low information gain or are statistically insignificant. <br> **Significance Test**: Chi-square ($ \\chi^2 $) can be used to prune branches that don't improve classification accuracy.                                          | **Overfitting**: A tree that memorizes training data patterns.                                          |\n",
    "| **Generalization**                 | The goal of a decision tree is to generalize well on unseen data by finding patterns in the training data.                                                | **Overfitting**: Model too complex to generalize well. <br> **Underfitting**: Model too simple to capture patterns. <br> **Bias-Variance Tradeoff**: Balance model complexity to minimize test error.                                                                                             | **Example**: Overfitting occurs if the tree has a branch for every unique input in the training set.    |\n",
    "| **Broadening Applicability**       | - Handle missing data by ignoring certain attributes. <br> - Use split points for continuous attributes. <br> - Handle multi-valued attributes effectively. | - **Split Points**: E.g., test $ \\text{Weight} > 160 $. <br> **Regression Tree**: Predict continuous outputs instead of classes. <br> **CART**: Combines classification and regression tree approaches.                                                                                         | **Example**: Predict house prices using square footage and number of bathrooms.                        |\n",
    "\n",
    "---\n",
    "\n",
    "### **Example Explanation**\n",
    "\n",
    "#### **Scenario: Restaurant Waiting Problem**\n",
    "The problem is to decide whether a customer will wait for a table at a restaurant based on attributes like the number of patrons, wait time, and reservation status. A decision tree is learned from training data, splitting on attributes with the highest information gain to create decision rules.\n",
    "\n",
    "#### **Decision Tree for the Example**\n",
    "\n",
    "**Training Data:**\n",
    "| Patrons     | WaitEstimate | WillWait |\n",
    "|-------------|--------------|----------|\n",
    "| None        | 0-10 min     | No       |\n",
    "| Full        | 10-30 min    | Yes      |\n",
    "| Some        | 0-10 min     | Yes      |\n",
    "| Full        | 30-60 min    | No       |\n",
    "\n",
    "**Derived Decision Tree**:\n",
    "1. Split on \"Patrons.\"\n",
    "   - If $ \\text{Patrons} = \\text{None} $, $ \\text{WillWait} = \\text{No} $.\n",
    "   - If $ \\text{Patrons} = \\text{Some} $, $ \\text{WillWait} = \\text{Yes} $.\n",
    "   - If $ \\text{Patrons} = \\text{Full} $, split further on \"WaitEstimate.\"\n",
    "     - If $ \\text{WaitEstimate} = \\text{10-30 min} $, $ \\text{WillWait} = \\text{Yes} $.\n",
    "     - If $ \\text{WaitEstimate} = \\text{30-60 min} $, $ \\text{WillWait} = \\text{No} $.\n",
    "\n",
    "---\n",
    "\n",
    "### **Code Snippet: Decision Tree Example**\n",
    "\n",
    "Below is a Python code example using `scikit-learn` to create a decision tree for the restaurant waiting problem:\n",
    "\n",
    "```python\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Training data\n",
    "# Features: [Patrons (0: None, 1: Some, 2: Full), WaitEstimate (0: 0-10, 1: 10-30, 2: 30-60)]\n",
    "# Labels: 1 = Will Wait, 0 = Won't Wait\n",
    "X_train = np.array([\n",
    "    [0, 0],  # None, 0-10 min\n",
    "    [2, 1],  # Full, 10-30 min\n",
    "    [1, 0],  # Some, 0-10 min\n",
    "    [2, 2]   # Full, 30-60 min\n",
    "])\n",
    "y_train = np.array([0, 1, 1, 0])  # Labels\n",
    "\n",
    "# Create and train decision tree\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Test data\n",
    "X_test = np.array([[2, 1]])  # Full, 10-30 min\n",
    "prediction = clf.predict(X_test)\n",
    "\n",
    "# Output prediction\n",
    "print(\"Will Wait\" if prediction[0] == 1 else \"Won't Wait\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Output of Code**\n",
    "For the test input $[2, 1]$ (Patrons = Full, WaitEstimate = 10-30 min), the model predicts:  \n",
    "**Output**: \"Will Wait.\"\n",
    "\n",
    "---\n",
    "\n",
    "This detailed table and explanation capture the key points of Section 19.3, providing a comprehensive understanding of decision trees, complete with theoretical and practical examples. Let me know if you need additional clarification!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15090ff8-f9d4-45f4-9d53-43b6b4c4e6f0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **Table: Summary of Section 19.7 - Nonparametric Models**\n",
    "\n",
    "| **Aspect**                         | **Details**                                                                                                   | **Definitions**                                                                                                                                                                                                                               | **Examples**                                                                                             |\n",
    "|------------------------------------|---------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------|\n",
    "| **Definition**                     | Nonparametric models predict directly from the data without assuming a fixed form for the target function.    | Nonparametric models do not assume a predetermined number of parameters. The complexity grows with the dataset size.                                                                                                                       | Predicting house prices using nearby house prices as reference points.                                  |\n",
    "| **Nearest Neighbors Algorithm**    | Predicts a label by finding the closest $k$ examples in the training data and using their labels.            | In $k$-Nearest Neighbors (k-NN), the label of a new point is determined by the majority vote (classification) or the average of the labels (regression) of its $k$ closest neighbors.                                                   | Predict if a customer will wait for a table based on similar past customers.                           |\n",
    "| **Kernel Machines**                | Use a kernel function to weigh the influence of training data points when predicting a new point.             | A kernel function measures similarity between points. Common kernels include the Gaussian (RBF), which assigns greater influence to closer points.                                                                                         | Classifying handwritten digits by weighing the influence of visually similar digits.                   |\n",
    "| **Advantages**                     | - No assumptions about the data distribution. <br> - Adapts to data complexity as the dataset grows.          | Nonparametric models like k-NN can model both linear and non-linear relationships without needing explicit feature engineering.                                                                                                              | k-NN can model both straight-line and complex boundaries automatically.                                |\n",
    "| **Disadvantages**                  | - Computationally expensive for large datasets. <br> - Sensitive to irrelevant features and noise.             | Nonparametric models are affected by the curse of dimensionality, where the effectiveness of distance metrics deteriorates as the number of features increases.                                                                              | High-dimensional image data can make \"nearest\" neighbors unreliable.                                   |\n",
    "| **Applications**                   | Widely used in classification and regression problems with unknown or complex relationships between variables. | Common applications include recommender systems, image recognition, and anomaly detection.                                                                                                                                                   | Using k-NN to detect credit card fraud based on past transaction patterns.                             |\n",
    "| **Improvements**                   | - Use efficient data structures for faster nearest neighbor search. <br> - Reduce dimensionality of features. | KD-trees and Ball trees can accelerate nearest neighbor search. Dimensionality reduction techniques like PCA can improve computational efficiency and model accuracy.                                                                        | Compress image data with PCA before applying k-NN.                                                     |\n",
    "\n",
    "---\n",
    "\n",
    "### **Equations**\n",
    "\n",
    "1. **Distance Metric**:  \n",
    "   The Euclidean distance between two points $x_1$ and $x_2$ is calculated as:  \n",
    "   $$\n",
    "   \\text{Distance}(x_1, x_2) = \\sqrt{\\sum_{i=1}^n (x_{1i} - x_{2i})^2}\n",
    "   $$\n",
    "\n",
    "2. **Kernel Function**:  \n",
    "   The Gaussian (RBF) kernel assigns weights to points based on their proximity:  \n",
    "   $$\n",
    "   K(x, x') = \\exp\\left(-\\frac{\\|x - x'\\|^2}{2\\sigma^2}\\right)\n",
    "   $$\n",
    "\n",
    "3. **k-NN Prediction**:  \n",
    "   For classification, $k$-NN predicts the most common label among the $k$ closest neighbors. For regression:  \n",
    "   $$\n",
    "   y = \\frac{1}{k} \\sum_{i=1}^k y_i\n",
    "   $$\n",
    "\n",
    "---\n",
    "\n",
    "### **Code Snippet: k-Nearest Neighbors Example**\n",
    "\n",
    "```python\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Training data\n",
    "# Features: [Patrons (0: None, 1: Some, 2: Full), WaitEstimate (0: 0-10, 1: 10-30, 2: 30-60)]\n",
    "# Labels: 1 = Will Wait, 0 = Won't Wait\n",
    "X_train = np.array([\n",
    "    [2, 1],  # Full, 10-30 min\n",
    "    [2, 2],  # Full, 30-60 min\n",
    "    [1, 0],  # Some, 0-10 min\n",
    "    [0, 0]   # None, 0-10 min\n",
    "])\n",
    "y_train = np.array([1, 0, 1, 0])  # Labels\n",
    "\n",
    "# Initialize k-NN classifier with k=3\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Test data\n",
    "X_test = np.array([[2, 0]])  # Full, 0-10 min\n",
    "prediction = knn.predict(X_test)\n",
    "\n",
    "# Output prediction\n",
    "print(\"Will Wait\" if prediction[0] == 1 else \"Won't Wait\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Output of Code**\n",
    "For the test input $[Patrons = Full, WaitEstimate = 0-10 min]$, the model predicts:  \n",
    "**Output**: \"Will Wait.\"\n",
    "\n",
    "---\n",
    "\n",
    "This cleaned-up format should resolve the formatting issue while maintaining clarity and completeness. Let me know if you need additional adjustments!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8d60da-6c48-4b9a-a24f-c51e1a074c89",
   "metadata": {},
   "source": [
    "# **Ch 20**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6649f504-a01e-42d9-86cd-0a421ce0eebd",
   "metadata": {},
   "source": [
    "# Here’s a detailed table summarizing Section 20.1 from the provided document. Below the table is an explanation of the example included in this section.\n",
    "\n",
    "---\n",
    "\n",
    "| **Aspect**                 | **Details**                                                                                                                                                                                                                                                                                    |\n",
    "|----------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Key Terms**              | **Hypothesis**: A logical representation that aims to explain classifications. <br> **False Positive**: Hypothesis incorrectly classifies a negative example as positive. <br> **False Negative**: Hypothesis incorrectly classifies a positive example as negative.                             |\n",
    "| **Equations**              | 1. **Hypothesis Formulation**: $ \\forall x \\, Goal(x) \\iff C_j(x) $, where $C_j(x)$ is the candidate definition. <br> 2. **Resolution Rule for Learning**: Example $I_1$ inconsistent with $h_2, h_3$ leads to $h_1 \\lor h_4$. <br> 3. **Consistency Check**: $ h_1 \\lor h_2 \\lor \\dots h_n $. |\n",
    "| **Logical Rules**          | 1. **Generalization**: Expanding hypothesis scope to include false negatives. Example: $ \\text{Alternate}(x) \\rightarrow \\text{Patrons}(x, \\text{Some}) $. <br> 2. **Specialization**: Restricting hypothesis to exclude false positives. Example: Adding conditions to exclude cases.            |\n",
    "| **Algorithm**              | **CURRENT-BEST-LEARNING** (CBL): Maintains and updates a single hypothesis for consistency with data.                                                                                                                                                                                          |\n",
    "| **Example Description**    | The restaurant learning problem, where attributes like \"Patrons\" and \"Alternate\" describe examples and the hypothesis predicts \"WillWait\".                                                                                                                                                    |\n",
    "| **Concepts of Hypothesis** | A hypothesis predicts positive/negative classifications. Hypotheses with inconsistent extensions are ruled out. Generalization and specialization ensure the hypothesis fits new examples incrementally.                                                                                         |\n",
    "\n",
    "---\n",
    "\n",
    "### Code Snippet for Current-Best-Learning Algorithm:\n",
    "\n",
    "```python\n",
    "def current_best_learning(examples, hypothesis):\n",
    "    if not examples:\n",
    "        return hypothesis\n",
    "    \n",
    "    example = examples[0]\n",
    "    remaining_examples = examples[1:]\n",
    "    \n",
    "    if is_consistent(hypothesis, example):\n",
    "        return current_best_learning(remaining_examples, hypothesis)\n",
    "    elif is_false_positive(hypothesis, example):\n",
    "        for specialization in get_specializations(hypothesis):\n",
    "            new_hypothesis = current_best_learning(remaining_examples, specialization)\n",
    "            if new_hypothesis is not None:\n",
    "                return new_hypothesis\n",
    "    elif is_false_negative(hypothesis, example):\n",
    "        for generalization in get_generalizations(hypothesis):\n",
    "            new_hypothesis = current_best_learning(remaining_examples, generalization)\n",
    "            if new_hypothesis is not None:\n",
    "                return new_hypothesis\n",
    "    return None\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Example Explanation:\n",
    "\n",
    "**Scenario**: A hypothesis $ h_1 $ predicts that people will wait at a restaurant if the attribute \"Alternate\" is true. New examples (positive or negative) are incrementally introduced to test and adjust the hypothesis.\n",
    "\n",
    "1. **Step 1**: $ X_1 $ is a positive example where \"Alternate\" is true. Hypothesis $ h_1 $ holds.\n",
    "2. **Step 2**: $ X_2 $ is a negative example where \"Alternate\" is true, making $ h_1 $ a **false positive**. The hypothesis is specialized by adding conditions (e.g., $ \\text{Patrons} = \\text{Some} $).\n",
    "3. **Step 3**: $ X_3 $ is a positive example with different attributes. The hypothesis generalizes to include this example.\n",
    "\n",
    "This process ensures the hypothesis evolves to fit the training data, while ruling out inconsistent predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ef6508-1012-4579-b277-96fcc8eb20d6",
   "metadata": {},
   "source": [
    "# Here's an in-depth summary of Section 20.2 from the document in table format, accompanied by code snippets and an explanation of examples.\n",
    "\n",
    "---\n",
    "\n",
    "| **Aspect**                  | **Details**                                                                                                                                                                                                                                                                                                                                                   |\n",
    "|-----------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Key Terms**               | **Background Knowledge**: Information already known and used to assist in learning. <br> **Inductive Learning**: Deriving general hypotheses from specific examples. <br> **Knowledge-Based Inductive Learning (KBIL)**: Learning that integrates background knowledge into hypothesis generation. <br> **Entailment Constraint**: Logical requirement that hypotheses explain observations (examples). |\n",
    "| **Equations**               | **Entailment Constraint**: $ \\text{Hypothesis} \\land \\text{Descriptions} \\models \\text{Classifications} $ (Equation 20.3). <br> **Explanation-Based Learning (EBL)**: Combines background knowledge and observations: $ \\text{Background} \\models \\text{Hypothesis} \\land \\text{Hypothesis} \\land \\text{Descriptions} \\models \\text{Classifications} $. (Equation 20.4)                     |\n",
    "| **Concepts of Learning**    | - **Pure Inductive Learning**: Constructs hypotheses without using prior knowledge, relying entirely on observed data. <br> - **Knowledge-Based Inductive Learning (KBIL)**: Uses background knowledge to reduce the hypothesis space and improve learning efficiency.                                                                                           |\n",
    "| **Background Knowledge Use**| **Relevance Information**: Identifies which attributes are necessary for classification. <br> **Generalization and Specialization**: Background knowledge is used to explain observations logically and narrow down hypotheses.                                                                                                                                     |\n",
    "| **Types of Learning**       | **Explanation-Based Learning (EBL)**: Extracts general rules by explaining specific observations using background knowledge. <br> **Relevance-Based Learning (RBL)**: Generalizes rules based on knowledge of relevant features. <br> **Knowledge-Based Inductive Learning (KBIL)**: Combines inductive learning with prior knowledge to infer compact hypotheses.                        |\n",
    "| **Applications**            | **Example**: Traveler infers that Brazilians speak Portuguese after hearing one Brazilian speak. Uses prior knowledge that most people in a country share the same language. <br> **Example in Science**: Physics student generalizes density of copper from one sample to all copper pieces but doesn’t generalize the mass of a copper piece to all copper.                                             |\n",
    "| **Limitations**             | KBIL depends heavily on accurate and sufficient background knowledge. Errors or incomplete knowledge can lead to incorrect hypotheses or failure to learn effectively.                                                                                                                                                                                         |\n",
    "\n",
    "---\n",
    "\n",
    "### Code Snippet: Explanation-Based Learning (EBL)\n",
    "\n",
    "```python\n",
    "def ebl(observation, background_knowledge):\n",
    "    \"\"\"\n",
    "    Extracts general rules using Explanation-Based Learning (EBL).\n",
    "    \"\"\"\n",
    "    # Construct a proof for the observation using background knowledge\n",
    "    proof = construct_proof(observation, background_knowledge)\n",
    "\n",
    "    # Generalize the proof into a rule\n",
    "    rule = generalize_proof(proof)\n",
    "\n",
    "    # Drop irrelevant conditions for efficiency\n",
    "    simplified_rule = drop_irrelevant_conditions(rule)\n",
    "\n",
    "    return simplified_rule\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Example Explanation:\n",
    "\n",
    "#### **Scenario**: Traveler in Brazil\n",
    "\n",
    "- **Observation**: The traveler hears a Brazilian speaking Portuguese.\n",
    "- **Background Knowledge**: Most people in a country share the same language.\n",
    "- **Reasoning**: Using background knowledge, the traveler generalizes that Brazilians speak Portuguese. However, the traveler doesn’t generalize that all Brazilians share the name “Fernando” because names aren’t typically uniform within a country.\n",
    "\n",
    "#### **Concept**: This is an example of **relevance-based learning (RBL)**, where the relevant attribute (language) is used for generalization while irrelevant attributes (e.g., names) are ignored.\n",
    "\n",
    "By using the framework of inductive learning with background knowledge, the system can efficiently generate hypotheses without overfitting to irrelevant details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307ecca1-4853-45c6-aa7d-ade302dd0530",
   "metadata": {},
   "source": [
    "# Here is an in-depth table summarizing Section 20.3, accompanied by code snippets and an example explanation.\n",
    "\n",
    "---\n",
    "\n",
    "| **Aspect**                  | **Details**                                                                                                                                                                                                                                                                                                                                                       |\n",
    "|-----------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Key Terms**               | **Explanation-Based Learning (EBL)**: A method to generalize rules by explaining specific observations using background knowledge. <br> **Generalization**: Process of deriving rules that apply to a broader set of cases. <br> **Operationality**: A property of subgoals that makes them easy to solve computationally. <br> **Memoization**: Storing results of computation to avoid redundant calculations. |\n",
    "| **Key Idea**                | EBL converts a specific example into a generalized rule by constructing a logical proof of the example, identifying the conditions necessary for the proof, and generalizing those conditions to form a reusable rule.                                                                                                                                               |\n",
    "| **Equations**               | **Generalized Rule**: $ \\text{Background Knowledge} \\land \\text{Generalized Conditions} \\models \\text{Goal} $.                                                                                                                                                                                                                                                  |\n",
    "| **Process of EBL**          | 1. **Explain**: Construct a proof for the observed example using background knowledge. <br> 2. **Generalize**: Replace constants in the proof with variables to create a generalized proof tree. <br> 3. **Rule Extraction**: Extract a rule from the generalized proof tree. <br> 4. **Simplify**: Drop irrelevant conditions from the rule for efficiency.                                             |\n",
    "| **Applications**            | - Simplifying algebraic expressions (e.g., $ 1 \\times (0 + X) \\to X $). <br> - Generalizing principles of physics (e.g., $ F = ma $ from observed cases). <br> - Learning to optimize computations (e.g., differential calculus).                                                                                                                                  |\n",
    "| **Advantages**              | - Produces reusable, general-purpose rules. <br> - Enables faster problem-solving for similar tasks in the future. <br> - Converts first-principles reasoning into specialized knowledge.                                                                                                                                                                         |\n",
    "| **Limitations**             | - May overgeneralize or fail to generalize when background knowledge is insufficient. <br> - Requires operational subgoals for practical efficiency. <br> - Sensitive to the quality of the example and background knowledge.                                                                                                                                       |\n",
    "\n",
    "---\n",
    "\n",
    "### Code Snippet: Simplified Explanation-Based Learning Process\n",
    "\n",
    "```python\n",
    "def explanation_based_learning(example, background_knowledge):\n",
    "    \"\"\"\n",
    "    Implements a simplified explanation-based learning process.\n",
    "    \"\"\"\n",
    "    # Step 1: Construct a proof of the example using background knowledge\n",
    "    proof = construct_proof(example, background_knowledge)\n",
    "    \n",
    "    # Step 2: Generalize the proof by replacing constants with variables\n",
    "    generalized_proof = generalize_proof(proof)\n",
    "    \n",
    "    # Step 3: Extract the generalized rule\n",
    "    rule = extract_rule(generalized_proof)\n",
    "    \n",
    "    # Step 4: Simplify the rule by dropping irrelevant conditions\n",
    "    simplified_rule = simplify_rule(rule)\n",
    "    \n",
    "    return simplified_rule\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Example Explanation:\n",
    "\n",
    "#### **Scenario**: Simplifying $ 1 \\times (0 + X) $\n",
    "\n",
    "- **Observation**: $ 1 \\times (0 + X) = X $.  \n",
    "- **Background Knowledge**:\n",
    "  1. $ \\text{Rewrite}(1 \\times u, u) $.  \n",
    "  2. $ \\text{Rewrite}(0 + u, u) $.  \n",
    "  3. $ \\text{ArithmeticUnknown}(x) \\to \\text{Primitive}(x) $.  \n",
    "\n",
    "#### **Steps**:\n",
    "\n",
    "1. **Explain**:\n",
    "   - Construct a proof: $ \\text{Simplify}(1 \\times (0 + X), X) $ is derived using the background knowledge.\n",
    "   - The proof involves steps: $ \\text{Rewrite}(1 \\times u, u) \\to \\text{Rewrite}(0 + u, u) \\to X $.\n",
    "\n",
    "2. **Generalize**:\n",
    "   - Replace constants $ 1, 0, X $ with variables $ x, y, z $. \n",
    "   - Proof generalizes to $ \\text{Simplify}(x \\times (y + z), z) $.\n",
    "\n",
    "3. **Rule Extraction**:\n",
    "   - Extract rule: $ \\text{ArithmeticUnknown}(z) \\to \\text{Simplify}(x \\times (y + z), z) $.\n",
    "\n",
    "4. **Simplify**:\n",
    "   - Drop irrelevant conditions, keeping $ \\text{ArithmeticUnknown}(z) $ as the only necessary condition.\n",
    "\n",
    "---\n",
    "\n",
    "**Final Rule**:\n",
    "$$\n",
    "\\text{ArithmeticUnknown}(z) \\to \\text{Simplify}(1 \\times (0 + z), z).\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Explanation of the Example:\n",
    "\n",
    "This example demonstrates how EBL works by taking a specific case, explaining it with logical proof steps, and generalizing it into a reusable rule. In this case, the simplification rule for $ 1 \\times (0 + X) $ becomes a generalized rule for any arithmetic unknown $ z $. This reduces computational effort for similar problems in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63315d97-7596-4689-87d0-a0b42fe78cba",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# **Ch 21**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c2fa50-cd60-437d-82b9-1421ea2124a8",
   "metadata": {},
   "source": [
    "Here's an in-depth summary of Section 21.1 from the document, structured into a table with definitions, equations, and explanations. Code snippets and detailed examples are presented separately for clarity.\n",
    "\n",
    "### **Summary Table for Section 21.1**\n",
    "\n",
    "| **Concept**            | **Definition/Description**                                                                                       | **Equation/Formula**                                                                                                                                                                                                                                                                                                                  | **Key Notes/Examples**                                                                                                                                                                                                                      |\n",
    "|-------------------------|-----------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Statistical Learning**| Learning as a form of probabilistic inference, based on observed data and hypotheses about the domain.          | None                                                                                                                                                                                                                                                                                           | Hypotheses represent probabilistic theories; data are evidence (e.g., the flavor of candy as observed data).                                                                                                                                |\n",
    "| **Hypothesis Prior ($P(h_i)$)** | The initial probability assigned to a hypothesis before observing data.                                  | None                                                                                                                                                                                                                                                                                           | Example: Prior probabilities for candy bag flavors.                                                                                                                                                                                         |\n",
    "| **Likelihood ($P(d|h_i)$)**     | The probability of observed data given a hypothesis.                                                   | $ P(d|h_i) = \\prod_j P(d_j|h_i) $                                                                                                                                                                                                                                                           | In the candy example, the likelihood is computed based on the observed sequence of candies.                                                                                                                                                 |\n",
    "| **Posterior Probability ($P(h_i|d)$)** | The updated probability of a hypothesis after observing data.                                         | $ P(h_i|d) = \\alpha P(d|h_i) P(h_i) $, where $ \\alpha $ is a normalization constant.                                                                                                                                                                                                      | Posterior probabilities are recalculated as more candies are observed (e.g., shifting belief towards \"all lime\" hypothesis after several lime candies).                                                                                      |\n",
    "| **Prediction ($P(X|d)$)**       | Probability distribution of an unknown variable $X$ based on observed data $d$.                    | $ P(X|d) = \\sum_i P(X|h_i) P(h_i|d) $                                                                                                                                                                                                                                                       | Predictions are weighted averages across all hypotheses. For example, estimating the probability that the next candy is lime.                                                                                                               |\n",
    "| **Maximum a Posteriori (MAP)**    | Hypothesis maximizing posterior probability.                                                          | $ h_{MAP} = \\text{argmax}_{h_i} P(h_i|d) $                                                                                                                                                                                                                                                   | In the candy case, if three lime candies are observed, MAP predicts the hypothesis \"all lime.\"                                                                                                                                              |\n",
    "| **Maximum Likelihood (ML)**       | Hypothesis maximizing likelihood of data.                                                            | $ h_{ML} = \\text{argmax}_{h_i} P(d|h_i) $                                                                                                                                                                                                                                                   | Used when the prior distribution is uniform or data set is large enough to dominate prior probabilities.                                                                                                                                     |\n",
    "| **Overfitting**                   | A situation where a model fits the training data too well, including noise, and performs poorly on new data. | None                                                                                                                                                                                                                                                                                           | Avoided using priors in Bayesian learning, which penalize overly complex hypotheses.                                                                                                                                                         |\n",
    "| **Minimum Description Length (MDL)** | A principle minimizing bits to encode hypotheses and data.                                           | None                                                                                                                                                                                                                                                                                           | MDL approximates MAP by favoring simpler hypotheses with fewer parameters.                                                                                                                                                                  |\n",
    "\n",
    "---\n",
    "\n",
    "### **Code Snippets**\n",
    "\n",
    "#### **Example: Bayesian Updating for Candy Prediction**\n",
    "The following Python code simulates Bayesian updates for predicting the next candy flavor based on observed candies.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Prior probabilities for hypotheses (h1 to h5)\n",
    "priors = np.array([0.1, 0.2, 0.4, 0.2, 0.1])\n",
    "\n",
    "# Likelihood function for observed data given hypotheses\n",
    "def likelihood(data, hypothesis):\n",
    "    p_cherry = [1.0, 0.75, 0.5, 0.25, 0.0]\n",
    "    return np.prod([p_cherry[hypothesis] if d == \"cherry\" else 1 - p_cherry[hypothesis] for d in data])\n",
    "\n",
    "# Observations and Bayesian updating\n",
    "data = [\"lime\", \"lime\", \"lime\"]\n",
    "posteriors = priors * np.array([likelihood(data, h) for h in range(5)])\n",
    "posteriors /= posteriors.sum()\n",
    "\n",
    "print(\"Posterior probabilities:\", posteriors)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Explanation of Example**\n",
    "In the candy example:\n",
    "- **Hypotheses**: Five types of candy bags, each with different cherry-to-lime ratios.\n",
    "- **Data**: Observations of candy flavors as they are unwrapped.\n",
    "- **Prediction**: Using Bayesian updating, the posterior probabilities for each hypothesis are recalculated after observing the sequence of candies. This helps predict the flavor of the next candy. For instance, observing many \"lime\" candies strongly supports the hypothesis of an all-lime bag. \n",
    "\n",
    "Let me know if further details or additional examples are needed!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388acf55-ff1b-4443-a10e-3fbb2fd5851c",
   "metadata": {},
   "source": [
    "# Here is an in-depth summary of Section 21.2, **Learning with Complete Data**, in tabular form with definitions, equations, and concepts. Code snippets and examples are provided separately for clarity.\n",
    "\n",
    "---\n",
    "\n",
    "| **Concept**                       | **Definition/Description**                                                                                                         | **Equation/Formula**                                                                                     | **Key Notes/Examples**                                                                                      |\n",
    "|-----------------------------------|-----------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------|\n",
    "| **Density Estimation**            | Task of learning a probability model from data that is assumed to be generated by the model. Originally applied to continuous variables but now also used for discrete distributions. | None                                                                                                     | Example: Learning the conditional probabilities in a Bayesian network.                                      |\n",
    "| **Complete Data**                 | Data where every variable in the probability model has a value for each data point.                                         | None                                                                                                     | Example: Unwrapping candies with both flavors and wrappers fully observed.                                  |\n",
    "| **Parameter Learning**            | Estimating numerical parameters of a fixed probability model structure.                                                     | None                                                                                                     | Example: Finding the proportion of cherry candies in a bag.                                                 |\n",
    "| **Maximum Likelihood (ML)**       | Approach to find parameters that maximize the likelihood of the observed data.                                               | $ L(d|h_{\\theta}) = c \\log \\theta + l \\log (1 - \\theta) $                                              | ML learning assigns $ \\theta = \\frac{c}{N} $, the proportion of cherry candies unwrapped so far.          |\n",
    "| **Log-Likelihood**                | Simplifies likelihood computations by converting products into sums.                                                        | $ L(d|h_{\\theta}) = \\sum_{j=1}^{N} \\log P(d_j|h_{\\theta}) $                                            | Easier for optimization, especially for complex models.                                                     |\n",
    "| **Naive Bayes Model**             | A Bayesian network where the class variable is the root, and attributes are conditionally independent given the class.       | $ P(C|X_1, \\ldots, X_n) = \\alpha P(C) \\prod_i P(X_i|C) $                                               | Example: Classifying emails as spam or not spam based on features like word frequencies.                    |\n",
    "| **Bayesian Parameter Learning**   | Uses a prior over parameters and updates posterior distributions as data arrive.                                            | $ P(\\theta | d) \\propto P(d|\\theta)P(\\theta) $                                                         | Handles small data sets better than ML by avoiding overconfidence in zero-probability events.               |\n",
    "| **Beta Distribution**             | A flexible prior distribution for parameters like probabilities, defined by two hyperparameters $a$ and $b$.             | $ \\text{Beta}(\\theta; a, b) = \\alpha \\theta^{a-1} (1 - \\theta)^{b-1} $                                 | Example: Prior for the fraction of cherry candies in a bag, where $a$ and $b$ control the distribution's shape. |\n",
    "| **Generative Models**             | Models the joint probability distribution $ P(X, Y) $ for classification tasks.                                            | None                                                                                                     | Example: Naive Bayes classifier, which models $ P(Y) $ and $ P(X|Y) $.                                  |\n",
    "| **Discriminative Models**         | Directly learns $ P(Y|X) $, the decision boundary between classes.                                                        | None                                                                                                     | Example: Logistic regression, which predicts the class probabilities directly.                              |\n",
    "| **Bayesian Linear Regression**    | Regression method that accounts for uncertainty in parameter estimates by placing priors on them.                           | $ P(y|x, \\theta) = N(y; \\theta x, \\sigma^2) $                                                          | Produces a posterior distribution over model parameters and predictive intervals.                           |\n",
    "\n",
    "---\n",
    "\n",
    "### Example: Candy Flavor Prediction with Maximum Likelihood\n",
    "#### Problem:\n",
    "A bag of candies has an unknown fraction $ \\theta $ of cherry candies. After unwrapping $ N $ candies, $ c $ are cherry, and $ l = N - c $ are lime. Estimate $ \\theta $.\n",
    "\n",
    "#### Solution:\n",
    "- The likelihood of data: $ P(d|h_{\\theta}) = \\theta^c (1 - \\theta)^l $\n",
    "- Log-likelihood: $ L(d|h_{\\theta}) = c \\log \\theta + l \\log (1 - \\theta) $\n",
    "- Maximizing $ L $: Solve $ \\frac{\\partial L}{\\partial \\theta} = 0 $ to get $ \\theta = \\frac{c}{N} $.\n",
    "\n",
    "#### Python Code:\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Data: number of cherry (c) and lime (l) candies\n",
    "c = 30\n",
    "l = 20\n",
    "N = c + l\n",
    "\n",
    "# Maximum Likelihood Estimation of theta\n",
    "theta_ml = c / N\n",
    "print(f\"Maximum Likelihood Estimate of theta: {theta_ml:.2f}\")\n",
    "```\n",
    "\n",
    "**Output:**  \n",
    "`Maximum Likelihood Estimate of theta: 0.60`\n",
    "\n",
    "#### Explanation:\n",
    "The ML estimate for $ \\theta $ is the observed proportion of cherry candies.\n",
    "\n",
    "---\n",
    "\n",
    "Let me know if you'd like further elaboration on any of these concepts or examples!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24569da1-d50f-4b0d-8ba6-dcc500693678",
   "metadata": {},
   "source": [
    "# Here’s a comprehensive summary of **Section 21.3: Learning with Hidden Variables** from the document, structured as an in-depth table. Definitions, important concepts, equations, and examples are included, with code snippets explained separately.\n",
    "\n",
    "---\n",
    "\n",
    "| **Concept**                     | **Definition/Description**                                                                                                         | **Equation/Formula**                                                                                                            | **Key Notes/Examples**                                                                                                           |\n",
    "|---------------------------------|-----------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Hidden Variables (Latent Variables)** | Variables that influence observed data but are not directly observable.                                                      | None                                                                                                                          | Example: In a medical dataset, symptoms are observed, but the underlying disease is a hidden variable    |\n",
    "| **Expectation-Maximization (EM)** | Iterative algorithm to handle learning in the presence of hidden variables by alternating between expectation (E) and maximization (M) steps. | $ \\theta^{(i+1)} = \\arg\\max_\\theta \\sum_{z} P(Z=z | X, \\theta^{(i)}) \\log P(X, Z | \\theta) $                                  | Applies to problems like Gaussian mixture models, hidden Markov models, and Bayesian networks  .                    | Computes the expected value of the hidden variables based on the current parameters.                                             | $ P(Z=z | X, \\theta^{(i)}) $                                                                                                | Uses Bayes' rule to infer the probability distribution over hidden variables .                                *M-Step**                      | Updates the model parameters to maximize the expected log-likelihood computed in the E-step.                                     | $ \\theta^{(i+1)} = \\arg\\max_\\theta \\mathbb{E}_{P(Z|X, \\theta^{(i)})}[\\log P(X, Z | \\theta)] $                                 | Parameters are recomputed as if the inferred hidden variables were observed .                                       |\n",
    "| ixture Models (GMMs)** | A common application of the EM algorithm where data are assumed to be generated by a mixture of Gaussian distributions.         | $ P(x) = \\sum_{i=1}^{k} w_i \\cdot \\mathcal{N}(x | \\mu_i, \\Sigma_i) $                                                         | EM alternates between assigning probabilities of data points to clusters (E-step) and updating parameters for clusters (M-step) . |\n",
    "| **Hidden Markov Models (HMMs)**  | Sequential moden states and observable outputs; EM is used to estimate transition and emission probabilities.       | $ \\theta_{ij} = \\frac{\\sum_t \\mathbb{E}[N(X_t = i, X_{t+1} = j)]}{\\sum_t \\mathbb{E}[N(X_t = i)]} $                           | The forward-backward algorithm is used in the E-step for smoothing probabilities  .                       |\n",
    "| **Identifiability**              | Thel parameters uniquely from observed data.                                                           | None                                                                                                                          | Non-identifiability occurs when multiple models produce equivalent results; EM might converge to different solutions . |\n",
    "| **Structural EM Algorithm**      | Extends EM to update both the structure and paraesian networks during learning.                                    | None                                                                                                                          | Searches over structure space and parameter space iteratively to find the best model .                               |\n",
    "\n",
    "---\n",
    "\n",
    "### **Example: Gaussian Mixture Model with EM**\n",
    "#### Problem:dataset of 2D points that are generated from a mixture of 3 Gaussian distributions. The goal is to fit a GMM to the data using EM.\n",
    "\n",
    "#### Steps:\n",
    "1. **Initialize** the parameters (means, covariances, and weights) arbitrarily.\n",
    "2. **E-Step**: Calculate the probabilities $ p_{ij} $ that data point $ x_j $ belongs to Gaussian $ i $:\n",
    "   $$\n",
    "   p_{ij} = \\frac{w_i \\mathcal{N}(x_j | \\mu_i, \\Sigma_i)}{\\sum_k w_k \\mathcal{N}(x_j | \\mu_k, \\Sigma_k)}\n",
    "   $$\n",
    "3. **M-Step**: Update the parameters based on $ p_{ij} $:\n",
    "   $$\n",
    "   w_i = \\frac{\\sum_j p_{ij}}{N}, \\quad \\mu_i = \\frac{\\sum_j p_{ij} x_j}{\\sum_j p_{ij}}, \\quad \\Sigma_i = \\frac{\\sum_j p_{ij} (x_j - \\mu_i)(x_j - \\mu_i)^T}{\\sum_j p_{ij}}\n",
    "   $$\n",
    "4. Repeat until convergence.\n",
    "\n",
    "#### Python Code:\n",
    "```python\n",
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "data = np.vstack([\n",
    "    np.random.multivariate_normal([0, 0], [[1, 0], [0, 1]], size=100),\n",
    "    np.random.multivariate_normal([3, 3], [[1, 0.5], [0.5, 1]], size=100),\n",
    "    np.random.multivariate_normal([6, 0], [[1, -0.5], [-0.5, 1]], size=100)\n",
    "])\n",
    "\n",
    "# Fit GMM using EM\n",
    "gmm = GaussianMixture(n_components=3, random_state=42)\n",
    "gmm.fit(data)\n",
    "\n",
    "# Output learned parameters\n",
    "print(\"Means:\\n\", gmm.means_)\n",
    "print(\"Covariances:\\n\", gmm.covariances_)\n",
    "```\n",
    "\n",
    "#### Explanation:\n",
    "- **E-Step**: Assigns each data point a probability of belonging to each Gaussian.\n",
    "- **M-Step**: Updates the Gaussian parameters (mean, covariance) and weights using these probabilities.\n",
    "- The process iterates until convergence, resulting in a fitted GMM.\n",
    "\n",
    "Let me know if further elaboration or additional examples are needed!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a236ee57-cae3-4515-b3f9-728252a1decb",
   "metadata": {},
   "source": [
    "# Here’s an in-depth summary of **Section 21.4: Learning Bayesian Network Structures**, structured as a table with explanations of key terms, equations, and concepts. An example with code is provided separately for clarity.\n",
    "\n",
    "---\n",
    "\n",
    "| **Concept**                     | **Definition/Description**                                                                                                         | **Equation/Formula**                                                                                                            | **Key Notes/Examples**                                                                                                           |\n",
    "|---------------------------------|-----------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Bayesian Network Structure Learning** | The process of determining the network topology (connections) based on observed data.                                         | None                                                                                                                          | Structure learning can involve adding, removing, or reversing edges between nodes.                                              |\n",
    "| **Conditional Independence Tests** | Method to identify relationships in data by checking if conditional independence properties hold between variables.            | $ P(A, B | C) = P(A | C) P(B | C) $                                                                                          | Useful for determining if direct connections should exist between nodes.                                                        |\n",
    "| **Model Search**                | An iterative approach to find the best network structure by exploring possible topologies and measuring their performance.        | None                                                                                                                          | Common approaches include hill climbing, simulated annealing, and greedy search algorithms.                                     |\n",
    "| **Cycle Avoidance**             | Ensures that the learned network does not include cycles, preserving the Directed Acyclic Graph (DAG) property of Bayesian networks. | None                                                                                                                          | Typically achieved by imposing a variable ordering and allowing parent nodes only earlier in the order.                         |\n",
    "| **Maximum Likelihood Learning** | Seeks to maximize the likelihood of the observed data for a given network structure, often leading to overfitting without regularization. | $ L = \\prod_{i=1}^N P(X_i | \\text{Parents}(X_i)) $                                                                            | Regularization methods like MAP or MDL are used to penalize complexity.                                                         |\n",
    "| **MAP and MDL Approaches**      | MAP penalizes complex models using priors; MDL uses penalties based on the number of parameters or the size of the representation. | $ L_{\\text{MAP}} = L - \\text{Penalty} $, where penalty depends on prior or representation complexity.                         | Prevents overfitting and produces simpler, interpretable models.                                                                |\n",
    "| **Bayesian Score**              | Incorporates prior beliefs about structures and parameters, calculating the posterior probability of a structure.                 | $ P(S | D) \\propto P(D | S) P(S) $                                                                                           | Enables integration of prior knowledge into the structure learning process.                                                     |\n",
    "| **Markov Chain Monte Carlo (MCMC)** | Sampling method used to approximate Bayesian structure learning by exploring possible structures iteratively.                   | None                                                                                                                          | Samples from the posterior distribution to estimate probabilities for network structures.                                       |\n",
    "| **Structural EM Algorithm**     | Extends the EM algorithm to modify network structures during the optimization process, combining parameter learning and structure updates. | None                                                                                                                          | Simultaneously evaluates expected counts and updates likelihood for potential new structures.                                   |\n",
    "\n",
    "---\n",
    "\n",
    "### Example: Bayesian Network Structure Learning\n",
    "\n",
    "#### Problem:\n",
    "Given the following data, learn a Bayesian network structure that represents the relationships between variables $ A $, $ B $, and $ C $.\n",
    "\n",
    "| **A** | **B** | **C** |\n",
    "|-------|-------|-------|\n",
    "| 0     | 1     | 1     |\n",
    "| 1     | 0     | 0     |\n",
    "| 1     | 1     | 1     |\n",
    "| 0     | 0     | 0     |\n",
    "\n",
    "#### Solution:\n",
    "1. **Start with No Links:** Begin with an unconnected network of nodes $ A $, $ B $, and $ C $.\n",
    "2. **Test Conditional Independencies:** Use data to check relationships between variables, e.g., $ P(A, B | C) $.\n",
    "3. **Iterative Updates:** Use a search strategy (e.g., hill climbing) to add, remove, or reverse edges.\n",
    "4. **Evaluate Network:** Calculate the likelihood, penalized using MAP or MDL, for each candidate structure.\n",
    "5. **Stop When Optimal:** Conclude when changes no longer improve the score.\n",
    "\n",
    "---\n",
    "\n",
    "#### Python Code:\n",
    "```python\n",
    "from pgmpy.models import BayesianNetwork\n",
    "from pgmpy.estimators import HillClimbSearch, BicScore\n",
    "\n",
    "# Define the data\n",
    "import pandas as pd\n",
    "data = pd.DataFrame({\n",
    "    'A': [0, 1, 1, 0],\n",
    "    'B': [1, 0, 1, 0],\n",
    "    'C': [1, 0, 1, 0]\n",
    "})\n",
    "\n",
    "# Initialize a Bayesian Network Search\n",
    "hc = HillClimbSearch(data, scoring_method=BicScore(data))\n",
    "best_model = hc.estimate()\n",
    "\n",
    "# Display the learned structure\n",
    "print(\"Learned structure:\", best_model.edges())\n",
    "```\n",
    "\n",
    "#### Explanation:\n",
    "1. **Data Input:** A simple dataset with three binary variables is provided.\n",
    "2. **Structure Learning:** The `HillClimbSearch` function explores potential structures.\n",
    "3. **Scoring:** The `BicScore` evaluates the trade-off between data fit and complexity.\n",
    "4. **Output:** The best network structure is identified, revealing relationships in the data.\n",
    "\n",
    "Let me know if you need further elaboration or a more complex example!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d27898b-3928-43ba-8807-3216e796ae0c",
   "metadata": {},
   "source": [
    "---\n",
    "# **EXAMPLE Qs**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5805b0-df20-4c17-a73c-47e060fd9ba4",
   "metadata": {},
   "source": [
    "# Section 19.1, along with a worked solution:\n",
    "\n",
    "---\n",
    "\n",
    "### **Question:**\n",
    "A self-driving car is designed to learn braking behavior under different road conditions. \n",
    "\n",
    "1. Identify which **component(s)** of an agent can be improved through learning in this scenario. Provide specific examples based on the learning types discussed in Section 19.1.  \n",
    "2. Explain the differences between **supervised**, **unsupervised**, and **reinforcement learning** in the context of this car’s learning process.  \n",
    "3. Given the following training data for a supervised learning scenario, classify whether the car should brake hard or not (output: 1 = Brake Hard, 0 = Don't Brake Hard). Assume a decision tree algorithm is used.  \n",
    "    **Training Data**:\n",
    "    - Features: [Speed (km/h), WetRoad (1 = Yes, 0 = No)]  \n",
    "    - Outputs: Brake Hard (1) or Don't Brake Hard (0).  \n",
    "\n",
    "    $$\n",
    "    \\text{X (Features)} = \\begin{bmatrix} 60 & 1 \\\\ 80 & 0 \\\\ 30 & 1 \\\\ 100 & 1 \\\\ 50 & 0 \\end{bmatrix}, \\quad\n",
    "    \\text{y (Labels)} = \\begin{bmatrix} 1 \\\\ 0 \\\\ 1 \\\\ 1 \\\\ 0 \\end{bmatrix}\n",
    "    $$\n",
    "\n",
    "    Predict the output for a new scenario where the speed is 70 km/h and the road is wet (WetRoad = 1).  \n",
    "\n",
    "---\n",
    "\n",
    "### **Solution:**\n",
    "\n",
    "#### **Part 1: Components Improved by Learning**\n",
    "The following agent components can be improved for the self-driving car:\n",
    "\n",
    "1. **Direct Mapping (Condition → Action):**  \n",
    "   - The car learns specific rules, such as \"If Speed > 60 and WetRoad = 1, then Brake Hard.\"\n",
    "\n",
    "2. **Inference:**  \n",
    "   - The car uses sensory data (e.g., road conditions) to infer properties of the environment, such as whether a road is wet.\n",
    "\n",
    "3. **Action-Value Information:**  \n",
    "   - The car learns which braking actions minimize stopping distance on wet roads while ensuring passenger safety.\n",
    "\n",
    "4. **Utility Information:**  \n",
    "   - The car evaluates braking actions based on utility, such as minimizing accidents and maintaining comfort.\n",
    "\n",
    "#### **Part 2: Learning Types**\n",
    "1. **Supervised Learning:**  \n",
    "   - The car is trained using labeled examples of braking decisions based on historical data (e.g., \"If Speed = 60 and WetRoad = 1, Brake Hard\").\n",
    "\n",
    "2. **Unsupervised Learning:**  \n",
    "   - The car identifies patterns in road conditions without explicit feedback, such as clustering road types (e.g., wet, icy, dry) based on sensor data.\n",
    "\n",
    "3. **Reinforcement Learning:**  \n",
    "   - The car learns through trial and error by receiving rewards (e.g., successful braking without skidding) or penalties (e.g., accidents or sliding).\n",
    "\n",
    "#### **Part 3: Supervised Learning Prediction**\n",
    "Using a simple decision tree, we can build rules based on the training data:\n",
    "\n",
    "- Rule 1: If Speed ≤ 50, Brake Hard = 0.  \n",
    "- Rule 2: If Speed > 50 and WetRoad = 1, Brake Hard = 1.  \n",
    "- Rule 3: If Speed > 50 and WetRoad = 0, Brake Hard = 0.  \n",
    "\n",
    "**New Scenario:** Speed = 70, WetRoad = 1.  \n",
    "- Rule 2 applies since Speed > 50 and WetRoad = 1.  \n",
    "- **Prediction:** Brake Hard = 1.\n",
    "\n",
    "---\n",
    "\n",
    "### **Final Answer:**\n",
    "1. **Components Improved:** Direct Mapping, Inference, Action-Value Information, Utility Information.  \n",
    "2. **Learning Types:** Supervised, Unsupervised, Reinforcement Learning explained.  \n",
    "3. **Prediction:** For Speed = 70 and WetRoad = 1, the car will Brake Hard (Output = 1).  \n",
    "\n",
    "---\n",
    "\n",
    "This worked example integrates theoretical knowledge and practical application, reflecting the type of question you might encounter on an exam about machine learning concepts. Let me know if you'd like another example!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a69b2a-6d11-4faa-9ffa-1f26afac8812",
   "metadata": {},
   "source": [
    "#H ere’s a worked example of a possible exam question based on Section 19.2:\n",
    "\n",
    "---\n",
    "\n",
    "### **Question:**\n",
    "\n",
    "A machine learning engineer is tasked with building a model to predict whether customers will wait for a table at a restaurant. The engineer uses a supervised learning approach.\n",
    "\n",
    "1. **Understanding the Problem**:\n",
    "    - What type of learning is being used in this scenario? Explain why.\n",
    "    - Define the training set and hypothesis in the context of this problem.\n",
    "2. **Overfitting and Underfitting**:\n",
    "    - Explain the concepts of overfitting and underfitting in the context of this problem.\n",
    "    - Provide an example of how overfitting and underfitting could occur in this task.\n",
    "3. **Model Application**:\n",
    "    - Given the following training data, predict the outcome (1 = Will Wait, 0 = Won't Wait) for a customer with attributes [30-60 min wait, Raining = Yes, Reservation = No] using a decision tree.\n",
    "    \n",
    "    **Training Data:**\n",
    "    - Features: [WaitTime (0: 0-10, 1: 10-30, 2: 30-60, 3: >60), Raining (0: No, 1: Yes), Reservation (0: No, 1: Yes)]\n",
    "    - Labels: $ y $ (1 = Will Wait, 0 = Won't Wait)\n",
    "\n",
    "    $$\n",
    "    X = \\begin{bmatrix}\n",
    "    0 & 0 & 1 \\\\\n",
    "    3 & 1 & 0 \\\\\n",
    "    2 & 0 & 1 \\\\\n",
    "    1 & 1 & 0\n",
    "    \\end{bmatrix}, \\quad\n",
    "    y = \\begin{bmatrix}\n",
    "    1 \\\\ 0 \\\\ 1 \\\\ 0\n",
    "    \\end{bmatrix}\n",
    "    $$\n",
    "\n",
    "4. **Evaluation**:\n",
    "    - Why is it important to evaluate the model on unseen test data? Explain with an example.\n",
    "    - How could you improve the model's ability to generalize?\n",
    "\n",
    "---\n",
    "\n",
    "### **Solution:**\n",
    "\n",
    "#### **Part 1: Understanding the Problem**\n",
    "\n",
    "- **Type of Learning**:  \n",
    "  This is **supervised learning** because the training data contains input-output pairs (features and labels). The goal is to learn a mapping from the input attributes (wait time, weather, reservation) to the output (wait or not wait).\n",
    "\n",
    "- **Training Set**:  \n",
    "  The training set consists of:\n",
    "  $$\n",
    "  X = \\begin{bmatrix}\n",
    "  0 & 0 & 1 \\\\\n",
    "  3 & 1 & 0 \\\\\n",
    "  2 & 0 & 1 \\\\\n",
    "  1 & 1 & 0\n",
    "  \\end{bmatrix}, \\quad\n",
    "  y = \\begin{bmatrix}\n",
    "  1 \\\\ 0 \\\\ 1 \\\\ 0\n",
    "  \\end{bmatrix}\n",
    "  $$\n",
    "  Here, $ X $ contains the features (WaitTime, Raining, Reservation), and $ y $ contains the labels.\n",
    "\n",
    "- **Hypothesis**:  \n",
    "  A hypothesis is a function $ h(x) $ learned from the data that maps the input $ x $ (attributes) to the output $ y $ (decision: wait or not wait).\n",
    "\n",
    "---\n",
    "\n",
    "#### **Part 2: Overfitting and Underfitting**\n",
    "\n",
    "- **Overfitting**:  \n",
    "  Overfitting occurs when the model memorizes the training data, including noise or specific details, but fails to generalize to new examples.  \n",
    "\n",
    "  **Example**: A decision tree splits excessively on attributes (e.g., creating branches for each unique combination of attributes), leading to a complex tree that performs poorly on unseen data.\n",
    "\n",
    "- **Underfitting**:  \n",
    "  Underfitting occurs when the model is too simple and fails to capture the patterns in the data.\n",
    "\n",
    "  **Example**: A decision tree with just one split based on \"WaitTime\" might ignore the impact of \"Raining\" or \"Reservation,\" leading to poor predictions even on the training data.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Part 3: Model Application**\n",
    "\n",
    "**Prediction Using Decision Tree**:\n",
    "\n",
    "1. Analyze the training data to find the best splits:\n",
    "    - $ WaitTime = 0 $: Will Wait (1).\n",
    "    - $ WaitTime = 3 $: Won't Wait (0).\n",
    "    - $ WaitTime = 2 $: Will Wait (1).\n",
    "    - $ WaitTime = 1 $: Won't Wait (0).\n",
    "\n",
    "    Rules derived from the training data:\n",
    "    - Rule 1: If $ WaitTime = 0 $ or $ WaitTime = 2 $, $ y = 1 $ (Will Wait).\n",
    "    - Rule 2: If $ WaitTime = 1 $ or $ WaitTime = 3 $, $ y = 0 $ (Won't Wait).\n",
    "\n",
    "2. Apply the rules to the new input $[WaitTime = 2, Raining = 1, Reservation = 0]$:\n",
    "    - According to Rule 1 ($ WaitTime = 2 $), the predicted label is $ y = 1 $ (Will Wait).\n",
    "\n",
    "**Prediction**: **Will Wait** ($ y = 1 $).\n",
    "\n",
    "---\n",
    "\n",
    "#### **Part 4: Evaluation**\n",
    "\n",
    "- **Importance of Evaluation on Unseen Data**:  \n",
    "  Evaluating on unseen data ensures the model generalizes well and avoids overfitting.  \n",
    "\n",
    "  **Example**: If the model memorizes the training data but performs poorly on new customer scenarios, it cannot provide reliable predictions in practice.\n",
    "\n",
    "- **Improving Generalization**:\n",
    "  1. Use **cross-validation** to assess performance on different data splits.\n",
    "  2. Regularize the model to prevent it from becoming overly complex (e.g., limit tree depth).\n",
    "  3. Collect more training data to capture diverse scenarios.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Takeaways**\n",
    "\n",
    "- The model effectively predicted the output based on training data rules.\n",
    "- Evaluation ensures the model is reliable in real-world applications.\n",
    "- Overfitting and underfitting must be carefully managed to balance model complexity and generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7468a1-2131-43c1-8a66-9b562882c196",
   "metadata": {},
   "source": [
    "# Here’s a worked example of an exam-style question based on Section 19.3 (Learning Decision Trees):\n",
    "\n",
    "---\n",
    "\n",
    "### **Question**\n",
    "\n",
    "A machine learning engineer is tasked with building a decision tree model to predict whether a customer will wait for a table at a restaurant. The training data and relevant attributes are as follows:\n",
    "\n",
    "#### **Training Data**\n",
    "| Patrons     | WaitEstimate | Raining | WillWait |\n",
    "|-------------|--------------|---------|----------|\n",
    "| Full        | 10-30 min    | No      | Yes      |\n",
    "| Full        | 30-60 min    | Yes     | No       |\n",
    "| Some        | 0-10 min     | No      | Yes      |\n",
    "| None        | 0-10 min     | Yes     | No       |\n",
    "\n",
    "Attributes:\n",
    "1. **Patrons**: Number of people at the restaurant (None, Some, Full).  \n",
    "2. **WaitEstimate**: Host's wait estimate (0-10 min, 10-30 min, 30-60 min).  \n",
    "3. **Raining**: Whether it is raining (Yes, No).  \n",
    "4. **WillWait**: Output label (Yes, No).\n",
    "\n",
    "#### **Tasks**\n",
    "1. **Tree Construction**:\n",
    "   - Explain the process of building the decision tree using the greedy algorithm. \n",
    "   - Calculate the information gain for each attribute at the root node and select the best attribute for splitting.\n",
    "\n",
    "2. **Prediction**:\n",
    "   - Predict whether a customer with attributes $[Patrons = Full, WaitEstimate = 0-10 min, Raining = No]$ will wait for a table.\n",
    "\n",
    "3. **Evaluation**:\n",
    "   - Explain how overfitting could occur with this decision tree. Propose one method to prevent overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "### **Solution**\n",
    "\n",
    "---\n",
    "\n",
    "#### **Part 1: Tree Construction**\n",
    "\n",
    "**Step 1: Calculate Entropy at Root Node**\n",
    "\n",
    "Entropy ($H$) measures the uncertainty of the output labels. The formula is:  \n",
    "$$\n",
    "H(S) = -\\sum P(c) \\log_2 P(c)\n",
    "$$\n",
    "\n",
    "At the root, there are 2 \"Yes\" and 2 \"No\" labels:  \n",
    "$$\n",
    "H(\\text{Root}) = -\\left(\\frac{2}{4} \\log_2 \\frac{2}{4} + \\frac{2}{4} \\log_2 \\frac{2}{4}\\right) = 1.0\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "**Step 2: Information Gain for Each Attribute**\n",
    "\n",
    "**a) Patrons**:  \n",
    "Split data by $ \\text{Patrons} $: None, Some, Full. Calculate entropy for each branch:\n",
    "\n",
    "- $ \\text{Patrons = None} $: $ H = 0 $ (1 No).  \n",
    "- $ \\text{Patrons = Some} $: $ H = 0 $ (1 Yes).  \n",
    "- $ \\text{Patrons = Full} $: $ H = -\\left(\\frac{1}{2} \\log_2 \\frac{1}{2} + \\frac{1}{2} \\log_2 \\frac{1}{2}\\right) = 1.0 $.\n",
    "\n",
    "Weighted average entropy:  \n",
    "$$\n",
    "\\text{Remainder(Patrons)} = \\frac{1}{4}(0) + \\frac{1}{4}(0) + \\frac{2}{4}(1.0) = 0.5\n",
    "$$\n",
    "\n",
    "Information Gain:  \n",
    "$$\n",
    "\\text{Gain(Patrons)} = 1.0 - 0.5 = 0.5\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "**b) WaitEstimate**:  \n",
    "Split data by $ \\text{WaitEstimate} $: 0-10 min, 10-30 min, 30-60 min.\n",
    "\n",
    "- $ \\text{WaitEstimate = 0-10 min} $: $ H = 0 $ (1 Yes, 1 No).  \n",
    "- $ \\text{WaitEstimate = 10-30 min} $: $ H = 0 $ (1 Yes).  \n",
    "- $ \\text{WaitEstimate = 30-60 min} $: $ H = 0 $ (1 No).\n",
    "\n",
    "Weighted average entropy:  \n",
    "$$\n",
    "\\text{Remainder(WaitEstimate)} = \\frac{2}{4}(0) + \\frac{1}{4}(0) + \\frac{1}{4}(0) = 0\n",
    "$$\n",
    "\n",
    "Information Gain:  \n",
    "$$\n",
    "\\text{Gain(WaitEstimate)} = 1.0 - 0 = 1.0\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "**c) Raining**:  \n",
    "Split data by $ \\text{Raining} $: Yes, No.\n",
    "\n",
    "- $ \\text{Raining = Yes} $: $ H = -\\left(\\frac{1}{2} \\log_2 \\frac{1}{2} + \\frac{1}{2} \\log_2 \\frac{1}{2}\\right) = 1.0 $.  \n",
    "- $ \\text{Raining = No} $: $ H = -\\left(\\frac{1}{2} \\log_2 \\frac{1}{2} + \\frac{1}{2} \\log_2 \\frac{1}{2}\\right) = 1.0 $.\n",
    "\n",
    "Weighted average entropy:  \n",
    "$$\n",
    "\\text{Remainder(Raining)} = \\frac{2}{4}(1.0) + \\frac{2}{4}(1.0) = 1.0\n",
    "$$\n",
    "\n",
    "Information Gain:  \n",
    "$$\n",
    "\\text{Gain(Raining)} = 1.0 - 1.0 = 0\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "**Step 3: Select Best Attribute for Root Split**\n",
    "\n",
    "- $ \\text{Gain(Patrons)} = 0.5 $  \n",
    "- $ \\text{Gain(WaitEstimate)} = 1.0 $  \n",
    "- $ \\text{Gain(Raining)} = 0 $\n",
    "\n",
    "**Best Split**: $ \\text{WaitEstimate} $.\n",
    "\n",
    "---\n",
    "\n",
    "**Step 4: Build Tree**\n",
    "\n",
    "- Root: $ \\text{WaitEstimate} $  \n",
    "  - $ \\text{WaitEstimate = 0-10 min} $: Branch to Yes or No.  \n",
    "  - $ \\text{WaitEstimate = 10-30 min} $: Leaf = Yes.  \n",
    "  - $ \\text{WaitEstimate = 30-60 min} $: Leaf = No.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Part 2: Prediction**\n",
    "\n",
    "For $[Patrons = Full, WaitEstimate = 0-10 min, Raining = No]$:  \n",
    "- The decision tree first splits on $ \\text{WaitEstimate = 0-10 min} $.  \n",
    "- The branch for $ \\text{WaitEstimate = 0-10 min} $ indicates mixed results.  \n",
    "- A tie-breaking rule (e.g., most common label) predicts **\"Will Wait\" (Yes)**.\n",
    "\n",
    "**Prediction**: $ y = 1 $ (\"Will Wait\").\n",
    "\n",
    "---\n",
    "\n",
    "#### **Part 3: Evaluation**\n",
    "\n",
    "**Overfitting**:  \n",
    "Overfitting occurs when the tree becomes too complex, memorizing the training data instead of generalizing to unseen data. For example, a tree with excessive splits based on specific patterns in the training data may fail to predict accurately on new customers.\n",
    "\n",
    "**Preventing Overfitting**:\n",
    "1. **Pruning**: Remove branches with low information gain or statistical insignificance.  \n",
    "2. **Set Tree Depth Limit**: Restrict the maximum depth of the tree.  \n",
    "3. **Use Cross-Validation**: Evaluate the tree's performance on multiple data splits to ensure generalization.\n",
    "\n",
    "---\n",
    "\n",
    "### **Final Answer**\n",
    "\n",
    "1. **Best Attribute for Root**: $ \\text{WaitEstimate} $.  \n",
    "2. **Prediction**: The customer **will wait** ($ y = 1 $).  \n",
    "3. **Overfitting Solution**: Apply pruning or limit tree depth to prevent overfitting.  \n",
    "\n",
    "This solution demonstrates how to construct, use, and evaluate a decision tree model while addressing overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1dbead-4a96-4a64-9378-18c4b57ab4a4",
   "metadata": {},
   "source": [
    "### Exam Question 20.1:\n",
    "\n",
    "**Question**:  \n",
    "Consider the restaurant example discussed in Section 20.1. Suppose the following examples are provided:  \n",
    "\n",
    "1. **Example 1**: $ \\text{Alternate}(X_1) \\land \\text{Patrons}(X_1, \\text{Some}) \\land \\text{Hungry}(X_1) \\land \\text{WillWait}(X_1) $.  \n",
    "2. **Example 2**: $ \\neg \\text{Alternate}(X_2) \\land \\text{Patrons}(X_2, \\text{Full}) \\land \\neg \\text{Hungry}(X_2) \\land \\neg \\text{WillWait}(X_2) $.  \n",
    "3. **Example 3**: $ \\text{Alternate}(X_3) \\land \\text{Patrons}(X_3, \\text{Full}) \\land \\text{Hungry}(X_3) \\land \\text{WillWait}(X_3) $.  \n",
    "\n",
    "Starting with the initial hypothesis $ h_1: \\forall x \\, \\text{WillWait}(x) \\iff \\text{Alternate}(x) $, answer the following:  \n",
    "\n",
    "1. Identify whether each example is a **false positive**, **false negative**, or **consistent** with $ h_1 $.  \n",
    "2. Update the hypothesis $ h_1 $ incrementally using **generalization** or **specialization** as needed to fit the examples.  \n",
    "3. Write the final hypothesis after processing all examples.  \n",
    "\n",
    "---\n",
    "\n",
    "### Solution:\n",
    "\n",
    "#### **Step 1: Check consistency of $ h_1 $ with each example**\n",
    "\n",
    "1. **Example 1**:  \n",
    "   - $ \\text{Alternate}(X_1) $ is true.  \n",
    "   - $ h_1 $ predicts $ \\text{WillWait}(X_1) $, which matches the example.  \n",
    "   - **Consistent**.  \n",
    "\n",
    "2. **Example 2**:  \n",
    "   - $ \\text{Alternate}(X_2) $ is false.  \n",
    "   - $ h_1 $ predicts $ \\neg \\text{WillWait}(X_2) $, which matches the example.  \n",
    "   - **Consistent**.  \n",
    "\n",
    "3. **Example 3**:  \n",
    "   - $ \\text{Alternate}(X_3) $ is true.  \n",
    "   - $ h_1 $ predicts $ \\text{WillWait}(X_3) $, which matches the example.  \n",
    "   - **Consistent**.  \n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 2: Hypothesis Update**\n",
    "\n",
    "Since $ h_1 $ is consistent with all examples, no updates to the hypothesis are required.  \n",
    "\n",
    "---\n",
    "\n",
    "#### **Final Hypothesis**\n",
    "\n",
    "The hypothesis remains unchanged:  \n",
    "$$ h_1: \\forall x \\, \\text{WillWait}(x) \\iff \\text{Alternate}(x) $$\n",
    "\n",
    "---\n",
    "\n",
    "**Alternate Scenario**: If $ h_1 $ had mismatched an example, we would have:  \n",
    "- **Specialized $ h_1 $**: Add conditions to rule out false positives.  \n",
    "- **Generalized $ h_1 $**: Remove conditions to include false negatives.  \n",
    "\n",
    "**Exam Tips**:  \n",
    "- Identify consistency by comparing hypothesis predictions to the example's classification.  \n",
    "- Use specialization for false positives and generalization for false negatives.  \n",
    "- Revisit prior examples after each update to ensure consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664c1f61-db92-4443-9931-1f751ca97982",
   "metadata": {},
   "source": [
    "### Exam Question 20.3:\n",
    "\n",
    "**Question**:  \n",
    "The process of **Explanation-Based Learning (EBL)** involves generalizing specific observations into reusable rules using background knowledge. Consider the following scenario:  \n",
    "\n",
    "**Observation**: A student simplifies the expression $ 1 \\times (0 + X) $ to $ X $.  \n",
    "**Background Knowledge**:  \n",
    "1. $ \\text{Rewrite}(1 \\times u, u) $.  \n",
    "2. $ \\text{Rewrite}(0 + u, u) $.  \n",
    "3. $ \\text{ArithmeticUnknown}(x) \\to \\text{Primitive}(x) $.  \n",
    "4. $ \\text{Primitive}(x) \\to \\text{Simplify}(x, x) $.  \n",
    "\n",
    "**Tasks**:  \n",
    "1. **Explain**: Construct a proof for simplifying $ 1 \\times (0 + X) = X $ using the given background knowledge.  \n",
    "2. **Generalize**: Replace constants with variables to generalize the proof into a reusable rule.  \n",
    "3. **Extract Rule**: Write the final generalized rule.  \n",
    "4. **Simplify Rule**: Drop irrelevant conditions to simplify the rule.  \n",
    "\n",
    "---\n",
    "\n",
    "### Solution:\n",
    "\n",
    "#### **Step 1: Explain**\n",
    "\n",
    "Construct a proof using the background knowledge:  \n",
    "1. Start with the expression $ 1 \\times (0 + X) $.  \n",
    "2. Apply $ \\text{Rewrite}(1 \\times u, u) $ to simplify $ 1 \\times (0 + X) $ into $ 0 + X $.  \n",
    "3. Apply $ \\text{Rewrite}(0 + u, u) $ to simplify $ 0 + X $ into $ X $.  \n",
    "4. Recognize that $ X $ is $ \\text{Primitive}(X) $, which satisfies $ \\text{Simplify}(X, X) $.  \n",
    "\n",
    "Proof structure:  \n",
    "$$\n",
    "\\text{Rewrite}(1 \\times u, u) \\to \\text{Rewrite}(0 + u, u) \\to \\text{Simplify}(x, x).\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 2: Generalize**\n",
    "\n",
    "Replace constants $ 1, 0, X $ with variables $ x, y, z $:  \n",
    "1. Generalize $ 1 \\times (0 + X) $ to $ x \\times (y + z) $.  \n",
    "2. The proof becomes:  \n",
    "   $$\n",
    "   \\text{Rewrite}(x \\times u, u) \\to \\text{Rewrite}(y + u, u) \\to \\text{Simplify}(z, z).\n",
    "   $$\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 3: Extract Rule**\n",
    "\n",
    "Extract a rule from the generalized proof:  \n",
    "$$\n",
    "\\text{ArithmeticUnknown}(z) \\to \\text{Simplify}(x \\times (y + z), z).\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 4: Simplify Rule**\n",
    "\n",
    "Drop irrelevant conditions:  \n",
    "- The conditions $ \\text{Rewrite}(x \\times u, u) $ and $ \\text{Rewrite}(y + u, u) $ are universally true for any $ x, y, z $.  \n",
    "- The only necessary condition is $ \\text{ArithmeticUnknown}(z) $.  \n",
    "\n",
    "Final simplified rule:  \n",
    "$$\n",
    "\\text{ArithmeticUnknown}(z) \\to \\text{Simplify}(x \\times (y + z), z).\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Explanation:\n",
    "\n",
    "This question tests the student's ability to follow the steps of EBL, from constructing a proof to generalizing and simplifying it. The example highlights how EBL can convert specific observations into reusable knowledge, improving computational efficiency for future tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3f7dd8-5c4c-4067-8b17-1837f8dac78a",
   "metadata": {},
   "source": [
    "Here’s a detailed, worked example of a question related to **Section 21.2: Learning with Complete Data** that could appear on an exam:\n",
    "\n",
    "---\n",
    "\n",
    "### **Question: Estimating Parameters Using Maximum Likelihood**\n",
    "\n",
    "A bag of candy contains two flavors: **cherry** and **lime**. The proportion of cherry candies in the bag is represented by $ \\theta $, which is unknown. You unwrap 12 candies and observe the following sequence:  \n",
    "$$ \\text{cherry, lime, lime, cherry, lime, cherry, cherry, lime, lime, lime, cherry, lime} $$  \n",
    "1. Write down the likelihood function for $ \\theta $ based on the data.  \n",
    "2. Derive the maximum likelihood estimate (MLE) for $ \\theta $.  \n",
    "3. Calculate the MLE of $ \\theta $ for the given data.  \n",
    "4. Explain why the MLE is intuitive in this context.\n",
    "\n",
    "---\n",
    "\n",
    "### **Solution**\n",
    "\n",
    "#### 1. Likelihood Function:\n",
    "Let $ c $ represent the number of cherry candies and $ l $ the number of lime candies in the observed data. The likelihood function for $ \\theta $, the proportion of cherry candies, is:\n",
    "\n",
    "$$\n",
    "P(d|\\theta) = \\theta^c (1 - \\theta)^l\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $ c $ is the number of cherry candies.\n",
    "- $ l $ is the number of lime candies.\n",
    "- $ d $ is the observed data.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Deriving the MLE:\n",
    "To find the MLE of $ \\theta $, we maximize the likelihood function with respect to $ \\theta $. Since the log function is monotonic, we work with the **log-likelihood**:\n",
    "\n",
    "$$\n",
    "L(\\theta) = \\log P(d|\\theta) = c \\log \\theta + l \\log (1 - \\theta)\n",
    "$$\n",
    "\n",
    "Take the derivative of $ L(\\theta) $ with respect to $ \\theta $:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L(\\theta)}{\\partial \\theta} = \\frac{c}{\\theta} - \\frac{l}{1 - \\theta}\n",
    "$$\n",
    "\n",
    "Set $ \\frac{\\partial L(\\theta)}{\\partial \\theta} = 0 $ to find the critical point:\n",
    "\n",
    "$$\n",
    "\\frac{c}{\\theta} = \\frac{l}{1 - \\theta}\n",
    "$$\n",
    "\n",
    "Simplify:\n",
    "\n",
    "$$\n",
    "c (1 - \\theta) = l \\theta\n",
    "$$\n",
    "\n",
    "$$\n",
    "c - c \\theta = l \\theta\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\theta = \\frac{c}{c + l}\n",
    "$$\n",
    "\n",
    "Thus, the MLE for $ \\theta $ is:\n",
    "\n",
    "$$\n",
    "\\theta_{\\text{MLE}} = \\frac{c}{c + l}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Calculating the MLE:\n",
    "From the data:\n",
    "- Number of cherry candies ($ c $) = 5\n",
    "- Number of lime candies ($ l $) = 7\n",
    "- Total candies ($ c + l $) = 12\n",
    "\n",
    "Substitute into the formula:\n",
    "\n",
    "$$\n",
    "\\theta_{\\text{MLE}} = \\frac{c}{c + l} = \\frac{5}{12} \\approx 0.417\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. Intuition Behind the MLE:\n",
    "The MLE for $ \\theta $ is simply the observed proportion of cherry candies in the data. This makes sense intuitively because, in the absence of any prior information, the best estimate for $ \\theta $ is the proportion observed in the sample. As the sample size increases, the MLE converges to the true value of $ \\theta $.\n",
    "\n",
    "---\n",
    "\n",
    "### **Exam Tip:**\n",
    "Always show your work step-by-step for derivations, especially when solving for MLEs. Highlighting the intuition behind results can earn additional marks.\n",
    "\n",
    "Let me know if you'd like additional examples or questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9074879c-d080-487e-8928-92bbdf80c424",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
