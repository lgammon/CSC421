{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fea2194-c9b4-471b-a54c-cc9e939f15ef",
   "metadata": {},
   "source": [
    "# Ch 2\n",
    "Here’s a set of multiple-choice questions covering **PEAS description**, **task environments**, and **agent architectures**:\n",
    "\n",
    "---\n",
    "\n",
    "### **PEAS Description**\n",
    "**Question 1:**  \n",
    "Which of the following is NOT part of a PEAS description?  \n",
    "a) **Performance Measure**  \n",
    "b) **Environment**  \n",
    "c) **Actuators**  \n",
    "d) **Sensors**  \n",
    "e) **Agent Goals**\n",
    "\n",
    "**Correct Answer:** e) **Agent Goals**  \n",
    "*Explanation:* The PEAS description includes the Performance Measure, Environment, Actuators, and Sensors. Goals may be implicit but are not explicitly part of PEAS.\n",
    "\n",
    "---\n",
    "\n",
    "**Question 2:**  \n",
    "In a PEAS description for an autonomous taxi, which of the following would be classified as a sensor?  \n",
    "a) The steering mechanism.  \n",
    "b) The GPS system.  \n",
    "c) The accelerator pedal.  \n",
    "d) The navigation algorithm.  \n",
    "\n",
    "**Correct Answer:** b) **The GPS system**  \n",
    "*Explanation:* Sensors are responsible for perceiving the environment, and GPS provides location data. The other options represent actuators or internal processes.\n",
    "\n",
    "---\n",
    "\n",
    "### **Task Environments**\n",
    "**Question 3:**  \n",
    "A task environment where the agent has access to all relevant information about the current state is classified as:  \n",
    "a) Fully Observable  \n",
    "b) Partially Observable  \n",
    "c) Static  \n",
    "d) Deterministic  \n",
    "\n",
    "**Correct Answer:** a) **Fully Observable**  \n",
    "*Explanation:* Fully observable environments allow the agent to perceive the complete state relevant to decision-making.\n",
    "\n",
    "---\n",
    "\n",
    "**Question 4:**  \n",
    "Which of the following environments is best classified as **episodic**?  \n",
    "a) Chess  \n",
    "b) Image classification  \n",
    "c) Self-driving cars  \n",
    "d) Poker  \n",
    "\n",
    "**Correct Answer:** b) **Image classification**  \n",
    "*Explanation:* In episodic environments, each action is independent, as in image classification, where decisions about one image do not affect others.\n",
    "\n",
    "---\n",
    "\n",
    "**Question 5:**  \n",
    "In a dynamic environment, what challenge must an agent address?  \n",
    "a) Maintaining state information for partially observable aspects.  \n",
    "b) Adapting to changes in the environment while deliberating.  \n",
    "c) Handling deterministic state transitions.  \n",
    "d) Ensuring actions are independent of past states.\n",
    "\n",
    "**Correct Answer:** b) **Adapting to changes in the environment while deliberating**  \n",
    "*Explanation:* In dynamic environments, the agent must handle changes that occur during its decision-making process.\n",
    "\n",
    "---\n",
    "\n",
    "### **Agent Architectures**\n",
    "**Question 6:**  \n",
    "A reflex agent selects actions based on:  \n",
    "a) A predefined goal.  \n",
    "b) The utility of outcomes.  \n",
    "c) The current percept.  \n",
    "d) A model of the environment.  \n",
    "\n",
    "**Correct Answer:** c) **The current percept**  \n",
    "*Explanation:* Reflex agents react to current percepts without considering history or future consequences.\n",
    "\n",
    "---\n",
    "\n",
    "**Question 7:**  \n",
    "Which of the following agent types maintains an internal model of the environment to handle partially observable states?  \n",
    "a) Reflex Agent  \n",
    "b) Model-Based Agent  \n",
    "c) Utility-Based Agent  \n",
    "d) Learning Agent  \n",
    "\n",
    "**Correct Answer:** b) **Model-Based Agent**  \n",
    "*Explanation:* Model-based agents maintain an internal representation of the environment to infer information about unobservable aspects.\n",
    "\n",
    "---\n",
    "\n",
    "**Question 8:**  \n",
    "Which type of agent uses a utility function to evaluate and select actions that maximize expected outcomes?  \n",
    "a) Reflex Agent  \n",
    "b) Goal-Based Agent  \n",
    "c) Utility-Based Agent  \n",
    "d) Learning Agent  \n",
    "\n",
    "**Correct Answer:** c) **Utility-Based Agent**  \n",
    "*Explanation:* Utility-based agents use utility functions to make rational decisions based on the desirability of outcomes.\n",
    "\n",
    "---\n",
    "\n",
    "**Question 9:**  \n",
    "What distinguishes a learning agent from other types of agents?  \n",
    "a) It reacts to the current percept.  \n",
    "b) It updates its behavior based on experience.  \n",
    "c) It relies on pre-programmed rules to act.  \n",
    "d) It maximizes utility using a fixed model.  \n",
    "\n",
    "**Correct Answer:** b) **It updates its behavior based on experience**  \n",
    "*Explanation:* Learning agents adapt and improve their performance over time by learning from interactions with the environment.\n",
    "\n",
    "---\n",
    "\n",
    "**Question 10:**  \n",
    "A goal-based agent differs from a reflex agent because it:  \n",
    "a) Uses a utility function for decision-making.  \n",
    "b) Considers future actions to achieve objectives.  \n",
    "c) Does not require an internal model of the environment.  \n",
    "d) Operates only in episodic environments.  \n",
    "\n",
    "**Correct Answer:** b) **Considers future actions to achieve objectives**  \n",
    "*Explanation:* Goal-based agents use goals to guide their decision-making and plan sequences of actions.\n",
    "\n",
    "---\n",
    "\n",
    "These questions ensure comprehensive coverage of the topics and test understanding in a variety of ways. Let me know if you'd like more questions or explanations!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efb494b-9c83-4d44-b9ea-6b4aea8035f0",
   "metadata": {},
   "source": [
    "# ch 2 - asked for a lil more complex \n",
    "Here’s an updated set of slightly more complex multiple-choice questions to challenge a deeper understanding of the topics:\n",
    "\n",
    "---\n",
    "\n",
    "### **PEAS Description**\n",
    "**Question 1:**  \n",
    "You are designing a **medical diagnosis agent** that assists doctors by analyzing patient symptoms and recommending treatments. Its PEAS description includes:  \n",
    "- **Performance Measure:** Accuracy of diagnosis, speed of recommendations, and patient satisfaction.  \n",
    "- **Environment:** Patient records, current symptoms, medical staff input, and treatment outcomes.  \n",
    "- **Actuators:** Display screen, automated alerts, and voice instructions.  \n",
    "- **Sensors:** Touchscreen inputs, voice recognition, and medical test results.  \n",
    "\n",
    "Which of the following statements about this PEAS description is correct?  \n",
    "a) The actuators include sensors for medical test results.  \n",
    "b) The environment is fully observable because all necessary data is in the patient records.  \n",
    "c) The performance measure accounts for multiple objectives, not just accuracy.  \n",
    "d) Sensors and actuators must operate independently of the environment.\n",
    "\n",
    "**Correct Answer:** c) **The performance measure accounts for multiple objectives, not just accuracy.**  \n",
    "*Explanation:* The PEAS description considers multiple factors (accuracy, speed, and satisfaction) in its performance measure, while sensors and actuators interact with the environment.\n",
    "\n",
    "---\n",
    "\n",
    "**Question 2:**  \n",
    "For a **self-driving car**, which of the following would require a significant change to the PEAS description?  \n",
    "a) Adding a new camera sensor to detect pedestrians.  \n",
    "b) Modifying the performance measure to prioritize fuel efficiency over speed.  \n",
    "c) Replacing the steering system with a voice-controlled mechanism.  \n",
    "d) Increasing the number of roads in the agent’s map database.  \n",
    "\n",
    "**Correct Answer:** b) **Modifying the performance measure to prioritize fuel efficiency over speed.**  \n",
    "*Explanation:* Changing the performance measure significantly alters how the agent evaluates its actions, while the other options involve modifying components without fundamentally changing the agent's goals.\n",
    "\n",
    "---\n",
    "\n",
    "### **Task Environments**\n",
    "**Question 3:**  \n",
    "A **chess-playing robot** operates in a fully observable, deterministic, and discrete environment. However, when playing against an opponent in a noisy outdoor environment, it fails to detect moves accurately due to vision system limitations.  \n",
    "\n",
    "Which properties of the task environment have changed, and how should the agent adapt?  \n",
    "a) Fully observable to partially observable; the agent should maintain an internal model of the board state.  \n",
    "b) Deterministic to stochastic; the agent should use probabilistic reasoning to handle noisy observations.  \n",
    "c) Static to dynamic; the agent should continuously monitor and update its plans.  \n",
    "d) Single-agent to multi-agent; the agent should account for its opponent’s behavior.\n",
    "\n",
    "**Correct Answer:** a) **Fully observable to partially observable; the agent should maintain an internal model of the board state.**  \n",
    "*Explanation:* Noise in the vision system means the agent no longer has access to the complete state of the environment and must infer missing information using a model.\n",
    "\n",
    "---\n",
    "\n",
    "**Question 4:**  \n",
    "Consider an **automated warehouse robot** tasked with retrieving items from shelves and avoiding other robots. The task environment is partially observable, stochastic, multi-agent, sequential, dynamic, and continuous.  \n",
    "\n",
    "Which of the following statements best describes why the environment is **stochastic**?  \n",
    "a) The robot must continuously navigate changing obstacles.  \n",
    "b) The robot's sensors cannot detect the state of the entire warehouse.  \n",
    "c) The outcome of actions, like picking up items, may fail due to mechanical errors.  \n",
    "d) The robot operates alongside other agents competing for the same resources.\n",
    "\n",
    "**Correct Answer:** c) **The outcome of actions, like picking up items, may fail due to mechanical errors.**  \n",
    "*Explanation:* Stochasticity refers to uncertainty in the outcomes of actions, such as failures in executing a task like picking up an item.\n",
    "\n",
    "---\n",
    "\n",
    "### **Agent Architectures**\n",
    "**Question 5:**  \n",
    "A **reflex-based thermostat** adjusts the heating system based on the current room temperature. Which of the following limitations would most directly apply if the thermostat were placed in a multi-room house?  \n",
    "a) It cannot maintain an internal model of which rooms need heating.  \n",
    "b) It cannot optimize for energy efficiency across multiple rooms.  \n",
    "c) It cannot predict future temperature fluctuations in the house.  \n",
    "d) It cannot detect whether people are present in the house.  \n",
    "\n",
    "**Correct Answer:** a) **It cannot maintain an internal model of which rooms need heating.**  \n",
    "*Explanation:* Reflex agents act only on current percepts and cannot maintain internal models, making it difficult to manage multi-room environments.\n",
    "\n",
    "---\n",
    "\n",
    "**Question 6:**  \n",
    "A **goal-based agent** is deployed to navigate a maze. The agent must reach the goal while minimizing the number of steps taken. However, the environment contains obstacles that sometimes move unpredictably.  \n",
    "\n",
    "Which of the following is the most significant limitation of a purely goal-based agent in this scenario?  \n",
    "a) It cannot plan sequences of actions to reach the goal.  \n",
    "b) It cannot handle the trade-off between reaching the goal and avoiding obstacles.  \n",
    "c) It cannot adapt to changes in the environment after the goal is set.  \n",
    "d) It cannot evaluate the utility of intermediate states.  \n",
    "\n",
    "**Correct Answer:** b) **It cannot handle the trade-off between reaching the goal and avoiding obstacles.**  \n",
    "*Explanation:* Goal-based agents focus solely on achieving a predefined goal, while utility-based agents can evaluate trade-offs like obstacle avoidance.\n",
    "\n",
    "---\n",
    "\n",
    "**Question 7:**  \n",
    "Which of the following best illustrates the advantage of a **learning agent** over other architectures?  \n",
    "a) It can use sensors to perceive the environment without an internal model.  \n",
    "b) It adapts its behavior over time based on performance feedback.  \n",
    "c) It selects actions that maximize utility for each possible state.  \n",
    "d) It uses predefined rules to act on current percepts without learning.\n",
    "\n",
    "**Correct Answer:** b) **It adapts its behavior over time based on performance feedback.**  \n",
    "*Explanation:* A learning agent improves its performance by learning from interactions with the environment, unlike predefined or rule-based agents.\n",
    "\n",
    "---\n",
    "\n",
    "**Question 8:**  \n",
    "Which of the following modifications would turn a **utility-based agent** into a **learning agent**?  \n",
    "a) Adding a goal-oriented decision-making component.  \n",
    "b) Incorporating a feedback mechanism to update utility values over time.  \n",
    "c) Increasing the complexity of its utility function to handle dynamic environments.  \n",
    "d) Allowing the agent to switch between multiple predefined goals.\n",
    "\n",
    "**Correct Answer:** b) **Incorporating a feedback mechanism to update utility values over time.**  \n",
    "*Explanation:* Learning requires feedback and adaptation, allowing the agent to improve its decision-making by updating utility values dynamically.\n",
    "\n",
    "---\n",
    "\n",
    "These questions explore deeper connections between concepts, adding complexity by requiring application, analysis, and synthesis of the material. Let me know if you need more or a different focus!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ea7d68-f12f-411b-b3a8-9abc502243d0",
   "metadata": {},
   "source": [
    "# Ch 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7c741c-9917-42e0-918d-bf834271876f",
   "metadata": {},
   "source": [
    "Here is an updated version of the multiple-choice questions, now with explanations for each correct answer:\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 1: Problem Formulation**\n",
    "\n",
    "1. **What is the state space for this problem?**\n",
    "   - A. The robot's position on the grid.\n",
    "   - B. A list of all possible dirt configurations and the robot's position. **(Correct Answer)**\n",
    "   - C. The number of moves taken by the robot.\n",
    "   - D. The size of the grid.\n",
    "\n",
    "   **Explanation**: The state space must account for both the robot's position and the configuration of the dirt across the grid. This is necessary to differentiate between states with the same robot position but different cleaning progress.\n",
    "\n",
    "2. **What is the goal test for this problem?**\n",
    "   - A. The robot has moved over all cells.\n",
    "   - B. The robot's position is in the bottom-right corner of the grid.\n",
    "   - C. All cells in the grid are clean. **(Correct Answer)**\n",
    "   - D. The robot has completed a set number of actions.\n",
    "\n",
    "   **Explanation**: The goal of the vacuum robot is to ensure all cells are clean, regardless of its final position or the number of moves.\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 2: Uninformed Search**\n",
    "\n",
    "**For a problem with a shallow goal, which of the following uninformed search strategies is most likely to find the solution with minimal time and space requirements?**\n",
    "\n",
    "- A. Breadth-First Search (BFS)\n",
    "- B. Depth-First Search (DFS) **(Correct Answer)**\n",
    "- C. Uniform-Cost Search (UCS)\n",
    "- D. Iterative Deepening Depth-First Search (IDDFS)\n",
    "\n",
    "**Explanation**: For shallow goals, DFS is faster and uses less memory because it explores paths deeply before moving to another branch. While it is not guaranteed to find the optimal solution, it is efficient when the solution is near the root.\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 3: Uniform-Cost Search**\n",
    "\n",
    "**Which of the following best describes Uniform-Cost Search?**\n",
    "\n",
    "- A. Expands the shallowest nodes first.\n",
    "- B. Expands nodes in the order of their total path cost from the root. **(Correct Answer)**\n",
    "- C. Uses a heuristic to estimate the cost to the goal.\n",
    "- D. Always finds the solution with the fewest steps.\n",
    "\n",
    "**Explanation**: Uniform-Cost Search always expands the node with the smallest cumulative path cost ($g(n)$) from the root, ensuring it finds the least-cost solution. However, it doesn't use a heuristic, so it is not guided toward the goal.\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 4: A* Search and Heuristics**\n",
    "\n",
    "1. **Which of the following conditions must a heuristic satisfy for A* search to be admissible?**\n",
    "   - A. It must always underestimate the true cost to the goal. **(Correct Answer)**\n",
    "   - B. It must always overestimate the true cost to the goal.\n",
    "   - C. It must be computationally inexpensive to calculate.\n",
    "   - D. It must be equal to the actual cost in some states.\n",
    "\n",
    "   **Explanation**: An admissible heuristic never overestimates the true cost to the goal, ensuring that A* does not bypass the optimal solution.\n",
    "\n",
    "2. **If a heuristic $ h_1 $ dominates another heuristic $ h_2 $, which of the following is true?**\n",
    "   - A. $ h_1(n) \\leq h_2(n) $ for all nodes $ n $.\n",
    "   - B. $ h_1(n) \\geq h_2(n) $ for all nodes $ n $, and $ h_1(n) > h_2(n) $ for at least one node $ n $. **(Correct Answer)**\n",
    "   - C. $ h_1(n) = h_2(n) $ for all nodes $ n $.\n",
    "   - D. $ h_1(n) $ and $ h_2(n) $ must both overestimate the true cost.\n",
    "\n",
    "   **Explanation**: Dominance means that $ h_1(n) $ is always at least as accurate as $ h_2(n) $ (i.e., higher or equal values) and provides strictly better estimates for at least one node. This leads to fewer node expansions in A*.\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 5: Greedy Best-First Search**\n",
    "\n",
    "**Which of the following statements about Greedy Best-First Search is correct?**\n",
    "\n",
    "- A. It is guaranteed to find the shortest path to the goal.\n",
    "- B. It uses the evaluation function $ f(n) = g(n) + h(n) $, where $ g(n) $ is the path cost and $ h(n) $ is the heuristic.\n",
    "- C. It uses only the heuristic value $ h(n) $ to expand nodes. **(Correct Answer)**\n",
    "- D. It always expands the node with the smallest total cost from the start.\n",
    "\n",
    "**Explanation**: Greedy Best-First Search uses only the heuristic value $ h(n) $ to decide which node to expand, aiming for the most promising path to the goal. It does not account for the cost of the path already taken ($g(n)$), which makes it incomplete and suboptimal.\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 6: Comparison of Search Strategies**\n",
    "\n",
    "**Consider a tree search problem with branching factor $ b $, depth $ d $, and maximum depth $ m $. Which of the following is true about the time complexity of Breadth-First Search (BFS) and Depth-First Search (DFS)?**\n",
    "\n",
    "- A. BFS is $ O(b^d) $, DFS is $ O(b^m) $. **(Correct Answer)**\n",
    "- B. BFS is $ O(b^m) $, DFS is $ O(b^d) $.\n",
    "- C. Both BFS and DFS are $ O(b^d) $.\n",
    "- D. BFS is $ O(d^b) $, DFS is $ O(m^b) $.\n",
    "\n",
    "**Explanation**: BFS explores all nodes at each level, so its time complexity depends on the depth of the solution ($b^d$). DFS can potentially go to the maximum depth of the tree ($b^m$).\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 7: Iterative Deepening Search**\n",
    "\n",
    "**Which of the following is an advantage of Iterative Deepening Depth-First Search (IDDFS) over Breadth-First Search (BFS)?**\n",
    "\n",
    "- A. It is guaranteed to use less memory than BFS. **(Correct Answer)**\n",
    "- B. It always finds the optimal solution faster than BFS.\n",
    "- C. It avoids the overhead of recomputing repeated states.\n",
    "- D. It avoids exploring nodes at the same depth multiple times.\n",
    "\n",
    "**Explanation**: IDDFS combines the memory efficiency of DFS with the completeness of BFS. It explores nodes at each depth multiple times, but it requires significantly less memory than BFS.\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 8: Search Strategies and Completeness**\n",
    "\n",
    "**Which of the following search strategies is not complete if the state space is infinite?**\n",
    "\n",
    "- A. Breadth-First Search (BFS)\n",
    "- B. Uniform-Cost Search (UCS)\n",
    "- C. Depth-First Search (DFS) **(Correct Answer)**\n",
    "- D. Iterative Deepening Depth-First Search (IDDFS)\n",
    "\n",
    "**Explanation**: DFS is not complete in infinite state spaces because it may follow an infinitely long path without ever finding a solution. The other strategies can systematically explore the space to guarantee finding a solution if one exists.\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 9: Heuristics in Relaxed Problems**\n",
    "\n",
    "1. **Which of the following describes a relaxed problem used to derive admissible heuristics?**\n",
    "   - A. A problem with fewer constraints than the original. **(Correct Answer)**\n",
    "   - B. A problem with additional constraints compared to the original.\n",
    "   - C. A simpler heuristic that ignores the actual state space.\n",
    "   - D. A problem that always has an overestimated solution cost.\n",
    "\n",
    "   **Explanation**: A relaxed problem simplifies the constraints of the original problem, allowing admissible heuristics to be derived from optimal solutions to the relaxed version.\n",
    "\n",
    "2. **For the 8-puzzle problem, which of the following heuristics represents a solution to a relaxed version of the problem?**\n",
    "   - A. Number of tiles in their correct positions.\n",
    "   - B. Number of misplaced tiles.\n",
    "   - C. Number of tiles that can move to any position.\n",
    "   - D. Sum of tile distances to their correct positions (Manhattan distance). **(Correct Answer)**\n",
    "\n",
    "   **Explanation**: The Manhattan distance heuristic assumes tiles can move independently of other tiles, which is a relaxation of the actual 8-puzzle constraints.\n",
    "\n",
    "---\n",
    "\n",
    "These questions now include both correct answers and detailed explanations to aid understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c0c939-1696-421c-bbb2-9ea8b30ad203",
   "metadata": {},
   "source": [
    "# Ch 6\n",
    "### **Question 1: Formulating a Problem as a CSP**\n",
    "\n",
    "**Question:**\n",
    "You are tasked with scheduling three classes, $ C_1, C_2, C_3 $, in a school. Each class can be held in one of three time slots: $ \\{1, 2, 3\\} $. However, $ C_1 $ and $ C_2 $ cannot be held at the same time, and $ C_2 $ and $ C_3 $ cannot be held at the same time. How should this problem be formulated as a CSP?\n",
    "\n",
    "A)  \n",
    "- Variables: $ X = \\{C_1, C_2, C_3\\} $  \n",
    "- Domains: $ D(C_1) = \\{1, 2, 3\\}, D(C_2) = \\{1, 2, 3\\}, D(C_3) = \\{1, 2, 3\\} $  \n",
    "- Constraints: $ C_1 = C_2 $, $ C_2 \\neq C_3 $.\n",
    "\n",
    "B) **(Correct Answer)**  \n",
    "- Variables: $ X = \\{C_1, C_2, C_3\\} $  \n",
    "- Domains: $ D(C_1) = D(C_2) = D(C_3) = \\{1, 2, 3\\} $  \n",
    "- Constraints: $ C_1 \\neq C_2 $, $ C_2 \\neq C_3 $.\n",
    "\n",
    "C)  \n",
    "- Variables: $ X = \\{C_1, C_2, C_3\\} $  \n",
    "- Domains: $ D(C_1) = D(C_2) = D(C_3) = \\{1, 2, 3\\} $  \n",
    "- Constraints: $ C_1 \\neq C_2 $, $ C_2 = C_3 $.\n",
    "\n",
    "D)  \n",
    "- Variables: $ X = \\{C_1, C_2, C_3\\} $  \n",
    "- Domains: $ D(C_1) = \\{1, 2\\}, D(C_2) = \\{1, 2, 3\\}, D(C_3) = \\{1, 3\\} $  \n",
    "- Constraints: $ C_1 \\neq C_2 $, $ C_2 \\neq C_3 $.\n",
    "\n",
    "**Answer: B**  \n",
    "- **Reasoning**:  \n",
    "  In CSP formulation, we specify:\n",
    "  - **Variables**: Each class corresponds to one variable: $ \\{C_1, C_2, C_3\\} $.  \n",
    "  - **Domains**: Each class can take values from $ \\{1, 2, 3\\} $, representing time slots. Thus, $ D(C_1) = D(C_2) = D(C_3) = \\{1, 2, 3\\} $.\n",
    "  - **Constraints**: $ C_1 \\neq C_2 $ ensures $ C_1 $ and $ C_2 $ are not in the same slot. Similarly, $ C_2 \\neq C_3 $ ensures $ C_2 $ and $ C_3 $ differ.  \n",
    "\n",
    "  - **Why the other options are wrong**:  \n",
    "    - A specifies $ C_1 = C_2 $, which violates the problem requirements.  \n",
    "    - C specifies $ C_2 = C_3 $, contradicting the constraint that $ C_2 \\neq C_3 $.  \n",
    "    - D incorrectly restricts the domains of $ C_1 $ and $ C_3 $ without justification.\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 2: CSP as a Special Case of Search**\n",
    "\n",
    "**Question:**\n",
    "You are solving a map-coloring problem using backtracking search. The regions to color are $ A, B, C $, with domains $ D(A) = D(B) = D(C) = \\{\\text{Red, Green, Blue}\\} $. The constraints are $ A \\neq B $, $ B \\neq C $, and $ A \\neq C $. The search tree starts with $ A = \\text{Red} $. Which of the following is the correct sequence of steps to find a solution, assuming forward checking is used?\n",
    "\n",
    "A) **(Correct Answer)**  \n",
    "1. Assign $ A = \\text{Red} $.  \n",
    "2. Prune $ \\text{Red} $ from $ D(B) $ and $ D(C) $.  \n",
    "3. Assign $ B = \\text{Green} $.  \n",
    "4. Prune $ \\text{Green} $ from $ D(C) $.  \n",
    "5. Assign $ C = \\text{Blue} $.  \n",
    "\n",
    "B)  \n",
    "1. Assign $ A = \\text{Red} $.  \n",
    "2. Prune $ \\text{Red} $ from $ D(B) $ and $ D(C) $.  \n",
    "3. Assign $ B = \\text{Blue} $.  \n",
    "4. Prune $ \\text{Blue} $ from $ D(C) $.  \n",
    "5. Assign $ C = \\text{Green} $.  \n",
    "\n",
    "C)  \n",
    "1. Assign $ A = \\text{Red} $.  \n",
    "2. Prune $ \\text{Red} $ from $ D(B) $.  \n",
    "3. Assign $ B = \\text{Blue} $.  \n",
    "4. Prune $ \\text{Blue} $ from $ D(C) $.  \n",
    "5. Assign $ C = \\text{Red} $.  \n",
    "\n",
    "D)  \n",
    "1. Assign $ A = \\text{Red} $.  \n",
    "2. Prune $ \\text{Red} $ from $ D(B) $.  \n",
    "3. Assign $ B = \\text{Green} $.  \n",
    "4. Prune $ \\text{Green} $ from $ D(C) $.  \n",
    "5. Assign $ C = \\text{Green} $.  \n",
    "\n",
    "**Answer: A**  \n",
    "- **Reasoning**:  \n",
    "  Using **backtracking search with forward checking**:\n",
    "  - Start with $ A = \\text{Red} $. Forward checking prunes $ \\text{Red} $ from the domains of $ B $ and $ C $, so $ D(B) = D(C) = \\{\\text{Green, Blue}\\} $.\n",
    "  - Assign $ B = \\text{Green} $, which prunes $ \\text{Green} $ from $ D(C) $, leaving $ D(C) = \\{\\text{Blue}\\} $.\n",
    "  - Assign $ C = \\text{Blue} $, satisfying all constraints.  \n",
    "\n",
    "  - **Why the other options are wrong**:  \n",
    "    - B assigns $ B = \\text{Blue} $ but does not align with least constraining value logic, as it results in $ C = \\text{Green} $, which violates a constraint.  \n",
    "    - C assigns $ C = \\text{Red} $, violating $ A \\neq C $.  \n",
    "    - D assigns $ C = \\text{Green} $, violating $ B \\neq C $.\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 3: Inference in CSP**\n",
    "\n",
    "**Question:**\n",
    "Consider the following CSP with variables $ X = \\{X_1, X_2, X_3\\} $ and domains:  \n",
    "- $ D(X_1) = \\{1, 2, 3\\} $  \n",
    "- $ D(X_2) = \\{1, 3\\} $  \n",
    "- $ D(X_3) = \\{2, 3\\} $\n",
    "\n",
    "The constraints are:  \n",
    "- $ X_1 \\neq X_2 $  \n",
    "- $ X_2 \\neq X_3 $  \n",
    "- $ X_1 \\neq X_3 $  \n",
    "\n",
    "Using the **AC-3 algorithm**, what are the final domains for each variable?\n",
    "\n",
    "A) **(Correct Answer)**  \n",
    "- $ D(X_1) = \\{1, 2, 3\\} $  \n",
    "- $ D(X_2) = \\{1, 3\\} $  \n",
    "- $ D(X_3) = \\{2, 3\\} $  \n",
    "\n",
    "B)  \n",
    "- $ D(X_1) = \\{2, 3\\} $  \n",
    "- $ D(X_2) = \\{1, 3\\} $  \n",
    "- $ D(X_3) = \\{2, 3\\} $  \n",
    "\n",
    "C)  \n",
    "- $ D(X_1) = \\{1, 2\\} $  \n",
    "- $ D(X_2) = \\{1, 3\\} $  \n",
    "- $ D(X_3) = \\{2, 3\\} $  \n",
    "\n",
    "D)  \n",
    "- $ D(X_1) = \\{2, 3\\} $  \n",
    "- $ D(X_2) = \\{3\\} $  \n",
    "- $ D(X_3) = \\{2, 3\\} $  \n",
    "\n",
    "**Answer: A**  \n",
    "- **Reasoning**:  \n",
    "  The **AC-3 algorithm** enforces arc consistency. In this case, no domains are reduced because:\n",
    "  - Every value in $ D(X_1) $ has a consistent value in $ D(X_2) $ and $ D(X_3) $, and so on.  \n",
    "  Therefore, the domains remain unchanged.\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 4: Combining Inference and Search**\n",
    "\n",
    "**Question:**\n",
    "In a CSP with variables $ A, B, C $, each has a domain $ \\{1, 2, 3\\} $. The constraints are:  \n",
    "- $ A \\neq B $,  \n",
    "- $ B \\neq C $,  \n",
    "- $ A \\neq C $.\n",
    "\n",
    "Using **backtracking search with forward checking**, which of the following partial assignments causes a conflict and requires backtracking?\n",
    "\n",
    "A) **(Correct Answer)**  \n",
    "- Assign $ A = 1 $  \n",
    "- Assign $ B = 2 $  \n",
    "- Assign $ C = 1 $  \n",
    "\n",
    "B)  \n",
    "- Assign $ A = 2 $  \n",
    "- Assign $ B = 2 $  \n",
    "\n",
    "C)  \n",
    "- Assign $ A = 1 $  \n",
    "- Assign $ B = 3 $  \n",
    "- Assign $ C = 2 $  \n",
    "\n",
    "D)  \n",
    "- Assign $ A = 3 $  \n",
    "- Assign $ B = 2 $  \n",
    "- Assign $ C = 1 $  \n",
    "\n",
    "**Answer: A**  \n",
    "- **Reasoning**:  \n",
    "  - $ A = 1 $, $ B = 2 $, and $ C = 1 $ causes $ A \\neq C $ to be violated, requiring backtracking.  \n",
    "  - **Why the other options are wrong**:  \n",
    "    - B is incomplete but does not violate any constraints yet.  \n",
    "    - C and D satisfy all constraints for the given assignments.  \n",
    "\n",
    "--- \n",
    "\n",
    "This format integrates reasoning for both correct and incorrect answers, mimicking the thought process for an open-book exam. Let me know if you need further clarification!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9035791c-693c-41f3-bb36-d7478c137282",
   "metadata": {},
   "source": [
    "# ch 7 \n",
    "### **Multiple Choice Questions: Propositional Logic and Theorem Proving**\n",
    "\n",
    "---\n",
    "\n",
    "#### **Question 1: Formulating Problems in Propositional Logic**\n",
    "**Problem:**  \n",
    "A robot is navigating a grid world. At each square, it can perceive whether there is a pit nearby. If the robot perceives a breeze at square $ A $, then there is at least one pit in the adjacent squares $ B, C, D, $ or $ E $.  \n",
    "\n",
    "Which of the following propositional logic sentences correctly represents this scenario?\n",
    "\n",
    "1. $ \\text{Breeze}_A \\implies (\\text{Pit}_B \\land \\text{Pit}_C \\land \\text{Pit}_D \\land \\text{Pit}_E) $\n",
    "2. $ \\text{Breeze}_A \\iff (\\text{Pit}_B \\lor \\text{Pit}_C \\lor \\text{Pit}_D \\lor \\text{Pit}_E) $\n",
    "3. $ \\text{Breeze}_A \\implies (\\text{Pit}_B \\lor \\text{Pit}_C \\lor \\text{Pit}_D \\lor \\text{Pit}_E) $\n",
    "4. $ \\text{Breeze}_A \\land (\\text{Pit}_B \\lor \\text{Pit}_C \\lor \\text{Pit}_D \\lor \\text{Pit}_E) $\n",
    "\n",
    "**Answer:** 3. $ \\text{Breeze}_A \\implies (\\text{Pit}_B \\lor \\text{Pit}_C \\lor \\text{Pit}_D \\lor \\text{Pit}_E) $  \n",
    "\n",
    "**Reasoning:**  \n",
    "A breeze at square $ A $ indicates that there is at least one pit in the adjacent squares, which corresponds to a disjunction ($ \\lor $) of the propositions $ \\text{Pit}_B, \\text{Pit}_C, \\text{Pit}_D, \\text{Pit}_E $. The correct logical relationship is an implication ($ \\implies $), not equivalence ($ \\iff $), because a breeze implies a pit nearby, but the absence of a breeze does not guarantee the absence of pits.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Question 2: Understanding Logic Notation**\n",
    "**Problem:**  \n",
    "Which of the following is **not** logically equivalent to $ A \\lor (B \\land C) $?  \n",
    "\n",
    "1. $ (A \\lor B) \\land (A \\lor C) $  \n",
    "2. $ (A \\land B) \\lor (A \\land C) $  \n",
    "3. $ (A \\lor B) \\land C $  \n",
    "4. $ (B \\land C) \\lor A $\n",
    "\n",
    "**Answer:** 3. $ (A \\lor B) \\land C $  \n",
    "\n",
    "**Reasoning:**  \n",
    "- $ A \\lor (B \\land C) $ is equivalent to $ (B \\land C) \\lor A $ by commutativity (Answer 4).  \n",
    "- Using distributive laws, $ A \\lor (B \\land C) \\equiv (A \\lor B) \\land (A \\lor C) $ (Answer 1).  \n",
    "- Answer 2 is incorrect because $ (A \\land B) \\lor (A \\land C) $ does not distribute properly in this form.  \n",
    "- $ (A \\lor B) \\land C $ (Answer 3) is not equivalent since it requires $ C $ to be true, which is not required in $ A \\lor (B \\land C) $.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Question 3: Prove Entailment by Model Checking**\n",
    "**Problem:**  \n",
    "Given $ \\text{KB} = \\{A \\implies B, B \\implies C, A\\} $, which of the following statements is entailed by $ \\text{KB} $?  \n",
    "\n",
    "1. $ C $  \n",
    "2. $ \\neg A \\lor C $  \n",
    "3. $ \\neg C $  \n",
    "4. $ A \\land C $\n",
    "\n",
    "**Answer:** 1. $ C $  \n",
    "\n",
    "**Reasoning:**  \n",
    "Using model checking:\n",
    "- $ A \\implies B $: If $ A = \\text{True} $, then $ B = \\text{True} $.  \n",
    "- $ B \\implies C $: If $ B = \\text{True} $, then $ C = \\text{True} $.  \n",
    "- Since $ A $ is given as $ \\text{True} $, we deduce $ C = \\text{True} $.  \n",
    "Thus, $ C $ is entailed.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Question 4: Deduction Theorem and Proof by Contradiction**\n",
    "**Problem:**  \n",
    "Which of the following steps correctly applies proof by contradiction to show that $ A \\land B \\implies C $ is valid when $ A = \\text{True} $ and $ B = \\text{True} $?  \n",
    "\n",
    "1. Assume $ A \\land B \\land \\neg C $ and show this leads to a contradiction.  \n",
    "2. Assume $ \\neg C $ and deduce $ \\neg A \\lor \\neg B $.  \n",
    "3. Assume $ C $ and show $ A \\land B \\land \\neg C $ leads to a contradiction.  \n",
    "4. Assume $ A \\lor B \\lor \\neg C $ and derive $ \\neg C $.\n",
    "\n",
    "**Answer:** 1. Assume $ A \\land B \\land \\neg C $ and show this leads to a contradiction.  \n",
    "\n",
    "**Reasoning:**  \n",
    "Proof by contradiction involves assuming the negation of the statement to be proved and showing that this assumption leads to a contradiction. Here:\n",
    "- Assume $ A \\land B \\land \\neg C $.\n",
    "- $ A \\land B $ implies $ C $, so $ \\neg C $ contradicts $ C $.  \n",
    "\n",
    "---\n",
    "\n",
    "#### **Question 5: Principles of Theorem Proving vs. Model Checking**\n",
    "**Problem:**  \n",
    "Which of the following statements best distinguishes **theorem proving** from **model checking**?  \n",
    "\n",
    "1. Theorem proving is sound but incomplete; model checking is sound and complete.  \n",
    "2. Theorem proving directly proves logical equivalences; model checking evaluates all possible models.  \n",
    "3. Theorem proving uses truth tables to evaluate entailment; model checking uses resolution.  \n",
    "4. Theorem proving is computationally faster than model checking for large problems.\n",
    "\n",
    "**Answer:** 2. Theorem proving directly proves logical equivalences; model checking evaluates all possible models.  \n",
    "\n",
    "**Reasoning:**  \n",
    "- **Theorem Proving:** Uses logical rules like resolution, deduction, and proof by contradiction to derive conclusions. It focuses on symbolic manipulation rather than enumerating all models.  \n",
    "- **Model Checking:** Explicitly evaluates all possible truth assignments (models) to determine satisfiability or entailment.  \n",
    "Thus, Answer 2 correctly highlights the key distinction.\n",
    "\n",
    "---\n",
    "\n",
    "### **Recap of Concepts Tested**\n",
    "1. **Formulate Problems in Propositional Logic** (Q1)\n",
    "2. **Understand Logic Notation** (Q2)\n",
    "3. **Prove Entailment by Model Checking** (Q3)\n",
    "4. **Deduction Theorem and Proof by Contradiction** (Q4)\n",
    "5. **Principles of Theorem Proving vs. Model Checking** (Q5)\n",
    "\n",
    "Let me know if you'd like more questions or further elaboration!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b2d17c-c65b-4f7e-beb0-e951904f3083",
   "metadata": {},
   "source": [
    "Here are **five more open-book multiple-choice questions** designed to test the skills and concepts related to propositional logic, model checking, theorem proving, and related reasoning techniques.\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 6: Translate Natural Language to Propositional Logic**\n",
    "**Problem:**  \n",
    "A burglar alarm goes off ($ A $) if the motion detector is triggered ($ M $) or the window is broken ($ W $). Additionally, the window is broken only if it is windy ($ \\text{Windy} $).\n",
    "\n",
    "Which propositional logic formulation correctly represents these rules?\n",
    "\n",
    "1. $ A \\iff (M \\lor W) \\land (W \\implies \\text{Windy}) $  \n",
    "2. $ A \\implies (M \\lor W) \\land (\\text{Windy} \\implies W) $  \n",
    "3. $ A \\iff (M \\lor W) \\land (\\text{Windy} \\implies W) $  \n",
    "4. $ A \\implies (M \\lor W) \\lor (W \\implies \\text{Windy}) $  \n",
    "\n",
    "**Answer:** 3. $ A \\iff (M \\lor W) \\land (\\text{Windy} \\implies W) $  \n",
    "\n",
    "**Reasoning:**  \n",
    "- $ A \\iff (M \\lor W) $: The alarm goes off if and only if the motion detector or window break is triggered.  \n",
    "- $ W \\implies \\text{Windy} $: The window being broken implies it is windy.  \n",
    "Answer 3 correctly combines these with $ \\land $, while other options misuse implications or disjunctions.\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 7: Using Resolution to Prove Entailment**\n",
    "**Problem:**  \n",
    "Consider the knowledge base $ \\text{KB} = \\{A \\lor B, \\neg A \\lor C, \\neg B\\} $.  \n",
    "Which of the following statements is entailed by $ \\text{KB} $ using resolution?\n",
    "\n",
    "1. $ C $  \n",
    "2. $ \\neg C $  \n",
    "3. $ A $  \n",
    "4. $ B \\land C $\n",
    "\n",
    "**Answer:** 1. $ C $  \n",
    "\n",
    "**Reasoning:**  \n",
    "- From $ A \\lor B $ and $ \\neg B $, resolve $ A $.  \n",
    "- From $ A $ and $ \\neg A \\lor C $, resolve $ C $.  \n",
    "Thus, $ C $ is entailed by $ \\text{KB} $.\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 8: Prove Unsatisfiability via Model Checking**\n",
    "**Problem:**  \n",
    "Given the sentence $ S = (P \\lor Q) \\land (\\neg P \\lor R) \\land (\\neg Q \\lor \\neg R) $, which of the following truth assignments proves that $ S $ is unsatisfiable?\n",
    "\n",
    "1. $ P = \\text{True}, Q = \\text{False}, R = \\text{True} $  \n",
    "2. $ P = \\text{False}, Q = \\text{True}, R = \\text{False} $  \n",
    "3. $ P = \\text{False}, Q = \\text{False}, R = \\text{True} $  \n",
    "4. None of the above  \n",
    "\n",
    "**Answer:** 4. None of the above  \n",
    "\n",
    "**Reasoning:**  \n",
    "To prove unsatisfiability, all possible truth assignments must be checked. None of the options satisfy $ S $ under all conditions. Model checking involves verifying that $ S $ evaluates to false for every combination of $ P, Q, R $.\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 9: Theorem Proving and Proof by Contradiction**\n",
    "**Problem:**  \n",
    "You need to prove $ A \\land B \\implies C $ using proof by contradiction. Which of the following steps is valid?\n",
    "\n",
    "1. Assume $ \\neg (A \\land B) \\lor C $ and show a contradiction.  \n",
    "2. Assume $ A \\land B \\land \\neg C $ and show a contradiction.  \n",
    "3. Assume $ C \\lor \\neg (A \\land B) $ and show a contradiction.  \n",
    "4. Assume $ A \\lor B \\land \\neg C $ and show a contradiction.\n",
    "\n",
    "**Answer:** 2. Assume $ A \\land B \\land \\neg C $ and show a contradiction.  \n",
    "\n",
    "**Reasoning:**  \n",
    "Proof by contradiction requires negating the entire proposition $ A \\land B \\implies C $, which becomes $ A \\land B \\land \\neg C $. From this assumption, show that it leads to a contradiction in the KB.\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 10: Principles of Theorem Proving vs. Model Checking**\n",
    "**Problem:**  \n",
    "Which of the following correctly compares theorem proving with model checking?\n",
    "\n",
    "1. Theorem proving relies on checking all possible models; model checking uses logical rules to infer conclusions.  \n",
    "2. Model checking can always prove entailment; theorem proving is incomplete.  \n",
    "3. Theorem proving uses inference rules like resolution and proof by contradiction, while model checking evaluates the truth of a sentence under every possible interpretation.  \n",
    "4. Model checking is computationally faster for large propositional logic problems than theorem proving.\n",
    "\n",
    "**Answer:** 3. Theorem proving uses inference rules like resolution and proof by contradiction, while model checking evaluates the truth of a sentence under every possible interpretation.  \n",
    "\n",
    "**Reasoning:**  \n",
    "- Theorem proving applies symbolic inference methods, including resolution, forward chaining, and proof by contradiction.  \n",
    "- Model checking evaluates every possible truth assignment (i.e., all models) to determine entailment or satisfiability.  \n",
    "- Both methods are sound, but model checking is exhaustive and computationally expensive for large domains.\n",
    "\n",
    "---\n",
    "\n",
    "### Recap of New Concepts Covered\n",
    "1. **Translating natural language to propositional logic** (Q6).\n",
    "2. **Resolution as an inference rule** (Q7).\n",
    "3. **Proving unsatisfiability using model checking** (Q8).\n",
    "4. **Proof by contradiction** (Q9).\n",
    "5. **Key differences between theorem proving and model checking** (Q10).\n",
    "\n",
    "Let me know if you'd like additional questions or expanded explanations!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527ab9f8-1b26-462f-b885-19b5d6e8508e",
   "metadata": {},
   "source": [
    "# Ch 8 \n",
    "\n",
    "Here is a series of multiple-choice, open-book exam questions that require problem-solving and understanding of **First-Order Logic (FOL)** concepts. Each question includes reasoning and an answer key.\n",
    "\n",
    "---\n",
    "\n",
    "### Question 1: Formulating Problems Using FOL\n",
    "\n",
    "#### Question:\n",
    "You are modeling a domain of students and courses. A student is considered \"successful\" if they pass all their courses. Which FOL formula correctly expresses this statement?\n",
    "\n",
    "(A) $ \\forall x \\, Successful(x) \\implies (\\exists y \\, Course(y) \\land Passed(x, y)) $  \n",
    "(B) $ \\forall x \\, (\\forall y \\, Course(y) \\implies Passed(x, y)) \\implies Successful(x) $  \n",
    "(C) $ \\forall x \\, Successful(x) \\iff (\\forall y \\, Course(y) \\implies Passed(x, y)) $  \n",
    "(D) $ \\exists x \\, (\\forall y \\, Passed(x, y)) \\land Successful(x) $\n",
    "\n",
    "#### Answer:\n",
    "**(C)** $ \\forall x \\, Successful(x) \\iff (\\forall y \\, Course(y) \\implies Passed(x, y)) $.\n",
    "\n",
    "#### Reasoning:\n",
    "- The formula must state that a student $ x $ is \"successful\" if and only if, for every course $ y $, $ y $ being a course implies that $ x $ passed $ y $. Option (C) captures this bi-conditional relationship between success and passing all courses.\n",
    "\n",
    "---\n",
    "\n",
    "### Question 2: Understanding Universal and Existential Quantifiers\n",
    "\n",
    "#### Question:\n",
    "Which of the following sentences correctly expresses, \"There is at least one person who likes every book\"?\n",
    "\n",
    "(A) $ \\exists x \\, \\forall y \\, Likes(x, y) $  \n",
    "(B) $ \\forall x \\, \\exists y \\, Likes(x, y) $  \n",
    "(C) $ \\forall y \\, \\exists x \\, Likes(x, y) $  \n",
    "(D) $ \\exists y \\, \\forall x \\, Likes(x, y) $\n",
    "\n",
    "#### Answer:\n",
    "**(A)** $ \\exists x \\, \\forall y \\, Likes(x, y) $.\n",
    "\n",
    "#### Reasoning:\n",
    "- $ \\exists x $ means \"there exists a person\" $ x $, and $ \\forall y $ means \"for every book\" $ y $. Together, $ \\exists x \\, \\forall y \\, Likes(x, y) $ states that there is a person who likes all books.\n",
    "\n",
    "---\n",
    "\n",
    "### Question 3: Translating English Sentences to FOL\n",
    "\n",
    "#### Question:\n",
    "Translate the sentence \"All employees report to a manager who is not themselves\" into FOL.\n",
    "\n",
    "(A) $ \\forall x \\, (Employee(x) \\implies \\exists y \\, (Manager(y) \\land ReportsTo(x, y))) $  \n",
    "(B) $ \\forall x \\, (Employee(x) \\implies \\exists y \\, (Manager(y) \\land ReportsTo(x, y) \\land x \\neq y)) $  \n",
    "(C) $ \\forall x \\, (Employee(x) \\land \\exists y \\, (Manager(y) \\land ReportsTo(x, y) \\land x = y)) $  \n",
    "(D) $ \\forall x \\, \\exists y \\, (Employee(x) \\land Manager(y) \\implies ReportsTo(x, y)) $\n",
    "\n",
    "#### Answer:\n",
    "**(B)** $ \\forall x \\, (Employee(x) \\implies \\exists y \\, (Manager(y) \\land ReportsTo(x, y) \\land x \\neq y)) $.\n",
    "\n",
    "#### Reasoning:\n",
    "- $ \\forall x $: For every employee $ x $.  \n",
    "- $ \\exists y $: There exists a manager $ y $.  \n",
    "- $ Manager(y) \\land ReportsTo(x, y) $: $ y $ is a manager and $ x $ reports to $ y $.  \n",
    "- $ x \\neq y $: Ensures that the employee does not report to themselves.\n",
    "\n",
    "---\n",
    "\n",
    "### Question 4: Substitution of Variables with Specific Objects\n",
    "\n",
    "#### Question:\n",
    "Given the sentence $ \\forall x \\, Loves(x, Chocolate) $, which of the following is **not** a valid substitution?\n",
    "\n",
    "(A) $ Loves(Alice, Chocolate) $  \n",
    "(B) $ Loves(Chocolate, Chocolate) $  \n",
    "(C) $ \\forall y \\, Loves(y, Chocolate) $  \n",
    "(D) $ Loves(x, Chocolate) $\n",
    "\n",
    "#### Answer:\n",
    "**(D)** $ Loves(x, Chocolate) $.\n",
    "\n",
    "#### Reasoning:\n",
    "- Substitution replaces the quantified variable $ x $ with a specific constant (e.g., $ Alice $) or another quantified variable. $ Loves(x, Chocolate) $ is invalid because it does not remove the quantifier $ \\forall x $, violating substitution rules.\n",
    "\n",
    "---\n",
    "\n",
    "### Question 5: Understanding the Use of Equality\n",
    "\n",
    "#### Question:\n",
    "Which FOL formula expresses, \"No two people have the same parent\"?\n",
    "\n",
    "(A) $ \\forall x, y, p \\, (Parent(p, x) \\land Parent(p, y)) \\implies x = y $  \n",
    "(B) $ \\forall x, y, p \\, (Parent(p, x) \\land Parent(p, y)) \\implies x \\neq y $  \n",
    "(C) $ \\forall x, y, p \\, (x \\neq y \\implies Parent(p, x) \\lor Parent(p, y)) $  \n",
    "(D) $ \\forall x, y \\, x \\neq y \\implies \\exists p \\, Parent(p, x) \\land Parent(p, y) $\n",
    "\n",
    "#### Answer:\n",
    "**(A)** $ \\forall x, y, p \\, (Parent(p, x) \\land Parent(p, y)) \\implies x = y $.\n",
    "\n",
    "#### Reasoning:\n",
    "- $ \\forall x, y, p $: For every pair of people $ x, y $ and parent $ p $.  \n",
    "- $ Parent(p, x) \\land Parent(p, y) $: $ p $ is a parent of $ x $ and $ y $.  \n",
    "- $ x = y $: Ensures that $ x $ and $ y $ are the same person, prohibiting two different people from having the same parent.\n",
    "\n",
    "---\n",
    "\n",
    "### Bonus Question: Composite Skills\n",
    "\n",
    "#### Question:\n",
    "Translate the sentence \"There is a person who is both a teacher and a student, and who only teaches courses they take\" into FOL.\n",
    "\n",
    "(A) $ \\exists x \\, (Teacher(x) \\land Student(x) \\land \\forall y \\, (Teaches(x, y) \\implies Takes(x, y))) $  \n",
    "(B) $ \\forall x \\, (Teacher(x) \\lor Student(x) \\land \\forall y \\, (Teaches(x, y) \\implies Takes(x, y))) $  \n",
    "(C) $ \\exists x \\, (Teacher(x) \\land Student(x) \\land \\exists y \\, (Teaches(x, y) \\implies Takes(x, y))) $  \n",
    "(D) $ \\forall x \\, (Teacher(x) \\land Student(x) \\lor \\exists y \\, (Teaches(x, y) \\implies Takes(x, y))) $\n",
    "\n",
    "#### Answer:\n",
    "**(A)** $ \\exists x \\, (Teacher(x) \\land Student(x) \\land \\forall y \\, (Teaches(x, y) \\implies Takes(x, y))) $.\n",
    "\n",
    "#### Reasoning:\n",
    "- $ \\exists x $: There exists a person $ x $.  \n",
    "- $ Teacher(x) \\land Student(x) $: $ x $ is both a teacher and a student.  \n",
    "- $ \\forall y \\, (Teaches(x, y) \\implies Takes(x, y)) $: $ x $ only teaches courses $ y $ that they take.\n",
    "\n",
    "---\n",
    "\n",
    "These questions test both theoretical understanding and practical application of FOL concepts. Let me know if you'd like variations or additional examples!\n",
    "\n",
    "Here are five additional multiple-choice questions covering the topics of **formulating problems, understanding quantifiers, translating English sentences to FOL, substituting variables, and using equality**.\n",
    "\n",
    "---\n",
    "\n",
    "### Question 6: Combining Quantifiers\n",
    "\n",
    "#### Question:\n",
    "Which of the following correctly translates \"Every parent has at least one child\"?\n",
    "\n",
    "(A) $ \\forall x \\, Parent(x) \\implies \\exists y \\, Child(x, y) $  \n",
    "(B) $ \\forall x \\, \\exists y \\, Parent(x) \\land Child(x, y) $  \n",
    "(C) $ \\exists x \\, Parent(x) \\implies \\forall y \\, Child(x, y) $  \n",
    "(D) $ \\forall x, y \\, Parent(x) \\implies Child(x, y) $\n",
    "\n",
    "#### Answer:\n",
    "**(A)** $ \\forall x \\, Parent(x) \\implies \\exists y \\, Child(x, y) $.\n",
    "\n",
    "#### Reasoning:\n",
    "- $ \\forall x $: For every parent $ x $.  \n",
    "- $ \\exists y $: There exists at least one child $ y $.  \n",
    "- $ Parent(x) \\implies \\exists y \\, Child(x, y) $: If $ x $ is a parent, $ x $ has at least one child $ y $.\n",
    "\n",
    "---\n",
    "\n",
    "### Question 7: Equality and Substitution\n",
    "\n",
    "#### Question:\n",
    "Given $ Father(John) = Henry $ and $ Father(Henry) = Edward $, which of the following statements must be true?\n",
    "\n",
    "(A) $ Father(John) = Edward $  \n",
    "(B) $ Father(Father(John)) = Edward $  \n",
    "(C) $ Father(Henry) = John $  \n",
    "(D) $ Father(Father(Henry)) = John $\n",
    "\n",
    "#### Answer:\n",
    "**(B)** $ Father(Father(John)) = Edward $.\n",
    "\n",
    "#### Reasoning:\n",
    "- Substitution allows replacing $ Father(John) $ with $ Henry $, and then replacing $ Father(Henry) $ with $ Edward $.\n",
    "- $ Father(Father(John)) = Father(Henry) = Edward $.\n",
    "\n",
    "---\n",
    "\n",
    "### Question 8: Translating Nested Quantifiers\n",
    "\n",
    "#### Question:\n",
    "Which FOL formula best expresses \"There is a course that every student is enrolled in\"?\n",
    "\n",
    "(A) $ \\exists x \\, (Course(x) \\land \\forall y \\, (Student(y) \\implies Enrolled(y, x))) $  \n",
    "(B) $ \\forall y \\, \\exists x \\, (Course(x) \\land Student(y) \\land Enrolled(y, x)) $  \n",
    "(C) $ \\forall x \\, \\exists y \\, (Course(x) \\land Student(y) \\land Enrolled(y, x)) $  \n",
    "(D) $ \\exists x, y \\, (Course(x) \\land Student(y) \\land Enrolled(y, x)) $\n",
    "\n",
    "#### Answer:\n",
    "**(A)** $ \\exists x \\, (Course(x) \\land \\forall y \\, (Student(y) \\implies Enrolled(y, x))) $.\n",
    "\n",
    "#### Reasoning:\n",
    "- $ \\exists x $: There exists a course $ x $.  \n",
    "- $ \\forall y $: For every student $ y $, if $ y $ is a student, $ y $ is enrolled in $ x $.\n",
    "\n",
    "---\n",
    "\n",
    "### Question 9: Equivalent Sentences by Substitution\n",
    "\n",
    "#### Question:\n",
    "Given the sentence $ \\forall x \\, Loves(x, Chocolate) $, which of the following is an equivalent statement?\n",
    "\n",
    "(A) $ \\forall y \\, Loves(y, Chocolate) $  \n",
    "(B) $ \\exists y \\, Loves(y, Chocolate) $  \n",
    "(C) $ \\forall x \\, Loves(Chocolate, x) $  \n",
    "(D) $ Loves(Alice, Chocolate) $\n",
    "\n",
    "#### Answer:\n",
    "**(A)** $ \\forall y \\, Loves(y, Chocolate) $.\n",
    "\n",
    "#### Reasoning:\n",
    "- The universal quantifier $ \\forall $ applies to all variables, so renaming $ x $ to $ y $ does not change the meaning of the sentence. This is a valid substitution.\n",
    "\n",
    "---\n",
    "\n",
    "### Question 10: Translating English to FOL with Equality\n",
    "\n",
    "#### Question:\n",
    "Translate the sentence \"No two people can have the same email address\" into FOL.\n",
    "\n",
    "(A) $ \\forall x, y \\, (x \\neq y \\implies \\exists e \\, Email(x, e) \\land Email(y, e)) $  \n",
    "(B) $ \\forall x, y, e \\, (Email(x, e) \\land Email(y, e)) \\implies x = y $  \n",
    "(C) $ \\forall x, y, e \\, (Email(x, e) \\land Email(y, e) \\land x \\neq y) \\implies e = x $  \n",
    "(D) $ \\exists x, y, e \\, Email(x, e) \\land Email(y, e) \\land x \\neq y $\n",
    "\n",
    "#### Answer:\n",
    "**(B)** $ \\forall x, y, e \\, (Email(x, e) \\land Email(y, e)) \\implies x = y $.\n",
    "\n",
    "#### Reasoning:\n",
    "- $ \\forall x, y, e $: For all people $ x $ and $ y $, and all emails $ e $.  \n",
    "- $ Email(x, e) \\land Email(y, e) $: If both $ x $ and $ y $ have the same email $ e $,  \n",
    "- $ x = y $: Then $ x $ and $ y $ must be the same person.\n",
    "\n",
    "---\n",
    "\n",
    "These questions further test skills in **FOL formulation, quantifier manipulation, equality handling, and sentence equivalence**. Let me know if you'd like additional variations or deeper discussions!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2274c84e-12ee-4e8a-87b2-5c4ed9e61f6c",
   "metadata": {},
   "source": [
    "# Ch 12\n",
    "\n",
    "Here’s a series of **open-book multiple-choice questions** designed to test understanding and problem-solving skills for the specified topics. Each question includes the correct answer, reasoning, and an explanation.\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 1: Basic Probability Notation**\n",
    "**Problem**: A bag contains 3 red balls, 2 green balls, and 1 blue ball. A ball is drawn at random. What is the probability that the ball is either green or blue?\n",
    "\n",
    "1. $ \\frac{1}{6} $\n",
    "2. $ \\frac{2}{6} $\n",
    "3. $ \\frac{3}{6} $\n",
    "4. $ \\frac{4}{6} $\n",
    "\n",
    "**Answer**: **4. $ \\frac{4}{6} $**\n",
    "\n",
    "**Reasoning**:\n",
    "- Total outcomes: $ 3 + 2 + 1 = 6 $.\n",
    "- Favorable outcomes: $ 2 $ green + $ 1 $ blue = $ 3 $.\n",
    "- Probability: $ P(\\text{Green or Blue}) = \\frac{\\text{Favorable Outcomes}}{\\text{Total Outcomes}} = \\frac{4}{6} $.\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 2: Conditional Probability**\n",
    "**Problem**: A doctor knows the following probabilities:\n",
    "- $ P(\\text{Flu}) = 0.1 $,\n",
    "- $ P(\\text{Fever} \\mid \\text{Flu}) = 0.8 $,\n",
    "- $ P(\\text{Fever}) = 0.2 $.\n",
    "\n",
    "What is the probability that a patient has the flu given they have a fever?\n",
    "\n",
    "1. $ 0.08 $\n",
    "2. $ 0.1 $\n",
    "3. $ 0.4 $\n",
    "4. $ 0.5 $\n",
    "\n",
    "**Answer**: **3. $ 0.4 $**\n",
    "\n",
    "**Reasoning**:\n",
    "Use Bayes' Rule:\n",
    "$$\n",
    "P(\\text{Flu} \\mid \\text{Fever}) = \\frac{P(\\text{Fever} \\mid \\text{Flu}) P(\\text{Flu})}{P(\\text{Fever})}\n",
    "$$\n",
    "$$\n",
    "P(\\text{Flu} \\mid \\text{Fever}) = \\frac{(0.8)(0.1)}{0.2} = 0.4\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 3: Inference Using Full Joint Distributions**\n",
    "**Problem**: Consider the following joint probability table:\n",
    "\n",
    "| $ A $   | $ B $   | $ P(A, B) $ |\n",
    "|-----------|-----------|---------------|\n",
    "| $ \\text{True} $  | $ \\text{True} $  | $ 0.2 $         |\n",
    "| $ \\text{True} $  | $ \\text{False} $ | $ 0.3 $         |\n",
    "| $ \\text{False} $ | $ \\text{True} $  | $ 0.1 $         |\n",
    "| $ \\text{False} $ | $ \\text{False} $ | $ 0.4 $         |\n",
    "\n",
    "What is $ P(B = \\text{True}) $?\n",
    "\n",
    "1. $ 0.1 $\n",
    "2. $ 0.2 $\n",
    "3. $ 0.3 $\n",
    "4. $ 0.4 $\n",
    "\n",
    "**Answer**: **4. $ 0.4 $**\n",
    "\n",
    "**Reasoning**:\n",
    "Use marginalization:\n",
    "$$\n",
    "P(B = \\text{True}) = P(A = \\text{True}, B = \\text{True}) + P(A = \\text{False}, B = \\text{True})\n",
    "$$\n",
    "$$\n",
    "P(B = \\text{True}) = 0.2 + 0.1 = 0.4\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 4: Independence**\n",
    "**Problem**: Two dice are rolled. Let $ A $ be the event that the first die shows a 4, and $ B $ be the event that the second die shows a 6. Are $ A $ and $ B $ independent?\n",
    "\n",
    "1. Yes\n",
    "2. No\n",
    "\n",
    "**Answer**: **1. Yes**\n",
    "\n",
    "**Reasoning**:\n",
    "Events $ A $ and $ B $ are independent if $ P(A \\land B) = P(A)P(B) $.\n",
    "$$\n",
    "P(A) = \\frac{1}{6}, \\quad P(B) = \\frac{1}{6}, \\quad P(A \\land B) = \\frac{1}{36}.\n",
    "$$\n",
    "$$\n",
    "P(A)P(B) = \\frac{1}{6} \\cdot \\frac{1}{6} = \\frac{1}{36}.\n",
    "$$\n",
    "Since $ P(A \\land B) = P(A)P(B) $, $ A $ and $ B $ are independent.\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 5: Bayes’ Rule**\n",
    "**Problem**: A factory produces 80% of its widgets from Machine A and 20% from Machine B. Machine A produces 5% defective widgets, while Machine B produces 10% defective widgets. Given a defective widget, what is the probability it was produced by Machine A?\n",
    "\n",
    "1. $ 0.4 $\n",
    "2. $ 0.5 $\n",
    "3. $ 0.6 $\n",
    "4. $ 0.8 $\n",
    "\n",
    "**Answer**: **3. $ 0.6 $**\n",
    "\n",
    "**Reasoning**:\n",
    "Use Bayes' Rule:\n",
    "$$\n",
    "P(A \\mid D) = \\frac{P(D \\mid A)P(A)}{P(D)}\n",
    "$$\n",
    "Where:\n",
    "$$\n",
    "P(D) = P(D \\mid A)P(A) + P(D \\mid B)P(B)\n",
    "$$\n",
    "Substitute values:\n",
    "$$\n",
    "P(D) = (0.05)(0.8) + (0.1)(0.2) = 0.04 + 0.02 = 0.06\n",
    "$$\n",
    "$$\n",
    "P(A \\mid D) = \\frac{(0.05)(0.8)}{0.06} = 0.6\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 6: Naive Bayes Models and Text Classification**\n",
    "**Problem**: A spam filter uses the following probabilities:\n",
    "- $ P(\\text{Spam}) = 0.4, P(\\neg \\text{Spam}) = 0.6 $,\n",
    "- $ P(\\text{Offer} \\mid \\text{Spam}) = 0.3, P(\\text{Offer} \\mid \\neg \\text{Spam}) = 0.1 $,\n",
    "- $ P(\\text{Free} \\mid \\text{Spam}) = 0.6, P(\\text{Free} \\mid \\neg \\text{Spam}) = 0.05 $.\n",
    "\n",
    "Given an email containing the words \"Offer\" and \"Free,\" what is the probability it is spam?\n",
    "\n",
    "1. $ 0.42 $\n",
    "2. $ 0.67 $\n",
    "3. $ 0.75 $\n",
    "4. $ 0.85 $\n",
    "\n",
    "**Answer**: **2. $ 0.67 $**\n",
    "\n",
    "**Reasoning**:\n",
    "Use Naive Bayes:\n",
    "$$\n",
    "P(\\text{Spam} \\mid \\text{Offer}, \\text{Free}) \\propto P(\\text{Spam})P(\\text{Offer} \\mid \\text{Spam})P(\\text{Free} \\mid \\text{Spam})\n",
    "$$\n",
    "$$\n",
    "P(\\neg \\text{Spam} \\mid \\text{Offer}, \\text{Free}) \\propto P(\\neg \\text{Spam})P(\\text{Offer} \\mid \\neg \\text{Spam})P(\\text{Free} \\mid \\neg \\text{Spam})\n",
    "$$\n",
    "Substitute values:\n",
    "$$\n",
    "P(\\text{Spam} \\mid \\text{Offer}, \\text{Free}) \\propto (0.4)(0.3)(0.6) = 0.072\n",
    "$$\n",
    "$$\n",
    "P(\\neg \\text{Spam} \\mid \\text{Offer}, \\text{Free}) \\propto (0.6)(0.1)(0.05) = 0.003\n",
    "$$\n",
    "Normalize:\n",
    "$$\n",
    "P(\\text{Spam}) = \\frac{0.072}{0.072 + 0.003} = 0.96\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 7: Sampling from a Probability Distribution**\n",
    "**Problem**: A discrete random variable $ X $ has the following distribution:\n",
    "- $ P(X=1) = 0.2 $,\n",
    "- $ P(X=2) = 0.5 $,\n",
    "- $ P(X=3) = 0.3 $.\n",
    "\n",
    "You generate a random number $ U \\in [0,1] $. Which range corresponds to $ X = 2 $?\n",
    "\n",
    "1. $ 0.0 \\leq U < 0.2 $\n",
    "2. $ 0.2 \\leq U < 0.7 $\n",
    "3. $ 0.7 \\leq U \\leq 1.0 $\n",
    "4. $ 0.0 \\leq U \\leq 1.0 $\n",
    "\n",
    "**Answer**: **2. $ 0.2 \\leq U < 0.7 $**\n",
    "\n",
    "**Reasoning**:\n",
    "To sample $ X $:\n",
    "- $ U \\in [0, 0.2) $: $ X = 1 $,\n",
    "- $ U \\in [0.2, 0.7) $: $ X = 2 $ (corresponding to $ P(X=2) = 0.5 $),\n",
    "- $ U \\in [0.7, 1.0) $: $ X = 3 $.\n",
    "\n",
    "Here are **five additional open-book multiple-choice questions** covering the topics you requested, with answers and reasoning.\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 8: Conditional Independence**\n",
    "**Problem**: In a medical diagnosis problem, let $ S $ represent the presence of a symptom, $ D $ represent a disease, and $ T $ represent the result of a diagnostic test. Suppose:\n",
    "- $ P(S \\mid D, T) = P(S \\mid D) $,\n",
    "- $ P(T \\mid D) \\neq P(T) $.\n",
    "\n",
    "What does this imply about the relationships between $ S $, $ D $, and $ T $?\n",
    "\n",
    "1. $ S $ and $ T $ are independent.\n",
    "2. $ S $ and $ T $ are conditionally independent given $ D $.\n",
    "3. $ S $ and $ T $ are marginally independent.\n",
    "4. None of the above.\n",
    "\n",
    "**Answer**: **2. $ S $ and $ T $ are conditionally independent given $ D $**\n",
    "\n",
    "**Reasoning**:\n",
    "Conditional independence means $ P(S \\mid D, T) = P(S \\mid D) $, implying that once $ D $ (disease) is known, the symptom $ S $ is independent of the test result $ T $. However, $ P(T \\mid D) \\neq P(T) $ suggests that $ T $ and $ D $ are not marginally independent.\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 9: Full Joint Distribution**\n",
    "**Problem**: A robot has three sensors $ S_1 $, $ S_2 $, and $ S_3 $, each detecting a different property of an object (e.g., color, weight, size). The probabilities are as follows:\n",
    "- $ P(S_1 = \\text{Red}) = 0.5 $,\n",
    "- $ P(S_2 = \\text{Heavy} \\mid S_1 = \\text{Red}) = 0.4 $,\n",
    "- $ P(S_3 = \\text{Large} \\mid S_1 = \\text{Red}, S_2 = \\text{Heavy}) = 0.6 $.\n",
    "\n",
    "What is $ P(S_1 = \\text{Red}, S_2 = \\text{Heavy}, S_3 = \\text{Large}) $?\n",
    "\n",
    "1. $ 0.12 $\n",
    "2. $ 0.24 $\n",
    "3. $ 0.3 $\n",
    "4. $ 0.6 $\n",
    "\n",
    "**Answer**: **1. $ 0.12 $**\n",
    "\n",
    "**Reasoning**:\n",
    "The full joint probability is computed using the chain rule:\n",
    "$$\n",
    "P(S_1, S_2, S_3) = P(S_1)P(S_2 \\mid S_1)P(S_3 \\mid S_1, S_2)\n",
    "$$\n",
    "Substitute values:\n",
    "$$\n",
    "P(S_1 = \\text{Red}, S_2 = \\text{Heavy}, S_3 = \\text{Large}) = (0.5)(0.4)(0.6) = 0.12\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 10: Bayes’ Rule**\n",
    "**Problem**: An IT team is monitoring network activity. They know:\n",
    "- $ P(\\text{Attack}) = 0.02 $,\n",
    "- $ P(\\text{Alert} \\mid \\text{Attack}) = 0.9 $,\n",
    "- $ P(\\text{Alert} \\mid \\neg \\text{Attack}) = 0.1 $.\n",
    "\n",
    "What is $ P(\\text{Attack} \\mid \\text{Alert}) $?\n",
    "\n",
    "1. $ 0.05 $\n",
    "2. $ 0.15 $\n",
    "3. $ 0.18 $\n",
    "4. $ 0.2 $\n",
    "\n",
    "**Answer**: **3. $ 0.18 $**\n",
    "\n",
    "**Reasoning**:\n",
    "Using Bayes' Rule:\n",
    "$$\n",
    "P(\\text{Attack} \\mid \\text{Alert}) = \\frac{P(\\text{Alert} \\mid \\text{Attack}) P(\\text{Attack})}{P(\\text{Alert})}\n",
    "$$\n",
    "First, compute $ P(\\text{Alert}) $:\n",
    "$$\n",
    "P(\\text{Alert}) = P(\\text{Alert} \\mid \\text{Attack}) P(\\text{Attack}) + P(\\text{Alert} \\mid \\neg \\text{Attack}) P(\\neg \\text{Attack})\n",
    "$$\n",
    "$$\n",
    "P(\\text{Alert}) = (0.9)(0.02) + (0.1)(0.98) = 0.018 + 0.098 = 0.116\n",
    "$$\n",
    "Now compute:\n",
    "$$\n",
    "P(\\text{Attack} \\mid \\text{Alert}) = \\frac{(0.9)(0.02)}{0.116} = \\frac{0.018}{0.116} \\approx 0.18\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 11: Naive Bayes and Text Classification**\n",
    "**Problem**: A spam filter uses the following probabilities:\n",
    "- $ P(\\text{Spam}) = 0.4, P(\\neg \\text{Spam}) = 0.6 $,\n",
    "- $ P(\\text{Offer} \\mid \\text{Spam}) = 0.5, P(\\text{Offer} \\mid \\neg \\text{Spam}) = 0.2 $,\n",
    "- $ P(\\text{Free} \\mid \\text{Spam}) = 0.7, P(\\text{Free} \\mid \\neg \\text{Spam}) = 0.1 $.\n",
    "\n",
    "Given an email containing \"Offer\" and \"Free,\" what is the normalized probability it is **not spam**?\n",
    "\n",
    "1. $ 0.3 $\n",
    "2. $ 0.33 $\n",
    "3. $ 0.5 $\n",
    "4. $ 0.67 $\n",
    "\n",
    "**Answer**: **4. $ 0.67 $**\n",
    "\n",
    "**Reasoning**:\n",
    "Use Naive Bayes:\n",
    "$$\n",
    "P(\\text{Spam} \\mid \\text{Words}) \\propto P(\\text{Spam}) P(\\text{Offer} \\mid \\text{Spam}) P(\\text{Free} \\mid \\text{Spam})\n",
    "$$\n",
    "$$\n",
    "P(\\neg \\text{Spam} \\mid \\text{Words}) \\propto P(\\neg \\text{Spam}) P(\\text{Offer} \\mid \\neg \\text{Spam}) P(\\text{Free} \\mid \\neg \\text{Spam})\n",
    "$$\n",
    "Substitute values:\n",
    "$$\n",
    "P(\\text{Spam} \\mid \\text{Words}) \\propto (0.4)(0.5)(0.7) = 0.14\n",
    "$$\n",
    "$$\n",
    "P(\\neg \\text{Spam} \\mid \\text{Words}) \\propto (0.6)(0.2)(0.1) = 0.012\n",
    "$$\n",
    "Normalize:\n",
    "$$\n",
    "P(\\neg \\text{Spam}) = \\frac{0.012}{0.14 + 0.012} \\approx 0.067 / 0.15 \\approx 0.67\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 12: Sampling from a Probability Distribution**\n",
    "**Problem**: A random variable $ X $ has the following probabilities:\n",
    "- $ P(X=1) = 0.2 $,\n",
    "- $ P(X=2) = 0.5 $,\n",
    "- $ P(X=3) = 0.3 $.\n",
    "\n",
    "You generate a random number $ U = 0.35 $. What is the sampled value of $ X $?\n",
    "\n",
    "1. $ X = 1 $\n",
    "2. $ X = 2 $\n",
    "3. $ X = 3 $\n",
    "4. $ X = 4 $\n",
    "\n",
    "**Answer**: **2. $ X = 2 $**\n",
    "\n",
    "**Reasoning**:\n",
    "Map the probabilities to cumulative intervals:\n",
    "- $ P(X=1) = 0.2 $, so $ 0.0 \\leq U < 0.2 $ corresponds to $ X=1 $,\n",
    "- $ P(X=2) = 0.5 $, so $ 0.2 \\leq U < 0.7 $ corresponds to $ X=2 $,\n",
    "- $ P(X=3) = 0.3 $, so $ 0.7 \\leq U \\leq 1.0 $ corresponds to $ X=3 $.\n",
    "\n",
    "Since $ U = 0.35 $ falls in the interval $ [0.2, 0.7) $, the sampled value is $ X=2 $."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bda0251-59fb-4b98-93c4-0a2414ed505b",
   "metadata": {},
   "source": [
    "# ch 13\n",
    "\n",
    "### Multiple Choice Questions for Open Book Exam on Bayesian Networks\n",
    "\n",
    "---\n",
    "\n",
    "#### **1. Semantics of Bayesian Networks**\n",
    "**Question:**\n",
    "Consider a Bayesian Network with three variables: $ X $, $ Y $, and $ Z $. $ X $ is a parent of both $ Y $ and $ Z $, and $ Y $ is a parent of $ Z $. The network defines the following joint probability distribution:\n",
    "$$\n",
    "P(X, Y, Z) = P(X) \\cdot P(Y \\mid X) \\cdot P(Z \\mid Y, X).\n",
    "$$\n",
    "\n",
    "What would happen if the edge between $ Y $ and $ Z $ is removed, assuming $ Z $ depends only on $ X $?\n",
    "\n",
    "**A)** The new joint distribution becomes $ P(X, Y, Z) = P(X) \\cdot P(Y \\mid X) \\cdot P(Z) $.\n",
    "\n",
    "**B)** The new joint distribution becomes $ P(X, Y, Z) = P(X) \\cdot P(Y \\mid X) \\cdot P(Z \\mid X) $.\n",
    "\n",
    "**C)** The new joint distribution becomes $ P(X, Y, Z) = P(X) \\cdot P(Y) \\cdot P(Z \\mid Y) $.\n",
    "\n",
    "**D)** The joint distribution cannot be defined due to missing dependencies.\n",
    "\n",
    "**Answer:** **B**\n",
    "\n",
    "**Reasoning:**  \n",
    "Removing the edge $ Y \\to Z $ implies $ Z $ no longer depends on $ Y $. However, $ Z $ still depends on $ X $. Hence, the correct joint distribution is $ P(X, Y, Z) = P(X) \\cdot P(Y \\mid X) \\cdot P(Z \\mid X) $.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Conditional Probability Tables (CPTs)**\n",
    "**Question:**  \n",
    "Consider a variable $ Alarm $ in a Bayesian Network with two parent variables: $ Burglary $ and $ Earthquake $. The conditional probability table (CPT) for $ Alarm $ is given below:\n",
    "\n",
    "| Burglary | Earthquake | $ P(Alarm = true) $ | $ P(Alarm = false) $ |\n",
    "|----------|------------|-----------------------|------------------------|\n",
    "| true     | true       | 0.95                  | 0.05                   |\n",
    "| true     | false      | 0.94                  | 0.06                   |\n",
    "| false    | true       | 0.29                  | 0.71                   |\n",
    "| false    | false      | 0.001                 | 0.999                  |\n",
    "\n",
    "What is $ P(Alarm = true \\mid Burglary = true, Earthquake = false) $?\n",
    "\n",
    "**A)** 0.95  \n",
    "**B)** 0.94  \n",
    "**C)** 0.29  \n",
    "**D)** 0.001  \n",
    "\n",
    "**Answer:** **B**\n",
    "\n",
    "**Reasoning:**  \n",
    "From the CPT, the value of $ P(Alarm = true \\mid Burglary = true, Earthquake = false) $ is explicitly provided as $ 0.94 $.\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Exact Inference in Bayesian Networks**\n",
    "**Question:**  \n",
    "You are tasked with calculating $ P(Burglary = true \\mid JohnCalls = true, MaryCalls = true) $ in a Bayesian Network. The joint probability is given as:\n",
    "\n",
    "$$\n",
    "P(B, J, M) = \\sum_E \\sum_A P(B) \\cdot P(E) \\cdot P(A \\mid B, E) \\cdot P(J \\mid A) \\cdot P(M \\mid A),\n",
    "$$\n",
    "where $ E $ and $ A $ are hidden variables. What is the most efficient approach to calculate this without explicitly computing the entire joint distribution?\n",
    "\n",
    "**A)** Use rejection sampling to approximate the posterior probability.  \n",
    "**B)** Use direct sampling to approximate the posterior probability.  \n",
    "**C)** Evaluate the nested summation in the given equation directly.  \n",
    "**D)** Eliminate variables $ E $ and $ A $ by iteratively summing them out.\n",
    "\n",
    "**Answer:** **D**\n",
    "\n",
    "**Reasoning:**  \n",
    "Iteratively summing out hidden variables $ E $ and $ A $ reduces computation by avoiding the need to evaluate the full joint distribution for all possible combinations of variables.\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. Query, Hidden, and Evidence Variables**\n",
    "**Question:**  \n",
    "In the following query, identify the query, hidden, and evidence variables:\n",
    "$$\n",
    "P(Burglary \\mid JohnCalls = true, MaryCalls = true)\n",
    "$$\n",
    "\n",
    "**A)** Query: $ Burglary $; Evidence: $ JohnCalls, MaryCalls $; Hidden: None  \n",
    "**B)** Query: $ Burglary $; Evidence: $ JohnCalls, MaryCalls $; Hidden: $ Alarm, Earthquake $  \n",
    "**C)** Query: $ Alarm $; Evidence: $ Burglary, JohnCalls, MaryCalls $; Hidden: $ Earthquake $  \n",
    "**D)** Query: $ JohnCalls, MaryCalls $; Evidence: $ Burglary $; Hidden: $ Alarm $\n",
    "\n",
    "**Answer:** **B**\n",
    "\n",
    "**Reasoning:**  \n",
    "- Query variable: $ Burglary $, because it is the variable we want to calculate the posterior probability for.  \n",
    "- Evidence variables: $ JohnCalls, MaryCalls $, as they are observed.  \n",
    "- Hidden variables: $ Alarm, Earthquake $, because they are unobserved and are marginalized during inference.\n",
    "\n",
    "---\n",
    "\n",
    "#### **5. Approximate Inference (Rejection Sampling)**\n",
    "**Question:**  \n",
    "In rejection sampling, suppose we sample 1,000 times from the prior distribution of a Bayesian Network and find that only 200 samples are consistent with the evidence $ JohnCalls = true, MaryCalls = true $. Among these 200 samples, 50 have $ Burglary = true $. What is the approximate probability $ P(Burglary = true \\mid JohnCalls = true, MaryCalls = true) $?\n",
    "\n",
    "**A)** 0.05  \n",
    "**B)** 0.20  \n",
    "**C)** 0.25  \n",
    "**D)** 0.50  \n",
    "\n",
    "**Answer:** **C**\n",
    "\n",
    "**Reasoning:**  \n",
    "Rejection sampling estimates the posterior probability as the fraction of accepted samples that match the query:\n",
    "$$\n",
    "P(Burglary = true \\mid JohnCalls = true, MaryCalls = true) = \\frac{\\text{Samples with } Burglary = true}{\\text{Total Accepted Samples}} = \\frac{50}{200} = 0.25.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### **6. Approximate Inference (Direct Sampling)**\n",
    "**Question:**  \n",
    "When using direct sampling to estimate $ P(Alarm = true \\mid Burglary = true) $, how do you handle evidence that is not directly sampled?\n",
    "\n",
    "**A)** Directly reject all samples where $ Burglary \\neq true $.  \n",
    "**B)** Assign a likelihood weight to each sample based on the conditional probability of evidence.  \n",
    "**C)** Ignore the evidence and use raw sampling results.  \n",
    "**D)** Generate only samples consistent with $ Burglary = true $.\n",
    "\n",
    "**Answer:** **B**\n",
    "\n",
    "**Reasoning:**  \n",
    "Direct sampling generates samples from the prior and adjusts their contribution to the estimate by weighting based on the likelihood of the evidence. Evidence is handled by computing a weight for each sample based on its consistency with observed evidence.\n",
    "\n",
    "Here are five additional multiple-choice questions, covering the specified topics:\n",
    "\n",
    "---\n",
    "\n",
    "#### **7. Semantics of Bayesian Networks**\n",
    "**Question:**\n",
    "A Bayesian Network contains three variables: $ A, B, C $. $ A $ and $ B $ are parents of $ C $. Which of the following correctly represents the joint probability distribution of this network?\n",
    "\n",
    "**A)** $ P(A, B, C) = P(A) \\cdot P(B) \\cdot P(C \\mid A, B) $  \n",
    "**B)** $ P(A, B, C) = P(C \\mid A, B) \\cdot P(A \\mid B) \\cdot P(B) $  \n",
    "**C)** $ P(A, B, C) = P(C \\mid A, B) \\cdot P(A) \\cdot P(B) $  \n",
    "**D)** $ P(A, B, C) = P(C) \\cdot P(A \\mid C) \\cdot P(B \\mid C) $\n",
    "\n",
    "**Answer:** **C**\n",
    "\n",
    "**Reasoning:**  \n",
    "The joint probability for a Bayesian Network is obtained by multiplying the probability of each variable with its parents. Here, $ C $ depends on $ A $ and $ B $, while $ A $ and $ B $ are independent (no parents), so the joint probability is $ P(A, B, C) = P(C \\mid A, B) \\cdot P(A) \\cdot P(B) $.\n",
    "\n",
    "---\n",
    "\n",
    "#### **8. Conditional Probability Tables (CPTs)**\n",
    "**Question:**  \n",
    "A node $ X $ has two parents, $ A $ and $ B $, both Boolean variables. The CPT for $ X $ is as follows:\n",
    "\n",
    "| $ A $ | $ B $ | $ P(X = true) $ | $ P(X = false) $ |\n",
    "|--------|---------|-------------------|--------------------|\n",
    "| true   | true    | 0.9               | 0.1                |\n",
    "| true   | false   | 0.6               | 0.4                |\n",
    "| false  | true    | 0.4               | 0.6                |\n",
    "| false  | false   | 0.1               | 0.9                |\n",
    "\n",
    "What is the probability $ P(X = false \\mid A = false, B = true) $?\n",
    "\n",
    "**A)** 0.6  \n",
    "**B)** 0.4  \n",
    "**C)** 0.9  \n",
    "**D)** 0.1  \n",
    "\n",
    "**Answer:** **A**\n",
    "\n",
    "**Reasoning:**  \n",
    "From the CPT, when $ A = false $ and $ B = true $, $ P(X = false) = 0.6 $.\n",
    "\n",
    "---\n",
    "\n",
    "#### **9. Exact Inference in Bayesian Networks**\n",
    "**Question:**  \n",
    "In a Bayesian Network, the query is $ P(Earthquake \\mid JohnCalls = true, MaryCalls = true) $. The following joint probability is provided:\n",
    "\n",
    "$$\n",
    "P(E, J, M) = \\sum_{B} \\sum_{A} P(E) \\cdot P(B) \\cdot P(A \\mid E, B) \\cdot P(J \\mid A) \\cdot P(M \\mid A),\n",
    "$$\n",
    "where $ B $ and $ A $ are hidden variables. What is the first step in computing this query?\n",
    "\n",
    "**A)** Marginalize over $ B $ and $ A $ by summing their probabilities.  \n",
    "**B)** Normalize $ P(E) $ over the evidence $ JohnCalls = true, MaryCalls = true $.  \n",
    "**C)** Directly use the CPT for $ Earthquake $ to find $ P(E \\mid J, M) $.  \n",
    "**D)** Combine $ P(E) $ with $ P(J \\mid A) $ and $ P(M \\mid A) $ directly.\n",
    "\n",
    "**Answer:** **A**\n",
    "\n",
    "**Reasoning:**  \n",
    "Exact inference involves marginalizing (summing) over all hidden variables ($ B $ and $ A $) that are not part of the query or evidence to calculate the posterior distribution.\n",
    "\n",
    "---\n",
    "\n",
    "#### **10. Approximate Inference (Direct Sampling)**\n",
    "**Question:**  \n",
    "Suppose you want to estimate $ P(Alarm \\mid Burglary = true) $ using direct sampling. After generating 1,000 samples from the prior, you find that 100 samples have $ Burglary = true $, and among these, 30 have $ Alarm = true $. What is the estimated probability $ P(Alarm \\mid Burglary = true) $?\n",
    "\n",
    "**A)** 0.03  \n",
    "**B)** 0.10  \n",
    "**C)** 0.30  \n",
    "**D)** 0.50  \n",
    "\n",
    "**Answer:** **C**\n",
    "\n",
    "**Reasoning:**  \n",
    "Direct sampling estimates the conditional probability using the fraction of samples matching both the query and the evidence. Here:\n",
    "$$\n",
    "P(Alarm \\mid Burglary = true) = \\frac{\\text{Samples with } Alarm = true \\text{ and } Burglary = true}{\\text{Samples with } Burglary = true} = \\frac{30}{100} = 0.30.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### **11. Approximate Inference (Rejection Sampling)**\n",
    "**Question:**  \n",
    "You are performing rejection sampling to estimate $ P(Burglary = true \\mid JohnCalls = true) $. Out of 5,000 total samples, only 500 are consistent with the evidence $ JohnCalls = true $. Among these, 100 have $ Burglary = true $. What is the estimate for $ P(Burglary = true \\mid JohnCalls = true) $?\n",
    "\n",
    "**A)** 0.10  \n",
    "**B)** 0.20  \n",
    "**C)** 0.30  \n",
    "**D)** 0.50  \n",
    "\n",
    "**Answer:** **B**\n",
    "\n",
    "**Reasoning:**  \n",
    "In rejection sampling, only samples consistent with the evidence are considered. Among the 500 valid samples, 100 have $ Burglary = true $. Thus:\n",
    "$$\n",
    "P(Burglary = true \\mid JohnCalls = true) = \\frac{\\text{Samples with } Burglary = true}{\\text{Total valid samples}} = \\frac{100}{500} = 0.20.\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249403b4-06f6-4016-ad9c-66bb0fbdd8f4",
   "metadata": {},
   "source": [
    "# ch 14\n",
    "\n",
    "### **Multiple-Choice Questions for an Open Book Exam**\n",
    "\n",
    "---\n",
    "\n",
    "#### **Question 1: States and Observations**\n",
    "\n",
    "A robot navigates in a grid. At each time step, its position ($ X_t $) is hidden, and it makes an observation ($ O_t $) of nearby landmarks. Which of the following correctly matches the type of variables in this scenario?\n",
    "\n",
    "1. $ X_t $ is:\n",
    "   - (A) Observable\n",
    "   - (B) Hidden\n",
    "   - (C) Deterministic\n",
    "   - (D) Noisy\n",
    "\n",
    "2. $ O_t $ is:\n",
    "   - (A) Hidden\n",
    "   - (B) Deterministic\n",
    "   - (C) Observable\n",
    "   - (D) Nonexistent\n",
    "\n",
    "**Answer:**\n",
    "- 1: (B) Hidden. The state ($ X_t $) is not directly observed; it must be inferred.\n",
    "- 2: (C) Observable. Observations ($ O_t $) are directly measurable but noisy, representing evidence about the hidden state.\n",
    "\n",
    "**Reasoning:**\n",
    "Hidden states describe the true condition of the system, which is not directly observed. Observations are noisy evidence about these states.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Question 2: Markov Assumption**\n",
    "\n",
    "Which of the following best illustrates the **Markov assumption** in a temporal system?\n",
    "\n",
    "1. (A) $ P(X_t \\mid X_{1:t-1}) = P(X_t \\mid X_{t-1}) $\n",
    "2. (B) $ P(X_t \\mid X_{1:t-1}) = P(X_t \\mid X_{0}) $\n",
    "3. (C) $ P(X_t \\mid X_{1:t}) = P(X_t \\mid X_{t+1}) $\n",
    "4. (D) $ P(X_t \\mid X_{t+1}) = P(X_t \\mid X_{1:t-1}) $\n",
    "\n",
    "**Answer:** (A) $ P(X_t \\mid X_{1:t-1}) = P(X_t \\mid X_{t-1}) $\n",
    "\n",
    "**Reasoning:**\n",
    "The Markov assumption states that the current state depends only on the immediate previous state, not the entire history.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Question 3: Transition and Sensor Models**\n",
    "\n",
    "Suppose a robot's state $ X_t $ describes its position, and its observations $ O_t $ describe noisy GPS measurements. Which of the following equations best represents the **sensor model**?\n",
    "\n",
    "1. (A) $ P(X_t \\mid X_{t-1}) $\n",
    "2. (B) $ P(O_t \\mid X_t) $\n",
    "3. (C) $ P(O_t \\mid X_{t-1}) $\n",
    "4. (D) $ P(X_t \\mid O_t) $\n",
    "\n",
    "**Answer:** (B) $ P(O_t \\mid X_t) $\n",
    "\n",
    "**Reasoning:**\n",
    "The sensor model describes the likelihood of an observation ($ O_t $) given the state ($ X_t $).\n",
    "\n",
    "---\n",
    "\n",
    "#### **Question 4: Filtering vs. Prediction**\n",
    "\n",
    "Which task is being performed if you are computing $ P(X_{t+1} \\mid O_{1:t}) $?\n",
    "\n",
    "1. (A) Filtering\n",
    "2. (B) Prediction\n",
    "3. (C) Smoothing\n",
    "4. (D) Most likely explanation\n",
    "\n",
    "**Answer:** (B) Prediction\n",
    "\n",
    "**Reasoning:**\n",
    "Prediction involves estimating the probability of future states ($ X_{t+1} $) given past and current observations ($ O_{1:t} $).\n",
    "\n",
    "---\n",
    "\n",
    "#### **Question 5: Filtering**\n",
    "\n",
    "Given a Hidden Markov Model (HMM) with states $ X_t $, observations $ O_t $, transition model $ P(X_t \\mid X_{t-1}) $, and sensor model $ P(O_t \\mid X_t) $, what is the correct equation for **filtering**?\n",
    "\n",
    "1. (A) $ P(X_t \\mid O_{1:t}) \\propto P(O_t \\mid X_t) \\sum_{x_{t-1}} P(X_t \\mid X_{t-1}) P(X_{t-1} \\mid O_{1:t-1}) $\n",
    "2. (B) $ P(X_t \\mid O_{1:t}) = P(O_t \\mid X_t) $\n",
    "3. (C) $ P(X_t \\mid O_{1:t}) = \\sum_{x_{t-1}} P(X_t \\mid X_{t-1}) $\n",
    "4. (D) $ P(X_t \\mid O_{1:t}) = P(O_t \\mid X_t) P(X_t \\mid X_{t-1}) $\n",
    "\n",
    "**Answer:** (A)\n",
    "\n",
    "**Reasoning:**\n",
    "Filtering combines the sensor model with a summation over the prior state probabilities to estimate the belief about the current state.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Question 6: Smoothing**\n",
    "\n",
    "What is the main difference between **smoothing** and **filtering**?\n",
    "\n",
    "1. (A) Filtering uses past observations, while smoothing uses future observations to refine the estimate of past states.\n",
    "2. (B) Smoothing uses only the current observation, while filtering uses past observations.\n",
    "3. (C) Filtering finds the most likely sequence of states, while smoothing finds the most likely single state.\n",
    "4. (D) Filtering uses the sensor model, while smoothing does not.\n",
    "\n",
    "**Answer:** (A)\n",
    "\n",
    "**Reasoning:**\n",
    "Smoothing incorporates both past and future observations to refine the estimate of a past state, while filtering only uses past observations.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Question 7: Hidden Markov Models**\n",
    "\n",
    "In an HMM with discrete observations, what are the **two main components** used to calculate the likelihood of an observation sequence $ O_{1:t} $?\n",
    "\n",
    "1. (A) Transition model and filtering\n",
    "2. (B) Transition model and sensor model\n",
    "3. (C) Sensor model and smoothing\n",
    "4. (D) Prediction and most likely explanation\n",
    "\n",
    "**Answer:** (B) Transition model and sensor model\n",
    "\n",
    "**Reasoning:**\n",
    "The transition model governs state transitions ($ P(X_t \\mid X_{t-1}) $), and the sensor model relates states to observations ($ P(O_t \\mid X_t) $).\n",
    "\n",
    "---\n",
    "\n",
    "#### **Question 8: Most Likely Explanation**\n",
    "\n",
    "Which of the following tasks computes the **most likely sequence of states** given an observation sequence $ O_{1:t} $?\n",
    "\n",
    "1. (A) Filtering\n",
    "2. (B) Prediction\n",
    "3. (C) Most likely explanation\n",
    "4. (D) Smoothing\n",
    "\n",
    "**Answer:** (C) Most likely explanation\n",
    "\n",
    "**Reasoning:**\n",
    "The \"most likely explanation\" task, often implemented using the Viterbi algorithm, identifies the sequence of states with the highest probability given the observations.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Question 9: Learning in HMMs**\n",
    "\n",
    "What does the **learning task** in HMMs aim to achieve?\n",
    "\n",
    "1. (A) Estimate the most likely state sequence for given observations.\n",
    "2. (B) Infer the transition and sensor models from a set of observations.\n",
    "3. (C) Predict future states based on current observations.\n",
    "4. (D) Compute the posterior probabilities of past states.\n",
    "\n",
    "**Answer:** (B) Infer the transition and sensor models from a set of observations.\n",
    "\n",
    "**Reasoning:**\n",
    "Learning in HMMs involves estimating the parameters of the model (e.g., transition and sensor probabilities) from observed data, often using algorithms like Expectation-Maximization (EM).\n",
    "\n",
    "---\n",
    "\n",
    "#### **Question 10: Hidden Markov Models with Discrete Observations**\n",
    "\n",
    "A weather system is modeled as an HMM with states $ S = \\{\\text{Rainy, Sunny}\\} $ and observations $ O = \\{\\text{Umbrella, No Umbrella}\\} $. If $ P(\\text{Umbrella} \\mid \\text{Rainy}) = 0.9 $ and $ P(\\text{Rainy} \\mid \\text{Sunny}) = 0.3 $, which of the following correctly computes $ P(\\text{Rainy}_2 \\mid \\text{Umbrella}_1, \\text{No Umbrella}_2) $?\n",
    "\n",
    "1. (A) $ P(\\text{Rainy}_2) \\cdot P(\\text{Umbrella}_1 \\mid \\text{Rainy}_1) $\n",
    "2. (B) Sum over $ P(\\text{Rainy}_2 \\mid \\text{Sunny}_1) P(\\text{Sunny}_1 \\mid \\text{Umbrella}_1) $\n",
    "3. (C) Use filtering: $ P(\\text{Rainy}_2) \\propto P(\\text{No Umbrella}_2 \\mid \\text{Rainy}_2) P(\\text{Rainy}_2 \\mid \\text{Rainy}_1) P(\\text{Rainy}_1 \\mid \\text{Umbrella}_1) $\n",
    "4. (D) Use smoothing: $ P(\\text{Rainy}_2) \\propto P(\\text{Umbrella}_1 \\mid \\text{Rainy}_1) \\cdot P(\\text{Rainy}_1) $\n",
    "\n",
    "**Answer:** (C)\n",
    "\n",
    "**Reasoning:**\n",
    "Filtering combines the sensor and transition models sequentially to calculate the belief about the current state given all past observations.\n",
    "\n",
    "--- \n",
    "\n",
    "These questions cover key concepts and require students to apply their understanding of HMMs, Markov assumptions, and inference tasks to solve problems systematically.\n",
    "\n",
    "### **Multiple-Choice Questions for an Open Book Exam**\n",
    "\n",
    "---\n",
    "\n",
    "#### **Question 1: States and Observations**\n",
    "\n",
    "A robot navigates in a grid. At each time step, its position ($ X_t $) is hidden, and it makes an observation ($ O_t $) of nearby landmarks. Which of the following correctly matches the type of variables in this scenario?\n",
    "\n",
    "1. $ X_t $ is:\n",
    "   - (A) Observable\n",
    "   - (B) Hidden\n",
    "   - (C) Deterministic\n",
    "   - (D) Noisy\n",
    "\n",
    "2. $ O_t $ is:\n",
    "   - (A) Hidden\n",
    "   - (B) Deterministic\n",
    "   - (C) Observable\n",
    "   - (D) Nonexistent\n",
    "\n",
    "**Answer:**\n",
    "- 1: (B) Hidden. The state ($ X_t $) is not directly observed; it must be inferred.\n",
    "- 2: (C) Observable. Observations ($ O_t $) are directly measurable but noisy, representing evidence about the hidden state.\n",
    "\n",
    "**Reasoning:**\n",
    "Hidden states describe the true condition of the system, which is not directly observed. Observations are noisy evidence about these states.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Question 2: Markov Assumption**\n",
    "\n",
    "Which of the following best illustrates the **Markov assumption** in a temporal system?\n",
    "\n",
    "1. (A) $ P(X_t \\mid X_{1:t-1}) = P(X_t \\mid X_{t-1}) $\n",
    "2. (B) $ P(X_t \\mid X_{1:t-1}) = P(X_t \\mid X_{0}) $\n",
    "3. (C) $ P(X_t \\mid X_{1:t}) = P(X_t \\mid X_{t+1}) $\n",
    "4. (D) $ P(X_t \\mid X_{t+1}) = P(X_t \\mid X_{1:t-1}) $\n",
    "\n",
    "**Answer:** (A) $ P(X_t \\mid X_{1:t-1}) = P(X_t \\mid X_{t-1}) $\n",
    "\n",
    "**Reasoning:**\n",
    "The Markov assumption states that the current state depends only on the immediate previous state, not the entire history.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Question 3: Transition and Sensor Models**\n",
    "\n",
    "Suppose a robot's state $ X_t $ describes its position, and its observations $ O_t $ describe noisy GPS measurements. Which of the following equations best represents the **sensor model**?\n",
    "\n",
    "1. (A) $ P(X_t \\mid X_{t-1}) $\n",
    "2. (B) $ P(O_t \\mid X_t) $\n",
    "3. (C) $ P(O_t \\mid X_{t-1}) $\n",
    "4. (D) $ P(X_t \\mid O_t) $\n",
    "\n",
    "**Answer:** (B) $ P(O_t \\mid X_t) $\n",
    "\n",
    "**Reasoning:**\n",
    "The sensor model describes the likelihood of an observation ($ O_t $) given the state ($ X_t $).\n",
    "\n",
    "---\n",
    "\n",
    "#### **Question 4: Filtering vs. Prediction**\n",
    "\n",
    "Which task is being performed if you are computing $ P(X_{t+1} \\mid O_{1:t}) $?\n",
    "\n",
    "1. (A) Filtering\n",
    "2. (B) Prediction\n",
    "3. (C) Smoothing\n",
    "4. (D) Most likely explanation\n",
    "\n",
    "**Answer:** (B) Prediction\n",
    "\n",
    "**Reasoning:**\n",
    "Prediction involves estimating the probability of future states ($ X_{t+1} $) given past and current observations ($ O_{1:t} $).\n",
    "\n",
    "---\n",
    "\n",
    "#### **Question 5: Filtering**\n",
    "\n",
    "Given a Hidden Markov Model (HMM) with states $ X_t $, observations $ O_t $, transition model $ P(X_t \\mid X_{t-1}) $, and sensor model $ P(O_t \\mid X_t) $, what is the correct equation for **filtering**?\n",
    "\n",
    "1. (A) $ P(X_t \\mid O_{1:t}) \\propto P(O_t \\mid X_t) \\sum_{x_{t-1}} P(X_t \\mid X_{t-1}) P(X_{t-1} \\mid O_{1:t-1}) $\n",
    "2. (B) $ P(X_t \\mid O_{1:t}) = P(O_t \\mid X_t) $\n",
    "3. (C) $ P(X_t \\mid O_{1:t}) = \\sum_{x_{t-1}} P(X_t \\mid X_{t-1}) $\n",
    "4. (D) $ P(X_t \\mid O_{1:t}) = P(O_t \\mid X_t) P(X_t \\mid X_{t-1}) $\n",
    "\n",
    "**Answer:** (A)\n",
    "\n",
    "**Reasoning:**\n",
    "Filtering combines the sensor model with a summation over the prior state probabilities to estimate the belief about the current state.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Question 6: Smoothing**\n",
    "\n",
    "What is the main difference between **smoothing** and **filtering**?\n",
    "\n",
    "1. (A) Filtering uses past observations, while smoothing uses future observations to refine the estimate of past states.\n",
    "2. (B) Smoothing uses only the current observation, while filtering uses past observations.\n",
    "3. (C) Filtering finds the most likely sequence of states, while smoothing finds the most likely single state.\n",
    "4. (D) Filtering uses the sensor model, while smoothing does not.\n",
    "\n",
    "**Answer:** (A)\n",
    "\n",
    "**Reasoning:**\n",
    "Smoothing incorporates both past and future observations to refine the estimate of a past state, while filtering only uses past observations.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Question 7: Hidden Markov Models**\n",
    "\n",
    "In an HMM with discrete observations, what are the **two main components** used to calculate the likelihood of an observation sequence $ O_{1:t} $?\n",
    "\n",
    "1. (A) Transition model and filtering\n",
    "2. (B) Transition model and sensor model\n",
    "3. (C) Sensor model and smoothing\n",
    "4. (D) Prediction and most likely explanation\n",
    "\n",
    "**Answer:** (B) Transition model and sensor model\n",
    "\n",
    "**Reasoning:**\n",
    "The transition model governs state transitions ($ P(X_t \\mid X_{t-1}) $), and the sensor model relates states to observations ($ P(O_t \\mid X_t) $).\n",
    "\n",
    "---\n",
    "\n",
    "#### **Question 8: Most Likely Explanation**\n",
    "\n",
    "Which of the following tasks computes the **most likely sequence of states** given an observation sequence $ O_{1:t} $?\n",
    "\n",
    "1. (A) Filtering\n",
    "2. (B) Prediction\n",
    "3. (C) Most likely explanation\n",
    "4. (D) Smoothing\n",
    "\n",
    "**Answer:** (C) Most likely explanation\n",
    "\n",
    "**Reasoning:**\n",
    "The \"most likely explanation\" task, often implemented using the Viterbi algorithm, identifies the sequence of states with the highest probability given the observations.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Question 9: Learning in HMMs**\n",
    "\n",
    "What does the **learning task** in HMMs aim to achieve?\n",
    "\n",
    "1. (A) Estimate the most likely state sequence for given observations.\n",
    "2. (B) Infer the transition and sensor models from a set of observations.\n",
    "3. (C) Predict future states based on current observations.\n",
    "4. (D) Compute the posterior probabilities of past states.\n",
    "\n",
    "**Answer:** (B) Infer the transition and sensor models from a set of observations.\n",
    "\n",
    "**Reasoning:**\n",
    "Learning in HMMs involves estimating the parameters of the model (e.g., transition and sensor probabilities) from observed data, often using algorithms like Expectation-Maximization (EM).\n",
    "\n",
    "---\n",
    "\n",
    "#### **Question 10: Hidden Markov Models with Discrete Observations**\n",
    "\n",
    "A weather system is modeled as an HMM with states $ S = \\{\\text{Rainy, Sunny}\\} $ and observations $ O = \\{\\text{Umbrella, No Umbrella}\\} $. If $ P(\\text{Umbrella} \\mid \\text{Rainy}) = 0.9 $ and $ P(\\text{Rainy} \\mid \\text{Sunny}) = 0.3 $, which of the following correctly computes $ P(\\text{Rainy}_2 \\mid \\text{Umbrella}_1, \\text{No Umbrella}_2) $?\n",
    "\n",
    "1. (A) $ P(\\text{Rainy}_2) \\cdot P(\\text{Umbrella}_1 \\mid \\text{Rainy}_1) $\n",
    "2. (B) Sum over $ P(\\text{Rainy}_2 \\mid \\text{Sunny}_1) P(\\text{Sunny}_1 \\mid \\text{Umbrella}_1) $\n",
    "3. (C) Use filtering: $ P(\\text{Rainy}_2) \\propto P(\\text{No Umbrella}_2 \\mid \\text{Rainy}_2) P(\\text{Rainy}_2 \\mid \\text{Rainy}_1) P(\\text{Rainy}_1 \\mid \\text{Umbrella}_1) $\n",
    "4. (D) Use smoothing: $ P(\\text{Rainy}_2) \\propto P(\\text{Umbrella}_1 \\mid \\text{Rainy}_1) \\cdot P(\\text{Rainy}_1) $\n",
    "\n",
    "**Answer:** (C)\n",
    "\n",
    "**Reasoning:**\n",
    "Filtering combines the sensor and transition models sequentially to calculate the belief about the current state given all past observations.\n",
    "\n",
    "--- \n",
    "\n",
    "These questions cover key concepts and require students to apply their understanding of HMMs, Markov assumptions, and inference tasks to solve problems systematically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060361c7-4a4c-4907-99e2-765183661339",
   "metadata": {},
   "source": [
    "# ch 19\n",
    "\n",
    "Here’s a series of multiple-choice questions designed for an **open-book exam**. These are problem-solving questions requiring analysis and reasoning, covering the requested topics. Each question includes the correct answer and an explanation.\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 1: Forms of Learning**\n",
    "A self-driving car is learning how to navigate intersections based on camera data. The system receives labeled training data showing actions (e.g., stop, go, turn left) for various intersection scenarios. \n",
    "\n",
    "What type of learning is the car using?\n",
    "\n",
    "**A)** Supervised learning  \n",
    "**B)** Unsupervised learning  \n",
    "**C)** Reinforcement learning  \n",
    "**D)** Semi-supervised learning  \n",
    "\n",
    "**Correct Answer:** **A) Supervised learning**  \n",
    "**Reasoning:** The car uses labeled data (actions paired with scenarios), which is the hallmark of supervised learning.\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 2: Supervised Learning Formulation**\n",
    "A regression model is trained to predict house prices based on the number of bedrooms, square footage, and lot size. The true function $f(x)$ is unknown. Which of the following represents the supervised learning problem?\n",
    "\n",
    "**A)** Finding the function $h(x)$ that minimizes the error on the test set.  \n",
    "**B)** Finding the function $f(x)$ that exactly matches the data.  \n",
    "**C)** Estimating the relationship between features without labels.  \n",
    "**D)** Clustering the houses into price ranges.  \n",
    "\n",
    "**Correct Answer:** **A) Finding the function $h(x)$ that minimizes the error on the test set.**  \n",
    "**Reasoning:** The goal of supervised learning is to approximate the true function $f(x)$ with a hypothesis $h(x)$ that generalizes well to unseen data.\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 3: Hypotheses**\n",
    "Given the hypothesis space $H = \\{h_1, h_2, h_3\\}$, a decision tree $h_1$ achieves 0% error on the training data but 40% error on the test set. Another decision tree $h_2$ has 10% training error and 15% test error. Which hypothesis should you select?\n",
    "\n",
    "**A)** $h_1$, because it perfectly fits the training data.  \n",
    "**B)** $h_2$, because it generalizes better to unseen data.  \n",
    "**C)** Any, since all are valid hypotheses.  \n",
    "**D)** Neither, because both have errors.  \n",
    "\n",
    "**Correct Answer:** **B) $h_2$, because it generalizes better to unseen data.**  \n",
    "**Reasoning:** $h_1$ is overfitting, while $h_2$ strikes a better balance between training and test performance, showing better generalization.\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 4: Bias-Variance Tradeoff**\n",
    "A machine learning model achieves very low training error but performs poorly on test data. What is the most likely cause?\n",
    "\n",
    "**A)** High bias  \n",
    "**B)** High variance  \n",
    "**C)** Low bias and low variance  \n",
    "**D)** Neither bias nor variance  \n",
    "\n",
    "**Correct Answer:** **B) High variance**  \n",
    "**Reasoning:** High variance models memorize the training data but fail to generalize, leading to poor performance on test data.\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 5: Decision Trees**\n",
    "Which attribute should a decision tree split on first, given the following training data?\n",
    "\n",
    "| Attribute A | Attribute B | Output |\n",
    "|-------------|-------------|--------|\n",
    "| High        | Yes         | 1      |\n",
    "| Low         | Yes         | 0      |\n",
    "| Medium      | No          | 1      |\n",
    "| High        | No          | 1      |\n",
    "\n",
    "**A)** Attribute A  \n",
    "**B)** Attribute B  \n",
    "**C)** Randomly choose either A or B  \n",
    "**D)** Both A and B simultaneously  \n",
    "\n",
    "**Correct Answer:** **A) Attribute A**  \n",
    "**Reasoning:** Calculate the information gain for both attributes. Attribute A provides more information for classification as it reduces the entropy of the output more effectively.\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 6: Perceptron**\n",
    "Which of the following datasets cannot be correctly classified by a perceptron?\n",
    "\n",
    "| $x_1$ | $x_2$ | Output |\n",
    "|--------|--------|--------|\n",
    "| 0      | 0      | 0      |\n",
    "| 0      | 1      | 1      |\n",
    "| 1      | 0      | 1      |\n",
    "| 1      | 1      | 0      |\n",
    "\n",
    "**A)** Any dataset with two inputs  \n",
    "**B)** A linearly separable dataset  \n",
    "**C)** The dataset above (XOR problem)  \n",
    "**D)** None of the above  \n",
    "\n",
    "**Correct Answer:** **C) The dataset above (XOR problem)**  \n",
    "**Reasoning:** The XOR problem is not linearly separable, so a perceptron cannot find a single hyperplane to separate the classes.\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 7: Support Vector Machines**\n",
    "You train an SVM with a linear kernel on a binary classification problem. Which of the following changes is most likely to improve performance on a non-linearly separable dataset?\n",
    "\n",
    "**A)** Increase the number of support vectors.  \n",
    "**B)** Use a polynomial or RBF kernel.  \n",
    "**C)** Reduce the margin width.  \n",
    "**D)** Add more data to the training set.  \n",
    "\n",
    "**Correct Answer:** **B) Use a polynomial or RBF kernel**  \n",
    "**Reasoning:** Non-linear kernels allow the SVM to separate data in a transformed feature space, addressing non-linear relationships in the original data.\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 8: Generalization**\n",
    "Which of the following is the best indicator of good generalization in a machine learning model?\n",
    "\n",
    "**A)** Low error on the training set  \n",
    "**B)** Low error on the validation set  \n",
    "**C)** Low complexity of the hypothesis space  \n",
    "**D)** High variance in predictions  \n",
    "\n",
    "**Correct Answer:** **B) Low error on the validation set**  \n",
    "**Reasoning:** Validation set performance reflects how well the model generalizes to unseen data, unlike training error which may indicate overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 9: Overfitting**\n",
    "Which of the following is NOT a method to address overfitting?\n",
    "\n",
    "**A)** Using a simpler model  \n",
    "**B)** Reducing the size of the training set  \n",
    "**C)** Adding regularization to the cost function  \n",
    "**D)** Using cross-validation  \n",
    "\n",
    "**Correct Answer:** **B) Reducing the size of the training set**  \n",
    "**Reasoning:** Reducing the training set size can exacerbate overfitting by giving the model less data to generalize from.\n",
    "\n",
    "---\n",
    "\n",
    "Here are five additional open-book, problem-solving multiple-choice questions covering the same topics:\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 10: Supervised Learning**\n",
    "You are training a supervised learning model for binary classification. After training, you observe the following error rates:\n",
    "\n",
    "- Training error: 5%  \n",
    "- Validation error: 25%  \n",
    "\n",
    "Which of the following is the most likely cause?\n",
    "\n",
    "**A)** High bias  \n",
    "**B)** High variance  \n",
    "**C)** Low bias, low variance  \n",
    "**D)** Low bias, high variance  \n",
    "\n",
    "**Correct Answer:** **D) Low bias, high variance**  \n",
    "**Reasoning:** The model has low training error (low bias) but high validation error, indicating it overfits the training data and fails to generalize (high variance).\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 11: Decision Trees**\n",
    "A decision tree is trained on a dataset with the following stopping criteria:\n",
    "1. Minimum information gain = 0.1  \n",
    "2. Maximum tree depth = 5  \n",
    "\n",
    "What will happen if the maximum depth is increased to 10?\n",
    "\n",
    "**A)** The tree will generalize better to new data.  \n",
    "**B)** The tree may overfit the training data.  \n",
    "**C)** The tree will become less interpretable but improve generalization.  \n",
    "**D)** The information gain at each split will decrease.  \n",
    "\n",
    "**Correct Answer:** **B) The tree may overfit the training data.**  \n",
    "**Reasoning:** Increasing the maximum depth allows the tree to split more, potentially fitting noise in the training data and leading to overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 12: Perceptron**\n",
    "The perceptron update rule is given as:\n",
    "\n",
    "$\n",
    "\\text{w} \\gets \\text{w} + \\eta \\cdot (\\text{y} - \\hat{\\text{y}}) \\cdot \\text{x}\n",
    "$\n",
    "\n",
    "Where:\n",
    "- $\\text{w}$: Weight vector  \n",
    "- $\\eta$: Learning rate  \n",
    "- $\\text{y}$: True label  \n",
    "- $\\hat{\\text{y}}$: Predicted label  \n",
    "\n",
    "What happens if the perceptron encounters a point that is already correctly classified ($ \\text{y} = \\hat{\\text{y}} $)?\n",
    "\n",
    "**A)** The weights are updated by a small amount.  \n",
    "**B)** The weights remain unchanged.  \n",
    "**C)** The learning rate decreases.  \n",
    "**D)** The model predicts incorrectly.  \n",
    "\n",
    "**Correct Answer:** **B) The weights remain unchanged.**  \n",
    "**Reasoning:** When $ \\text{y} = \\hat{\\text{y}} $, the update rule results in no change to the weights, as $ (\\text{y} - \\hat{\\text{y}}) = 0 $.\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 13: Bias-Variance Tradeoff**\n",
    "A machine learning engineer is trying to improve a model's performance. They reduce the degree of a polynomial regression model from 5 to 2. Which of the following is most likely to occur?\n",
    "\n",
    "**A)** Training error will increase, and test error will decrease.  \n",
    "**B)** Both training error and test error will increase.  \n",
    "**C)** Training error will decrease, and test error will increase.  \n",
    "**D)** Both training error and test error will decrease.  \n",
    "\n",
    "**Correct Answer:** **A) Training error will increase, and test error will decrease.**  \n",
    "**Reasoning:** Reducing the polynomial degree simplifies the model (reduces variance), which may slightly increase training error but improve generalization, reducing test error.\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 14: Support Vector Machines**\n",
    "A Support Vector Machine (SVM) with a linear kernel fails to separate the data. The engineer switches to an RBF (Gaussian) kernel, and the model achieves perfect accuracy on the training set but poor accuracy on the test set. What is the most likely issue?\n",
    "\n",
    "**A)** The linear kernel was insufficiently complex.  \n",
    "**B)** The RBF kernel overfits the training data.  \n",
    "**C)** The SVM was trained on too much data.  \n",
    "**D)** The RBF kernel underfits the training data.  \n",
    "\n",
    "**Correct Answer:** **B) The RBF kernel overfits the training data.**  \n",
    "**Reasoning:** The RBF kernel is highly flexible and may fit noise in the training data, leading to perfect accuracy on the training set but poor generalization to the test set.\n",
    "\n",
    "---\n",
    "\n",
    "### Additional Notes:\n",
    "Each of these questions requires reasoning and knowledge application rather than simple recall, aligning well with the open-book format. Let me know if you’d like even more! 😊"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1e9a2b-478c-45e3-85cc-79ba5ec03ef1",
   "metadata": {},
   "source": [
    "# ch 20 \n",
    "\n",
    "Here is a series of multiple-choice questions that involve working through problems on **maximum likelihood estimation (MLE)**, **maximum a posteriori (MAP)**, and **Bayesian learning**. Each question includes the answer and the reasoning behind it.\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 1: Maximum Likelihood Estimation for a Discrete Model**\n",
    "\n",
    "A six-sided die is rolled 100 times, and the results are summarized as follows:\n",
    "\n",
    "| Side | 1  | 2  | 3  | 4  | 5  | 6  |\n",
    "|------|----|----|----|----|----|----|\n",
    "| Count| 20 | 15 | 25 | 10 | 20 | 10 |\n",
    "\n",
    "Assume the die has a discrete probability distribution $ P(X=i) = p_i $, where $ i \\in \\{1, 2, 3, 4, 5, 6\\} $. What are the MLE estimates for $ p_1, p_2, \\dots, p_6 $?\n",
    "\n",
    "#### Options:\n",
    "A. $ p_i = \\frac{1}{6} $ for all $ i $.  \n",
    "B. $ p_i = \\frac{\\text{Count of side } i}{100} $.  \n",
    "C. $ p_i = \\frac{\\sqrt{\\text{Count of side } i}}{\\sum_{j=1}^6 \\sqrt{\\text{Count of side } j}} $.  \n",
    "D. $ p_i = \\frac{\\text{Count of side } i + 1}{106} $ (Laplace smoothing).\n",
    "\n",
    "#### **Answer**: **B**  \n",
    "#### **Reasoning**:  \n",
    "MLE maximizes the likelihood $ L(\\mathbf{p}) = \\prod_{i=1}^6 p_i^{\\text{Count}_i} $, subject to $ \\sum p_i = 1 $. The solution is $ p_i = \\frac{\\text{Count}_i}{\\text{Total Count}} = \\frac{\\text{Count}_i}{100} $.\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 2: Maximum Likelihood Estimation for a Continuous Model**\n",
    "\n",
    "Suppose you are given $ n $ independent observations $ x_1, x_2, \\dots, x_n $ from a normal distribution with unknown mean $ \\mu $ and variance $ \\sigma^2 $. What is the MLE for $ \\mu $?\n",
    "\n",
    "#### Options:\n",
    "A. $ \\mu = \\frac{\\sum_{i=1}^n x_i}{n} $.  \n",
    "B. $ \\mu = \\frac{\\sum_{i=1}^n x_i}{n-1} $.  \n",
    "C. $ \\mu = \\text{Median of } \\{x_1, x_2, \\dots, x_n\\} $.  \n",
    "D. $ \\mu = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})^2}{n} $.\n",
    "\n",
    "#### **Answer**: **A**  \n",
    "#### **Reasoning**:  \n",
    "The likelihood function is $ L(\\mu, \\sigma^2) = \\prod_{i=1}^n \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(x_i - \\mu)^2}{2\\sigma^2}\\right) $. Taking the derivative of the log-likelihood with respect to $ \\mu $ and setting it to zero yields $ \\mu = \\frac{\\sum_{i=1}^n x_i}{n} $.\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 3: Maximum a Posteriori Estimation**\n",
    "\n",
    "A biased coin is flipped 10 times, and the results are 7 heads and 3 tails. Assume a prior distribution on the probability of heads $ \\theta $ given by $ \\text{Beta}(2, 2) $. What is the MAP estimate for $ \\theta $?\n",
    "\n",
    "#### Options:\n",
    "A. $ \\theta = \\frac{7}{10} $.  \n",
    "B. $ \\theta = \\frac{7 + 2 - 1}{10 + 2 + 2 - 2} = \\frac{8}{12} $.  \n",
    "C. $ \\theta = \\frac{7 + 2}{10 + 4} = \\frac{9}{14} $.  \n",
    "D. $ \\theta = \\frac{7}{10} + \\frac{2}{4} $.\n",
    "\n",
    "#### **Answer**: **B**  \n",
    "#### **Reasoning**:  \n",
    "The posterior distribution is $ \\text{Beta}(\\alpha + k, \\beta + n - k) = \\text{Beta}(2 + 7, 2 + 3) = \\text{Beta}(9, 5) $. The MAP estimate is $ \\frac{\\alpha - 1 + k}{\\alpha + \\beta - 2 + n} = \\frac{7 + 2 - 1}{10 + 2 + 2 - 2} $.\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 4: Bayesian Learning**\n",
    "\n",
    "You are building a Bayesian spam classifier. The training data consists of 1,000 emails, of which 300 are spam. The word \"discount\" appears in 50 spam emails and 20 non-spam emails. What is the posterior probability $ P(\\text{spam} | \\text{\"discount\"}) $, assuming a uniform prior?\n",
    "\n",
    "#### Options:\n",
    "A. $ \\frac{50}{70} $.  \n",
    "B. $ \\frac{50 / 300}{(50 / 300) + (20 / 700)} $.  \n",
    "C. $ \\frac{50 + 1}{300 + 2} $.  \n",
    "D. $ \\frac{50 / 300}{50 / 300 + 20 / 700} \\cdot \\frac{300}{1000} $.\n",
    "\n",
    "#### **Answer**: **D**  \n",
    "#### **Reasoning**:  \n",
    "Bayes' rule:  \n",
    "$$\n",
    "P(\\text{spam} | \\text{\"discount\"}) = \\frac{P(\\text{\"discount\"} | \\text{spam}) P(\\text{spam})}{P(\\text{\"discount\"})}.\n",
    "$$\n",
    "Here:\n",
    "- $ P(\\text{\"discount\"} | \\text{spam}) = \\frac{50}{300} $,\n",
    "- $ P(\\text{spam}) = \\frac{300}{1000} $,\n",
    "- $ P(\\text{\"discount\"}) = P(\\text{\"discount\"} | \\text{spam})P(\\text{spam}) + P(\\text{\"discount\"} | \\text{non-spam})P(\\text{non-spam}) $.  \n",
    "\n",
    "Plugging these values in, $ P(\\text{\"discount\"} | \\text{non-spam}) = \\frac{20}{700} $ and $ P(\\text{non-spam}) = \\frac{700}{1000} $.\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 5: Comparing MLE, MAP, and Bayesian Learning**\n",
    "\n",
    "Which of the following statements is **true** regarding MLE, MAP, and Bayesian learning?\n",
    "\n",
    "#### Options:\n",
    "A. MLE ignores prior information, while MAP incorporates prior distributions.  \n",
    "B. Bayesian learning directly maximizes the posterior distribution without considering priors.  \n",
    "C. MLE is equivalent to MAP with a uniform prior.  \n",
    "D. Both A and C are true.\n",
    "\n",
    "#### **Answer**: **D**  \n",
    "#### **Reasoning**:  \n",
    "- **A**: MLE uses only the likelihood and does not account for priors, while MAP incorporates prior distributions.  \n",
    "- **C**: When the prior is uniform, MAP reduces to MLE because the prior does not affect the posterior.  \n",
    "- Bayesian learning does not \"maximize\" the posterior but uses the full posterior distribution for predictions, which makes B incorrect.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary of Topics Covered:\n",
    "- **Q1**: MLE for discrete models.  \n",
    "- **Q2**: MLE for continuous models.  \n",
    "- **Q3**: MAP estimation with Beta prior.  \n",
    "- **Q4**: Bayesian inference with spam classification.  \n",
    "- **Q5**: Conceptual comparison of MLE, MAP, and Bayesian learning.\n",
    "\n",
    "Here are five more open-book, multiple-choice questions covering **MLE, MAP, and Bayesian learning**, with detailed answers and reasoning.\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 6: MLE for a Bernoulli Distribution**\n",
    "\n",
    "You flip a coin $ n = 20 $ times and observe $ k = 12 $ heads. Assume the coin follows a Bernoulli distribution $ P(X = 1; \\theta) = \\theta $, where $ \\theta $ is the probability of heads. What is the MLE estimate for $ \\theta $?\n",
    "\n",
    "#### Options:\n",
    "A. $ \\theta = \\frac{12}{20} $.  \n",
    "B. $ \\theta = \\frac{12 + 1}{20 + 2} $.  \n",
    "C. $ \\theta = \\frac{12}{21} $.  \n",
    "D. $ \\theta = \\frac{12}{19} $.\n",
    "\n",
    "#### **Answer**: **A**  \n",
    "#### **Reasoning**:  \n",
    "The likelihood function is:\n",
    "$$\n",
    "L(\\theta) = \\theta^{k}(1 - \\theta)^{n - k}.\n",
    "$$\n",
    "Maximizing the log-likelihood $ \\ell(\\theta) = k \\log \\theta + (n - k) \\log (1 - \\theta) $, the derivative gives $ \\theta = \\frac{k}{n} = \\frac{12}{20} $.\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 7: MAP for a Gaussian Distribution**\n",
    "\n",
    "Let $ x_1, x_2, \\dots, x_n $ be $ n = 10 $ observations from a Gaussian distribution with unknown mean $ \\mu $ and known variance $ \\sigma^2 = 1 $. Assume a prior $ \\mu \\sim N(0, 1) $. The sample mean is $ \\bar{x} = 2 $. What is the MAP estimate of $ \\mu $?\n",
    "\n",
    "#### Options:\n",
    "A. $ \\mu = 2 $.  \n",
    "B. $ \\mu = \\frac{10 \\cdot 2 + 0}{10 + 1} = \\frac{20}{11} $.  \n",
    "C. $ \\mu = \\frac{10 \\cdot 2 + 1}{10 + 1} $.  \n",
    "D. $ \\mu = 0.5 \\cdot 2 = 1 $.\n",
    "\n",
    "#### **Answer**: **B**  \n",
    "#### **Reasoning**:  \n",
    "MAP maximizes the posterior:\n",
    "$$\n",
    "P(\\mu | x) \\propto P(x | \\mu) P(\\mu).\n",
    "$$\n",
    "The posterior combines the likelihood $ N(\\bar{x}, \\frac{1}{n}) $ and the prior $ N(0, 1) $. The MAP estimate is a weighted average of the prior and sample mean:\n",
    "$\n",
    "\\mu = \\frac{n \\bar{x} + 0}{n + \\frac{\\sigma^2}{\\tau^2}} = \\frac{10 \\cdot 2}{10 + 1} = \\frac{20}{11}.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 8: Bayesian Inference for Coin Flipping**\n",
    "\n",
    "You flip a coin 10 times and observe 6 heads. Assume a prior $ \\theta \\sim \\text{Beta}(2, 2) $. What is the posterior distribution of $ \\theta $?\n",
    "\n",
    "#### Options:\n",
    "A. $ \\text{Beta}(6, 6) $.  \n",
    "B. $ \\text{Beta}(8, 6) $.  \n",
    "C. $ \\text{Beta}(8, 8) $.  \n",
    "D. $ \\text{Beta}(7, 7) $.\n",
    "\n",
    "#### **Answer**: **B**  \n",
    "#### **Reasoning**:  \n",
    "The posterior for $ \\theta \\sim \\text{Beta}(\\alpha + k, \\beta + n - k) $. Here:\n",
    "- Prior $ \\text{Beta}(2, 2) $, $ k = 6 $, $ n - k = 4 $.  \n",
    "$\n",
    "\\alpha = 2 + 6, \\; \\beta = 2 + 4 \\; \\Rightarrow \\; \\text{Beta}(8, 6).\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 9: Likelihood vs Posterior**\n",
    "\n",
    "Suppose you observe data $ x_1, x_2, \\dots, x_n $ from a distribution $ f(x | \\theta) $, and you assume a prior $ p(\\theta) $. Which of the following statements is true?\n",
    "\n",
    "#### Options:\n",
    "A. The likelihood is proportional to the posterior.  \n",
    "B. The posterior is proportional to the likelihood times the prior.  \n",
    "C. The prior is proportional to the likelihood.  \n",
    "D. The likelihood and the posterior are equivalent if the prior is uniform.\n",
    "\n",
    "#### **Answer**: **B**  \n",
    "#### **Reasoning**:  \n",
    "Bayes' theorem states:\n",
    "$\n",
    "P(\\theta | x) \\propto P(x | \\theta) P(\\theta).\n",
    "$$\n",
    "The posterior is proportional to the likelihood times the prior. This makes B true. D is correct only if the likelihood is uniform, not the prior.\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 10: Comparing MLE and Bayesian Predictions**\n",
    "\n",
    "A biased coin has an unknown probability $ \\theta $ of landing heads. It is flipped 5 times, resulting in 3 heads and 2 tails. Assume a uniform prior for $ \\theta $. What is the Bayesian predictive probability that the next flip will land heads?\n",
    "\n",
    "#### Options:\n",
    "A. $ \\frac{3}{5} $.  \n",
    "B. $ \\frac{4}{7} $.  \n",
    "C. $ \\frac{3 + 1}{5 + 2} = \\frac{4}{7} $.  \n",
    "D. $ \\frac{3 + 0}{5 + 2} = \\frac{3}{7} $.\n",
    "\n",
    "#### **Answer**: **C**  \n",
    "#### **Reasoning**:  \n",
    "The posterior for $ \\theta $ after observing $ k = 3 $ heads and $ n = 5 $ trials with a uniform prior is:\n",
    "$\n",
    "\\text{Beta}(k + 1, n - k + 1) = \\text{Beta}(4, 3).\n",
    "$$\n",
    "The Bayesian predictive probability for the next flip is:\n",
    "$\n",
    "P(\\text{heads next}) = \\frac{\\alpha}{\\alpha + \\beta} = \\frac{4}{4 + 3} = \\frac{4}{7}.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Summary of Topics Covered:\n",
    "- **Q6**: MLE for a Bernoulli model.  \n",
    "- **Q7**: MAP for Gaussian distribution with prior.  \n",
    "- **Q8**: Bayesian posterior update for Beta distribution.  \n",
    "- **Q9**: Relationship between likelihood, prior, and posterior.  \n",
    "- **Q10**: Bayesian prediction for Bernoulli trials."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ab5f37-9a99-4ac2-9f6c-57a719431203",
   "metadata": {},
   "source": [
    "# ch 21\n",
    "\n",
    "Here’s a set of multiple-choice questions for an open-book exam based on **Section 21.4: Learning Bayesian Network Structures**. These problems require calculations or conceptual reasoning.\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 1: Likelihood Calculation**\n",
    "A Bayesian network consists of three nodes $A$, $B$, and $C$ with the structure $A \\rightarrow B \\rightarrow C$. Given the data:\n",
    "\n",
    "| $A$ | $B$ | $C$ |\n",
    "|-------|-------|-------|\n",
    "| 0     | 0     | 1     |\n",
    "| 1     | 1     | 0     |\n",
    "| 1     | 1     | 1     |\n",
    "| 0     | 0     | 0     |\n",
    "\n",
    "Assume $P(A = 1) = 0.5$, $P(B = 1 | A = 1) = 0.75$, $P(C = 1 | B = 1) = 0.8$. Calculate the likelihood of the observed data.\n",
    "\n",
    "A) $0.2016$  \n",
    "B) $0.3456$  \n",
    "C) $0.1728$  \n",
    "D) $0.5120$  \n",
    "\n",
    "**Answer:**  \n",
    "**B) $0.3456$**\n",
    "\n",
    "**Reasoning:**  \n",
    "- Likelihood $L = \\prod_{i=1}^4 P(A_i, B_i, C_i)$.  \n",
    "- Each term is expanded using the conditional probabilities. For example:\n",
    "  - For row 1: $P(A=0, B=0, C=1) = P(A=0)P(B=0|A=0)P(C=1|B=0)$.  \n",
    "  - Combine all rows' probabilities to calculate the likelihood.\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 2: Edge Modification Impact**\n",
    "In a Bayesian network, you are learning a structure with nodes $X$, $Y$, and $Z$. Initially, there is an edge $X \\rightarrow Z$. During the learning process, an edge $Y \\rightarrow Z$ is added. Which of the following would **not** occur?\n",
    "\n",
    "A) The likelihood of the data given the model may increase.  \n",
    "B) The network's complexity penalty may increase.  \n",
    "C) The independence assumptions encoded in the network may change.  \n",
    "D) The number of parameters for $Z$ remains unchanged.\n",
    "\n",
    "**Answer:**  \n",
    "**D) The number of parameters for $Z$ remains unchanged.**\n",
    "\n",
    "**Reasoning:**  \n",
    "- Adding $Y \\rightarrow Z$ changes the parent set of $Z$, increasing its parameters.  \n",
    "- The other options are valid outcomes of edge addition.\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 3: Scoring with MDL**\n",
    "You are scoring a Bayesian network using the **Minimum Description Length (MDL)** principle. Which of the following changes would most likely **decrease** the MDL score?\n",
    "\n",
    "A) Adding an edge that significantly improves the data likelihood.  \n",
    "B) Removing an edge with little impact on likelihood.  \n",
    "C) Reversing an edge, increasing the model's complexity.  \n",
    "D) Adding an edge that marginally improves likelihood but greatly increases complexity.\n",
    "\n",
    "**Answer:**  \n",
    "**B) Removing an edge with little impact on likelihood.**\n",
    "\n",
    "**Reasoning:**  \n",
    "- MDL balances likelihood improvement and model complexity. Removing an unnecessary edge reduces complexity without harming likelihood, improving the score.\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 4: Hill-Climbing for Structure Learning**\n",
    "You are using a **hill-climbing algorithm** for Bayesian network structure learning. Which of the following scenarios would result in the algorithm **failing** to find the optimal structure?\n",
    "\n",
    "A) The scoring function has a local maximum.  \n",
    "B) The data are insufficient to establish relationships.  \n",
    "C) The network starts with no edges.  \n",
    "D) The algorithm has no limit on iterations.\n",
    "\n",
    "**Answer:**  \n",
    "**A) The scoring function has a local maximum.**\n",
    "\n",
    "**Reasoning:**  \n",
    "- Hill climbing may converge to a local maximum, preventing discovery of the global optimum. Insufficient data (B) might limit model quality but doesn't affect optimization.\n",
    "\n",
    "---\n",
    "\n",
    "### **Question 5: Structure Learning Example**\n",
    "You are given the following data and learn a Bayesian network structure using **greedy search**. The final structure contains two edges: $A \\rightarrow B$ and $B \\rightarrow C$. Which is the most plausible reason for this structure?\n",
    "\n",
    "| $A$ | $B$ | $C$ |\n",
    "|-------|-------|-------|\n",
    "| 0     | 0     | 0     |\n",
    "| 1     | 1     | 1     |\n",
    "| 0     | 0     | 0     |\n",
    "| 1     | 1     | 1     |\n",
    "\n",
    "A) $A$ and $C$ are conditionally independent given $B$.  \n",
    "B) $A$ directly influences $C$.  \n",
    "C) $A$ is conditionally independent of $B$.  \n",
    "D) $B$ does not influence $C$.\n",
    "\n",
    "**Answer:**  \n",
    "**A) $A$ and $C$ are conditionally independent given $B$.**\n",
    "\n",
    "**Reasoning:**  \n",
    "- The structure $A \\rightarrow B \\rightarrow C$ encodes $P(C | A, B) = P(C | B)$, implying $A$ and $C$ are conditionally independent given $B$.\n",
    "\n",
    "---\n",
    "\n",
    "These multiple-choice questions encourage application of concepts like likelihood computation, structure learning, scoring, and independence reasoning. Let me know if you’d like more questions or additional clarification!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2693a122-1fe7-4f46-80c1-7c7b7697459f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
