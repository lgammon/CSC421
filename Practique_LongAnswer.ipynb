{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba6a8e2f-796e-4288-af83-9f9011b95322",
   "metadata": {},
   "source": [
    "### Example Exam Question from Section 2.1: Task Environment Properties\n",
    "\n",
    "**Question:**\n",
    "Consider the task environment of an **autonomous vacuum cleaner** designed to clean a rectangular room with dirt randomly distributed on the floor. The vacuum cleaner can move left, right, up, or down and can either suck up dirt or do nothing at a location.\n",
    "\n",
    "1. Describe the task environment of the autonomous vacuum cleaner in terms of the following properties:\n",
    "   - Fully Observable vs. Partially Observable\n",
    "   - Single-Agent vs. Multi-Agent\n",
    "   - Deterministic vs. Stochastic\n",
    "   - Episodic vs. Sequential\n",
    "   - Static vs. Dynamic\n",
    "   - Discrete vs. Continuous\n",
    "\n",
    "2. Discuss how each property affects the design of the vacuum cleaner’s agent.\n",
    "\n",
    "---\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "1. **Task Environment Properties:**\n",
    "   - **Fully Observable vs. Partially Observable:**\n",
    "     The environment is **partially observable** if the vacuum cleaner has limited sensors (e.g., it can only detect dirt at its current location or in a small radius). If it has a global view of the room, it would be **fully observable**.\n",
    "   - **Single-Agent vs. Multi-Agent:**\n",
    "     This is a **single-agent** environment as only the vacuum cleaner is actively making decisions. However, if another vacuum cleaner operates simultaneously, it could become a **multi-agent** environment.\n",
    "   - **Deterministic vs. Stochastic:**\n",
    "     The environment is **stochastic** if dirt randomly appears or if actions like sucking dirt fail occasionally. If dirt does not reappear and actions always succeed, the environment is **deterministic**.\n",
    "   - **Episodic vs. Sequential:**\n",
    "     The environment is **sequential** because the current actions of the vacuum cleaner (e.g., movement or cleaning) influence future states of the environment (e.g., where it moves next or what dirt remains).\n",
    "   - **Static vs. Dynamic:**\n",
    "     The environment is **dynamic** if dirt can appear or disappear while the vacuum cleaner is deliberating. It is **static** if dirt locations remain fixed during operation.\n",
    "   - **Discrete vs. Continuous:**\n",
    "     The environment is **discrete** if the room is divided into a grid of finite squares that the vacuum can move between. If the vacuum moves smoothly in any direction, the environment is **continuous**.\n",
    "\n",
    "---\n",
    "\n",
    "2. **Impact on Agent Design:**\n",
    "   - **Observability:** \n",
    "     If the environment is partially observable, the agent will need to maintain an internal representation of the room (e.g., a map) to track areas it has cleaned. If fully observable, no internal state is necessary.\n",
    "   - **Single vs. Multi-Agent:**\n",
    "     In a single-agent scenario, the agent focuses on optimizing its own performance. In a multi-agent scenario, the agent might need to coordinate or compete with other vacuums.\n",
    "   - **Determinism:** \n",
    "     In a stochastic environment, the agent will need a probabilistic model to handle uncertainty (e.g., \"What if sucking fails?\"). In a deterministic environment, simpler decision-making suffices.\n",
    "   - **Episodicity:** \n",
    "     In a sequential environment, the agent needs a long-term strategy (e.g., remembering where it has already cleaned). In an episodic environment, each action is independent, simplifying the agent’s design.\n",
    "   - **Dynamics:** \n",
    "     In a dynamic environment, the agent needs real-time responses and must adapt quickly to changes (e.g., new dirt appearing). In a static environment, the agent can plan its moves more thoroughly.\n",
    "   - **Discreteness:** \n",
    "     A discrete environment allows the agent to use grid-based pathfinding algorithms (e.g., A*). In a continuous environment, the agent must handle real-valued locations and smooth motion planning.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c6fc2d-f07c-438f-ad71-a3fc1a1a671f",
   "metadata": {},
   "source": [
    "### Example Exam Question from Section 2.2: Rationality of Agents\n",
    "\n",
    "**Question:**\n",
    "An autonomous drone is tasked with delivering packages in a city. It can navigate between designated delivery points while avoiding obstacles like buildings and other drones. The drone’s performance measure is based on the following criteria:\n",
    "- Successfully delivering packages to their destinations.\n",
    "- Minimizing delivery time.\n",
    "- Avoiding collisions.\n",
    "\n",
    "1. Define what it means for the drone to be **rational** in this task environment.\n",
    "2. How would the task environment properties (e.g., fully observable, stochastic, dynamic) influence the design of a rational agent for this drone?\n",
    "3. Discuss the role of utility functions in making the drone a utility-based agent and how it could handle trade-offs between minimizing delivery time and avoiding collisions.\n",
    "\n",
    "---\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "1. **Definition of Rationality:**\n",
    "   A drone is **rational** if, for every percept sequence it experiences, it selects an action that maximizes its performance measure, given its knowledge and available actions. In this case, a rational drone would:\n",
    "   - Deliver packages efficiently to their correct destinations.\n",
    "   - Choose routes that minimize delivery time while considering real-time obstacles.\n",
    "   - Prioritize avoiding collisions to ensure safety.\n",
    "\n",
    "   Rationality depends on the quality of the drone’s sensors, its ability to predict outcomes of actions, and its capacity to learn and adapt over time.\n",
    "\n",
    "---\n",
    "\n",
    "2. **Influence of Task Environment Properties:**\n",
    "   - **Fully Observable vs. Partially Observable:**\n",
    "     - If fully observable, the drone has complete knowledge of the city layout, obstacle locations, and traffic. It can directly plan optimal paths.\n",
    "     - If partially observable (e.g., obstacles might only be detected within a certain radius), the drone needs to maintain an internal map and rely on real-time updates.\n",
    "   - **Deterministic vs. Stochastic:**\n",
    "     - In a deterministic environment, actions like \"move forward\" have predictable outcomes, simplifying path planning.\n",
    "     - In a stochastic environment (e.g., unpredictable wind or other drones’ movements), the drone needs probabilistic models to handle uncertainty.\n",
    "   - **Dynamic vs. Static:**\n",
    "     - In a dynamic environment, the drone must continuously update its plans to account for moving obstacles (e.g., other drones).\n",
    "     - In a static environment, the drone can precompute paths without worrying about changes in the environment.\n",
    "   - **Episodic vs. Sequential:**\n",
    "     - In a sequential environment, the drone must consider how its current actions (e.g., taking a longer route to avoid congestion) affect future deliveries.\n",
    "     - In an episodic environment, each delivery is independent, allowing the drone to focus on one task at a time.\n",
    "\n",
    "---\n",
    "\n",
    "3. **Role of Utility Functions:**\n",
    "   Utility functions assign a numeric value to each possible outcome, enabling the agent to handle trade-offs rationally. For the drone:\n",
    "   - The utility function could include components like:\n",
    "     - Delivery success (+10 for each package delivered).\n",
    "     - Penalties for delays (-1 for each minute late).\n",
    "     - Severe penalties for collisions (-100 for a collision).\n",
    "   - Example: The drone might choose a slightly longer route (with a small time penalty) to avoid areas with high collision risk, as avoiding collisions has a much larger impact on utility.\n",
    "   - **Trade-off Handling:**\n",
    "     - If two routes are available:\n",
    "       - Route A takes 5 minutes with a 10% collision risk.\n",
    "       - Route B takes 7 minutes with a 0% collision risk.\n",
    "     - Utility function:\n",
    "       $ U(RouteA) = -5 + (-100 \\times 0.1) = -15 $\n",
    "       $ U(RouteB) = -7 + (-100 \\times 0) = -7 $\n",
    "       - The drone selects Route B because it has a higher utility.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70458193-108e-4bf1-9037-901e7068a1ab",
   "metadata": {},
   "source": [
    "# Certainly! Here’s an alternative approach to crafting a question for Section 2.3, focusing on applying the concepts rather than categorizing the properties directly:\n",
    "\n",
    "---\n",
    "\n",
    "### Alternative Example Exam Question for Section 2.3: The Nature of Environments\n",
    "\n",
    "**Question:**\n",
    "An agent is tasked with navigating through a maze to collect items and exit at a designated location. The maze includes the following features:\n",
    "- Some pathways are blocked by doors that can open or close randomly.\n",
    "- The maze contains other agents (robots) competing to collect the same items.\n",
    "- The agent can see its immediate surroundings but not the entire maze.\n",
    "\n",
    "1. Given this scenario, explain how the following properties of the environment interact with each other and influence the agent’s behavior:\n",
    "   - Observability\n",
    "   - Multi-Agent Nature\n",
    "   - Stochasticity\n",
    "   - Dynamics\n",
    "2. Describe an algorithm or approach the agent could use to handle **stochasticity** and **limited observability** effectively. \n",
    "3. Suppose the agent must compete with others to collect as many items as possible within a time limit. How would this change the agent's strategy, and which environment property becomes more critical in this context?\n",
    "\n",
    "---\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "1. **Interaction of Environment Properties:**\n",
    "   - **Observability:** \n",
    "     The environment is partially observable because the agent can only see its immediate surroundings. This limitation forces the agent to build an internal map to track visited areas and infer unseen parts of the maze.\n",
    "   - **Multi-Agent Nature:**\n",
    "     Competing robots add complexity because they may block paths, collect items before the agent reaches them, or alter the environment (e.g., opening or closing doors). The agent must account for these interactions in its strategy.\n",
    "   - **Stochasticity:**\n",
    "     Doors that open and close randomly introduce uncertainty, making it impossible to plan with complete confidence. The agent needs to evaluate probabilities and adapt its actions in real-time.\n",
    "   - **Dynamics:**\n",
    "     The environment is dynamic due to moving agents and changing door states. The agent must continually update its map and re-evaluate its plans to navigate efficiently.\n",
    "\n",
    "---\n",
    "\n",
    "2. **Handling Stochasticity and Limited Observability:**\n",
    "   - **Approach:** \n",
    "     The agent can use **Partially Observable Markov Decision Processes (POMDPs)** to model uncertainty and make decisions. Key elements include:\n",
    "     - Maintaining a belief state (a probability distribution over possible maze configurations).\n",
    "     - Using probabilistic reasoning to decide actions that maximize expected reward (e.g., prioritizing pathways with a higher likelihood of open doors).\n",
    "   - **Algorithm:** \n",
    "     - A simplified alternative is to use **A* search** with dynamic updates:\n",
    "       - Incorporate a heuristic that estimates the likelihood of success for unexplored paths.\n",
    "       - Continuously update the path plan as new observations (e.g., door states) are made.\n",
    "\n",
    "---\n",
    "\n",
    "3. **Impact of Competition and Strategy Changes:**\n",
    "   - **Strategy Adjustments:**\n",
    "     - The agent must prioritize speed and adapt to opponents’ actions. Instead of fully exploring the maze, it might focus on nearby high-value items or block opponents from accessing critical areas.\n",
    "     - Opportunistic behavior (e.g., following another agent to take advantage of doors they open) becomes valuable.\n",
    "   - **Critical Property:**\n",
    "     - **Multi-Agent Nature** becomes the most critical property. The agent must anticipate and react to competitors’ actions, possibly using techniques like:\n",
    "       - Game theory to predict opponents’ moves.\n",
    "       - Randomized behavior to prevent predictability, especially in contested areas.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e50b9e9-2c2e-4c35-a422-a9b9cb8c51cc",
   "metadata": {},
   "source": [
    "### Alternative Example Exam Question for Section 2.4: The Structure of Agents\n",
    "\n",
    "**Question:**\n",
    "An agent is designed to manage energy usage in a smart home. Its task is to:\n",
    "- Monitor the energy consumption of various appliances.\n",
    "- Predict future energy demands based on patterns of use.\n",
    "- Control devices to optimize energy efficiency while maintaining comfort for occupants.\n",
    "\n",
    "The agent uses a structured representation of the environment, where appliances are objects with attributes (e.g., power usage, schedule) and relationships (e.g., one device's operation depends on another).\n",
    "\n",
    "1. Explain why a **structured representation** is appropriate for this agent, compared to atomic or factored representations.\n",
    "2. Discuss the challenges of reasoning and learning in a structured representation compared to a factored one. How can the agent overcome these challenges?\n",
    "3. Suggest a learning algorithm or reasoning method that leverages the structured representation to improve the agent’s performance over time.\n",
    "\n",
    "---\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "1. **Why a Structured Representation is Appropriate:**\n",
    "   - In this environment, the relationships between objects (appliances) are critical:\n",
    "     - For example, a washing machine might only operate if the water heater is running, and an air conditioner may need to adjust its usage based on room occupancy sensors.\n",
    "   - **Atomic representation** (treating states as indivisible \"black boxes\") would fail to capture these dependencies, making it impossible to reason about relationships or shared attributes.\n",
    "   - **Factored representation** (splitting states into independent variables) could represent individual appliance states (e.g., power on/off, energy consumption), but it would struggle to represent interdependencies (e.g., \"washing machine requires hot water\").\n",
    "   - **Structured representation** explicitly models objects (appliances) with their attributes and relationships, allowing the agent to reason about how changes in one object affect others.\n",
    "\n",
    "---\n",
    "\n",
    "2. **Challenges of Reasoning and Learning in Structured Representation:**\n",
    "   - **Complexity:** Structured representations are more expressive but computationally expensive. For example:\n",
    "     - Representing all possible states and relationships in a smart home with dozens of devices requires significant memory and processing power.\n",
    "   - **Dynamic Changes:** Relationships between objects may change over time (e.g., new appliances added, schedules altered), requiring continuous updates to the model.\n",
    "   - **Learning and Reasoning:**\n",
    "     - Reasoning in structured representations often involves first-order logic or probabilistic graphical models, which can be computationally intensive.\n",
    "     - Learning relationships and attributes from data may require significant amounts of labeled training data.\n",
    "\n",
    "   **Overcoming Challenges:**\n",
    "   - Use hierarchical models to simplify reasoning by grouping similar objects (e.g., lighting, HVAC, appliances) and focusing on higher-level relationships.\n",
    "   - Use incremental learning algorithms that update the model dynamically as new data becomes available, reducing the need for retraining from scratch.\n",
    "\n",
    "---\n",
    "\n",
    "3. **Learning Algorithm or Reasoning Method:**\n",
    "   - **Relational Reinforcement Learning (RRL):**\n",
    "     - This method combines reinforcement learning with relational models, allowing the agent to learn policies that consider objects and their relationships.\n",
    "     - For example, the agent can learn that reducing the HVAC system's energy use during peak hours minimizes costs without sacrificing comfort.\n",
    "   - **Bayesian Networks or Markov Logic Networks:**\n",
    "     - These are well-suited for structured environments, as they represent probabilistic relationships between objects and attributes.\n",
    "     - For instance, the agent can model the probability of an appliance being used based on time of day, occupant behavior, and other appliance states.\n",
    "   - **Graph Neural Networks (GNNs):**\n",
    "     - A modern approach where the environment is represented as a graph (nodes are appliances, edges represent relationships). The agent can use GNNs to reason about dependencies and optimize actions based on learned patterns.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c46a5a-3646-4ce2-a618-e2c09a3d1ad8",
   "metadata": {},
   "source": [
    "# Ch 3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866f9e05-58d1-4d56-a636-a16af9fe98b6",
   "metadata": {},
   "source": [
    "# Sure! Here's a worked example based on Section 3.1, \"Problem-Solving Agents.\"\n",
    "\n",
    "---\n",
    "\n",
    "### **Exam Question**\n",
    "\n",
    "An agent is trying to navigate from the city of Arad to Bucharest on the map of Romania (Figure 3.1). The agent can travel along roads connecting cities, with the following road distances:\n",
    "\n",
    "- Arad → Sibiu: 140\n",
    "- Arad → Timisoara: 118\n",
    "- Arad → Zerind: 75\n",
    "- Sibiu → Fagaras: 99\n",
    "- Sibiu → Rimnicu Vilcea: 80\n",
    "- Zerind → Oradea: 71\n",
    "- Oradea → Sibiu: 151\n",
    "- Timisoara → Lugoj: 111\n",
    "- Lugoj → Mehadia: 70\n",
    "- Mehadia → Drobeta: 75\n",
    "- Drobeta → Craiova: 120\n",
    "- Rimnicu Vilcea → Pitesti: 97\n",
    "- Craiova → Pitesti: 138\n",
    "- Craiova → Rimnicu Vilcea: 146\n",
    "- Pitesti → Bucharest: 101\n",
    "- Fagaras → Bucharest: 211\n",
    "\n",
    "1. Formulate the problem of finding a path from Arad to Bucharest in terms of:\n",
    "   - Initial state\n",
    "   - Actions\n",
    "   - Transition model\n",
    "   - Goal state\n",
    "   - Path cost function\n",
    "\n",
    "2. Using Uniform-Cost Search, calculate the path to Bucharest, showing intermediate steps and expanding nodes systematically.\n",
    "\n",
    "---\n",
    "\n",
    "### **Solution**\n",
    "\n",
    "#### Part 1: Problem Formulation\n",
    "\n",
    "- **Initial State**: The agent starts in the city of Arad.\n",
    "- **Actions**: The agent can travel to any city directly connected to its current city via a road.\n",
    "- **Transition Model**: A function RESULT(state, action) returns the new state after applying the action (traveling to a connected city).\n",
    "- **Goal State**: Reaching the city of Bucharest.\n",
    "- **Path Cost Function**: The total distance traveled, calculated as the sum of road distances along the path.\n",
    "\n",
    "---\n",
    "\n",
    "#### Part 2: Uniform-Cost Search\n",
    "\n",
    "1. **Initialization**: Start from Arad with a path cost of 0. The frontier is initialized with Arad, and the explored set is empty.\n",
    "\n",
    "2. **Step 1 (Expand Arad)**:\n",
    "   - Frontier: {Sibiu (140), Timisoara (118), Zerind (75)}\n",
    "   - Explored: {Arad}\n",
    "\n",
    "3. **Step 2 (Expand Zerind)**:\n",
    "   - Choose the lowest-cost node in the frontier (Zerind, 75).\n",
    "   - Add successors:\n",
    "     - Zerind → Oradea (75 + 71 = 146)\n",
    "   - Frontier: {Sibiu (140), Timisoara (118), Oradea (146)}\n",
    "   - Explored: {Arad, Zerind}\n",
    "\n",
    "4. **Step 3 (Expand Timisoara)**:\n",
    "   - Choose the lowest-cost node in the frontier (Timisoara, 118).\n",
    "   - Add successors:\n",
    "     - Timisoara → Lugoj (118 + 111 = 229)\n",
    "   - Frontier: {Sibiu (140), Oradea (146), Lugoj (229)}\n",
    "   - Explored: {Arad, Zerind, Timisoara}\n",
    "\n",
    "5. **Step 4 (Expand Sibiu)**:\n",
    "   - Choose the lowest-cost node in the frontier (Sibiu, 140).\n",
    "   - Add successors:\n",
    "     - Sibiu → Fagaras (140 + 99 = 239)\n",
    "     - Sibiu → Rimnicu Vilcea (140 + 80 = 220)\n",
    "   - Frontier: {Oradea (146), Rimnicu Vilcea (220), Fagaras (239), Lugoj (229)}\n",
    "   - Explored: {Arad, Zerind, Timisoara, Sibiu}\n",
    "\n",
    "6. **Step 5 (Expand Oradea)**:\n",
    "   - Choose the lowest-cost node in the frontier (Oradea, 146).\n",
    "   - Add successors:\n",
    "     - Oradea → Sibiu (146 + 151 = 297, already explored)\n",
    "   - Frontier: {Rimnicu Vilcea (220), Fagaras (239), Lugoj (229)}\n",
    "   - Explored: {Arad, Zerind, Timisoara, Sibiu, Oradea}\n",
    "\n",
    "7. **Step 6 (Expand Rimnicu Vilcea)**:\n",
    "   - Choose the lowest-cost node in the frontier (Rimnicu Vilcea, 220).\n",
    "   - Add successors:\n",
    "     - Rimnicu Vilcea → Pitesti (220 + 97 = 317)\n",
    "     - Rimnicu Vilcea → Craiova (220 + 146 = 366)\n",
    "   - Frontier: {Fagaras (239), Lugoj (229), Pitesti (317), Craiova (366)}\n",
    "   - Explored: {Arad, Zerind, Timisoara, Sibiu, Oradea, Rimnicu Vilcea}\n",
    "\n",
    "8. **Step 7 (Expand Lugoj)**:\n",
    "   - Choose the lowest-cost node in the frontier (Lugoj, 229).\n",
    "   - Add successors:\n",
    "     - Lugoj → Mehadia (229 + 70 = 299)\n",
    "   - Frontier: {Fagaras (239), Pitesti (317), Craiova (366), Mehadia (299)}\n",
    "   - Explored: {Arad, Zerind, Timisoara, Sibiu, Oradea, Rimnicu Vilcea, Lugoj}\n",
    "\n",
    "9. **Step 8 (Expand Fagaras)**:\n",
    "   - Choose the lowest-cost node in the frontier (Fagaras, 239).\n",
    "   - Add successors:\n",
    "     - Fagaras → Bucharest (239 + 211 = 450)\n",
    "   - Frontier: {Pitesti (317), Craiova (366), Mehadia (299), Bucharest (450)}\n",
    "   - Explored: {Arad, Zerind, Timisoara, Sibiu, Oradea, Rimnicu Vilcea, Lugoj, Fagaras}\n",
    "\n",
    "10. **Step 9 (Expand Pitesti)**:\n",
    "    - Choose the lowest-cost node in the frontier (Pitesti, 317).\n",
    "    - Add successors:\n",
    "      - Pitesti → Bucharest (317 + 101 = 418)\n",
    "    - Frontier: {Craiova (366), Mehadia (299), Bucharest (418, from Pitesti), Bucharest (450, from Fagaras)}\n",
    "    - Explored: {Arad, Zerind, Timisoara, Sibiu, Oradea, Rimnicu Vilcea, Lugoj, Fagaras, Pitesti}\n",
    "\n",
    "11. **Step 10 (Expand Bucharest)**:\n",
    "    - Choose the lowest-cost node in the frontier (Bucharest, 418).\n",
    "    - Goal reached with the path: Arad → Sibiu → Rimnicu Vilcea → Pitesti → Bucharest.\n",
    "\n",
    "---\n",
    "\n",
    "#### Final Answer\n",
    "\n",
    "- **Optimal Path**: Arad → Sibiu → Rimnicu Vilcea → Pitesti → Bucharest\n",
    "- **Path Cost**: 418\n",
    "\n",
    "This type of question tests the student's ability to define search problems and simulate search algorithms systematically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5071f3b2-59a5-451d-9c20-86fc6a3c4987",
   "metadata": {},
   "source": [
    "Sure! Here’s a worked example based on Section 3.2, \"Formulating Problems.\"\n",
    "\n",
    "---\n",
    "\n",
    "### **Exam Question**\n",
    "\n",
    "An autonomous robot is tasked with collecting garbage from three locations (A, B, C) and returning to its home base (H). The robot starts at the home base and can move between locations using direct paths with the following distances:\n",
    "\n",
    "- H → A: 4\n",
    "- H → B: 2\n",
    "- H → C: 6\n",
    "- A → B: 3\n",
    "- A → C: 5\n",
    "- B → C: 4\n",
    "\n",
    "The robot has the following constraints:\n",
    "1. It must visit each location exactly once to collect garbage.\n",
    "2. It must return to the home base after collecting all the garbage.\n",
    "\n",
    "1. **Formulate this problem as a search problem:**\n",
    "   - Define the state space.\n",
    "   - Describe the initial state, goal test, and actions.\n",
    "   - Define the path cost function.\n",
    "\n",
    "2. **Using a brute-force search method, calculate the total cost for all possible paths to determine the optimal path.**\n",
    "\n",
    "---\n",
    "\n",
    "### **Solution**\n",
    "\n",
    "#### Part 1: Problem Formulation\n",
    "\n",
    "- **State Space**:\n",
    "  Each state represents the robot's current location and the set of garbage collection locations it has already visited. For example:\n",
    "  - $ (H, \\emptyset) $: At the home base with no garbage collected.\n",
    "  - $ (A, \\{A\\}) $: At location A with garbage collected from A.\n",
    "  - $ (B, \\{A, B\\}) $: At location B with garbage collected from A and B.\n",
    "\n",
    "- **Initial State**:\n",
    "  $ (H, \\emptyset) $: The robot starts at home without having collected any garbage.\n",
    "\n",
    "- **Goal Test**:\n",
    "  The robot has visited all garbage locations ($\\{A, B, C\\}$) and returned to the home base ($H$).\n",
    "\n",
    "- **Actions**:\n",
    "  The robot can move between any two locations if the destination has not yet been visited or if returning to the home base. For example:\n",
    "  - From $H$, it can go to $A$, $B$, or $C$.\n",
    "  - From $A$, it can go to $B$, $C$, or $H$ if all garbage has been collected.\n",
    "\n",
    "- **Path Cost Function**:\n",
    "  The total distance traveled by the robot. The cost of an action $ ACTION(current, next) $ is the distance between the two locations.\n",
    "\n",
    "---\n",
    "\n",
    "#### Part 2: Brute-Force Search for Optimal Path\n",
    "\n",
    "To solve this problem, the robot must evaluate all possible permutations of visiting $A$, $B$, and $C$, returning to $H$. The total path cost is calculated for each permutation.\n",
    "\n",
    "**Paths to Evaluate**:\n",
    "1. $ H → A → B → C → H $\n",
    "2. $ H → A → C → B → H $\n",
    "3. $ H → B → A → C → H $\n",
    "4. $ H → B → C → A → H $\n",
    "5. $ H → C → A → B → H $\n",
    "6. $ H → C → B → A → H $\n",
    "\n",
    "**Path Cost Calculations**:\n",
    "1. $ H → A → B → C → H $:\n",
    "   - Cost = $ H → A (4) + A → B (3) + B → C (4) + C → H (6) = 17 $\n",
    "2. $ H → A → C → B → H $:\n",
    "   - Cost = $ H → A (4) + A → C (5) + C → B (4) + B → H (2) = 15 $\n",
    "3. $ H → B → A → C → H $:\n",
    "   - Cost = $ H → B (2) + B → A (3) + A → C (5) + C → H (6) = 16 $\n",
    "4. $ H → B → C → A → H $:\n",
    "   - Cost = $ H → B (2) + B → C (4) + C → A (5) + A → H (4) = 15 $\n",
    "5. $ H → C → A → B → H $:\n",
    "   - Cost = $ H → C (6) + C → A (5) + A → B (3) + B → H (2) = 16 $\n",
    "6. $ H → C → B → A → H $:\n",
    "   - Cost = $ H → C (6) + C → B (4) + B → A (3) + A → H (4) = 17 $\n",
    "\n",
    "**Optimal Path**:\n",
    "The paths $ H → A → C → B → H $ and $ H → B → C → A → H $ both have the minimum cost of **15**.\n",
    "\n",
    "---\n",
    "\n",
    "#### Final Answer\n",
    "\n",
    "- **State Space Representation**: $ (current\\_location, visited\\_locations) $\n",
    "- **Initial State**: $ (H, \\emptyset) $\n",
    "- **Goal Test**: $ (H, \\{A, B, C\\}) $\n",
    "- **Optimal Path**: $ H → A → C → B → H $ or $ H → B → C → A → H $\n",
    "- **Optimal Cost**: **15**\n",
    "\n",
    "---\n",
    "\n",
    "This question tests the student’s ability to model a problem using state-space representation and apply systematic search techniques to find optimal solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27e6660-72d6-4954-9b45-959bc582f578",
   "metadata": {},
   "source": [
    "Here’s a worked example based on Section 3.3, \"Searching for Solutions.\"\n",
    "\n",
    "---\n",
    "\n",
    "### **Exam Question**\n",
    "\n",
    "A robot is navigating a grid world represented as follows:\n",
    "\n",
    "- The grid is $5 \\times 5$, with cells labeled from $ (0,0) $ (top-left corner) to $ (4,4) $ (bottom-right corner).\n",
    "- The robot starts at $ (0,0) $ and must reach the goal at $ (4,4) $.\n",
    "- Obstacles are located at $ (1,1) $, $ (1,2) $, $ (2,2) $, and $ (3,3) $.\n",
    "- The robot can move up, down, left, or right, but not diagonally.\n",
    "\n",
    "1. **Formulate this problem as a state-space search problem:**\n",
    "   - Define the state space, initial state, goal state, actions, and transition model.\n",
    "2. Using Breadth-First Search (BFS), find the shortest path from the start to the goal.\n",
    "3. Show the expanded nodes and the path cost.\n",
    "\n",
    "---\n",
    "\n",
    "### **Solution**\n",
    "\n",
    "#### Part 1: Problem Formulation\n",
    "\n",
    "- **State Space**: The state is represented as the robot's current position on the grid, $ (x, y) $, where $ x $ and $ y $ are the row and column indices.\n",
    "- **Initial State**: $ (0,0) $.\n",
    "- **Goal State**: $ (4,4) $.\n",
    "- **Actions**:\n",
    "  - Move up: $ (x, y) → (x-1, y) $\n",
    "  - Move down: $ (x, y) → (x+1, y) $\n",
    "  - Move left: $ (x, y) → (x, y-1) $\n",
    "  - Move right: $ (x, y) → (x, y+1) $\n",
    "- **Transition Model**: The result of an action is the new position of the robot. Actions are only valid if the resulting position is within the grid and not an obstacle.\n",
    "- **Path Cost**: Each move has a uniform cost of 1.\n",
    "\n",
    "---\n",
    "\n",
    "#### Part 2: BFS Search for the Shortest Path\n",
    "\n",
    "1. **Initialization**:\n",
    "   - Start at $ (0,0) $.\n",
    "   - Frontier: $ [(0,0)] $.\n",
    "   - Explored: $ \\emptyset $.\n",
    "\n",
    "2. **Search Steps**:\n",
    "\n",
    "| Step | Current Node | Frontier                     | Explored                     | Successors Added          |\n",
    "|------|--------------|-----------------------------|-----------------------------|---------------------------|\n",
    "| 1    | $ (0,0) $   | $ [(0,1), (1,0)] $        | $ \\{(0,0)\\} $              | $ (0,1), (1,0) $         |\n",
    "| 2    | $ (0,1) $   | $ [(1,0), (0,2), (1,1)] $ | $ \\{(0,0), (0,1)\\} $       | $ (0,2) $ (valid move), skip $ (1,1) $ (obstacle) |\n",
    "| 3    | $ (1,0) $   | $ [(0,2), (2,0)] $        | $ \\{(0,0), (0,1), (1,0)\\} $| $ (2,0) $ (valid move)   |\n",
    "| 4    | $ (0,2) $   | $ [(2,0), (0,3), (1,2)] $ | $ \\{(0,0), (0,1), (1,0), (0,2)\\} $ | $ (0,3) $, skip $ (1,2) $ (obstacle) |\n",
    "| 5    | $ (2,0) $   | $ [(0,3), (3,0)] $        | $ \\{(0,0), (0,1), (1,0), (0,2), (2,0)\\} $ | $ (3,0) $ (valid move) |\n",
    "| 6    | $ (0,3) $   | $ [(3,0), (0,4), (1,3)] $ | $ \\{(0,0), (0,1), (1,0), (0,2), (2,0), (0,3)\\} $ | $ (0,4), (1,3) $ |\n",
    "| 7    | $ (3,0) $   | $ [(0,4), (1,3), (4,0)] $ | $ \\{(0,0), (0,1), (1,0), (0,2), (2,0), (0,3), (3,0)\\} $ | $ (4,0) $ |\n",
    "| 8    | $ (0,4) $   | $ [(1,3), (4,0), (1,4)] $ | $ \\{(0,0), (0,1), (1,0), (0,2), (2,0), (0,3), (3,0), (0,4)\\} $ | $ (1,4) $ |\n",
    "| 9    | $ (4,0) $   | $ [(1,3), (1,4), (4,1)] $ | $ \\{(0,0), (0,1), (1,0), (0,2), (2,0), (0,3), (3,0), (0,4), (4,0)\\} $ | $ (4,1) $ |\n",
    "| 10   | $ (4,1) $   | $ [(1,3), (1,4), (4,2)] $ | $ \\{(0,0), ..., (4,1)\\} $  | $ (4,2) $ |\n",
    "| 11   | $ (4,2) $   | $ [(1,3), (1,4), (4,3)] $ | $ \\{(0,0), ..., (4,2)\\} $  | $ (4,3) $ |\n",
    "| 12   | $ (4,3) $   | $ [(1,3), (1,4), (4,4)] $ | $ \\{(0,0), ..., (4,3)\\} $  | $ (4,4) $ |\n",
    "| 13   | $ (4,4) $   | Goal Reached               |                             |                           |\n",
    "\n",
    "---\n",
    "\n",
    "#### Part 3: Solution\n",
    "\n",
    "- **Path**: $ (0,0) → (1,0) → (2,0) → (3,0) → (4,0) → (4,1) → (4,2) → (4,3) → (4,4) $\n",
    "- **Path Cost**: $ 8 $ (each step costs 1).\n",
    "- **Expanded Nodes**: $ (0,0), (0,1), (1,0), (0,2), (2,0), (0,3), (3,0), (0,4), (4,0), (4,1), (4,2), (4,3), (4,4) $.\n",
    "\n",
    "---\n",
    "\n",
    "### Notes\n",
    "\n",
    "This question tests the student’s ability to:\n",
    "1. Formulate a search problem in terms of states, actions, and transitions.\n",
    "2. Apply BFS systematically.\n",
    "3. Track the frontier, explored set, and goal achievement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c5a8e0-04d5-4054-b845-e76d536b927e",
   "metadata": {},
   "source": [
    "Here’s a worked example based on Section 3.3, which deals with search tree exploration and strategies.\n",
    "\n",
    "---\n",
    "\n",
    "### **Exam Question**\n",
    "\n",
    "A delivery robot needs to deliver packages from a warehouse (W) to two delivery points (A and B) in a small town. The robot must start at the warehouse, visit both delivery points in any order, and return to the warehouse. The travel times (in minutes) between locations are as follows:\n",
    "\n",
    "- $ W \\to A = 3 $\n",
    "- $ W \\to B = 4 $\n",
    "- $ A \\to B = 2 $\n",
    "- $ A \\to W = 3 $\n",
    "- $ B \\to W = 4 $\n",
    "- $ B \\to A = 2 $\n",
    "\n",
    "1. **Formulate this as a search problem**:\n",
    "   - Define the state space, initial state, goal test, actions, and path cost function.\n",
    "\n",
    "2. **Using Depth-First Search (DFS)**, find a path to satisfy the goal. Assume that DFS explores nodes in alphabetical order when branching (e.g., $ A $ before $ B $).\n",
    "\n",
    "3. **Is this path optimal? If not, briefly explain why.**\n",
    "\n",
    "---\n",
    "\n",
    "### **Solution**\n",
    "\n",
    "#### Part 1: Problem Formulation\n",
    "\n",
    "- **State Space**:\n",
    "  A state is represented as $ (location, visited) $, where:\n",
    "  - $ location $: The current location of the robot.\n",
    "  - $ visited $: A set of locations the robot has already visited.\n",
    "  For example, $ (A, \\{W, A\\}) $ means the robot is at $ A $ and has visited $ W $ and $ A $.\n",
    "\n",
    "- **Initial State**:\n",
    "  $ (W, \\{W\\}) $: The robot starts at the warehouse with only the warehouse visited.\n",
    "\n",
    "- **Goal Test**:\n",
    "  The robot has visited $ A $, $ B $, and $ W $ at least once, and the current location is $ W $.\n",
    "\n",
    "- **Actions**:\n",
    "  - The robot can move between locations $ W $, $ A $, and $ B $ if the move does not violate the problem constraints.\n",
    "\n",
    "- **Path Cost Function**:\n",
    "  The total travel time. Each action adds the corresponding travel time to the total.\n",
    "\n",
    "---\n",
    "\n",
    "#### Part 2: DFS Search\n",
    "\n",
    "1. **Initialization**:\n",
    "   - Start at $ W $: $ (W, \\{W\\}) $.\n",
    "   - Frontier: $ [ (W, \\{W\\}) ] $.\n",
    "   - Explored: $ \\emptyset $.\n",
    "\n",
    "2. **Step-by-Step Execution**:\n",
    "\n",
    "| **Step** | **Current State** | **Frontier**                                   | **Explored**             | **Notes**                                                                                     |\n",
    "|----------|--------------------|-----------------------------------------------|--------------------------|-----------------------------------------------------------------------------------------------|\n",
    "| 1        | $ (W, \\{W\\}) $   | $ [(A, \\{W, A\\}), (B, \\{W, B\\})] $          | $ \\{(W, \\{W\\})\\} $     | Expand $ W $; add successors $ A $ and $ B $.                                            |\n",
    "| 2        | $ (A, \\{W, A\\}) $ | $ [(B, \\{W, B\\}), (B, \\{W, A, B\\}), (W, \\{W, A\\})] $ | $ \\{(W, \\{W\\}), (A, \\{W, A\\})\\} $ | Expand $ A $; add successors $ B $, $ W $.                                              |\n",
    "| 3        | $ (B, \\{W, A, B\\}) $ | $ [(B, \\{W, B\\}), (W, \\{W, A\\}), (W, \\{W, A, B\\})] $ | $ \\{(W, \\{W\\}), (A, \\{W, A\\}), (B, \\{W, A, B\\})\\} $ | Expand $ B $; add successor $ W $ (goal state).                                            |\n",
    "| 4        | $ (W, \\{W, A, B\\}) $ | $ [(B, \\{W, B\\}), (W, \\{W, A\\})] $        | $ \\{(W, \\{W\\}), (A, \\{W, A\\}), (B, \\{W, A, B\\}), (W, \\{W, A, B\\})\\} $ | Goal state reached.                                                                           |\n",
    "\n",
    "- **Path**:\n",
    "  $ W → A → B → W $.\n",
    "\n",
    "- **Path Cost**:\n",
    "  $ W → A (3) + A → B (2) + B → W (4) = 9 $.\n",
    "\n",
    "---\n",
    "\n",
    "#### Part 3: Optimality Check\n",
    "\n",
    "- The path found by DFS is $ W → A → B → W $ with a cost of 9.\n",
    "- The optimal path is $ W → B → A → W $, which has a cost of $ W → B (4) + B → A (2) + A → W (3) = 9 $. \n",
    "- In this case, both paths have the same cost due to uniform edge weights, so the path found by DFS happens to be optimal.\n",
    "\n",
    "---\n",
    "\n",
    "### Final Answer:\n",
    "\n",
    "1. **Formulation**:\n",
    "   - State Space: $ (location, visited) $\n",
    "   - Initial State: $ (W, \\{W\\}) $\n",
    "   - Goal Test: $ (W, \\{W, A, B\\}) $\n",
    "   - Path Cost Function: Total travel time.\n",
    "\n",
    "2. **DFS Path**: $ W → A → B → W $\n",
    "3. **Path Cost**: 9\n",
    "4. **Is the path optimal?** Yes, because it has the same cost as the actual optimal path $ W → B → A → W $.\n",
    "\n",
    "---\n",
    "\n",
    "This type of question tests:\n",
    "1. Problem formulation skills.\n",
    "2. The ability to simulate search algorithms systematically.\n",
    "3. Understanding of optimality in the context of search strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd19758-3dc7-472f-bb0f-82457f584521",
   "metadata": {},
   "source": [
    "# Here’s a worked example based on Section 3.4, \"Uninformed Search Strategies.\"\n",
    "\n",
    "---\n",
    "\n",
    "### **Exam Question**\n",
    "\n",
    "A farmer needs to transport a wolf, a goat, and a cabbage across a river. The boat can only carry the farmer and one other item (wolf, goat, or cabbage) at a time. The farmer cannot leave the wolf alone with the goat or the goat alone with the cabbage on either side of the river.\n",
    "\n",
    "1. **Formulate this problem as a search problem:**\n",
    "   - Define the state space, initial state, goal state, actions, and path cost function.\n",
    "2. Solve the problem using Breadth-First Search (BFS), showing intermediate steps and expanded nodes.\n",
    "3. Determine whether the solution is optimal and explain why.\n",
    "\n",
    "---\n",
    "\n",
    "### **Solution**\n",
    "\n",
    "#### Part 1: Problem Formulation\n",
    "\n",
    "- **State Space**:\n",
    "  Each state is represented as $ (L, R) $, where:\n",
    "  - $ L $: Items (farmer, wolf, goat, cabbage) on the left bank.\n",
    "  - $ R $: Items on the right bank.\n",
    "  For example, $ ( \\{farmer, wolf, goat, cabbage\\}, \\emptyset ) $ represents all items on the left bank.\n",
    "\n",
    "- **Initial State**:\n",
    "  $ ( \\{farmer, wolf, goat, cabbage\\}, \\emptyset ) $: All items start on the left bank.\n",
    "\n",
    "- **Goal State**:\n",
    "  $ (\\emptyset, \\{farmer, wolf, goat, cabbage\\}) $: All items are on the right bank.\n",
    "\n",
    "- **Actions**:\n",
    "  The farmer can:\n",
    "  1. Take the wolf, goat, or cabbage across the river.\n",
    "  2. Return to the left bank alone if necessary.\n",
    "  Transitions must satisfy the constraint that the wolf cannot be left with the goat and the goat cannot be left with the cabbage.\n",
    "\n",
    "- **Path Cost**:\n",
    "  Each crossing (either way) has a uniform cost of 1.\n",
    "\n",
    "---\n",
    "\n",
    "#### Part 2: BFS Solution\n",
    "\n",
    "**Step 1: Initialization**\n",
    "\n",
    "- Start at $ ( \\{farmer, wolf, goat, cabbage\\}, \\emptyset ) $.\n",
    "- Frontier: $ [( \\{farmer, wolf, goat, cabbage\\}, \\emptyset )] $.\n",
    "- Explored: $ \\emptyset $.\n",
    "\n",
    "---\n",
    "\n",
    "**Step-by-Step Execution**\n",
    "\n",
    "| **Step** | **Current State**                              | **Frontier**                                                                                     | **Explored**                                               | **Notes**                                                                                      |\n",
    "|----------|-----------------------------------------------|-------------------------------------------------------------------------------------------------|-----------------------------------------------------------|------------------------------------------------------------------------------------------------|\n",
    "| 1        | $ (\\{farmer, wolf, goat, cabbage\\}, \\emptyset) $ | $ [(\\{wolf, goat, cabbage\\}, \\{farmer\\})] $                                                   | $ \\{(\\{farmer, wolf, goat, cabbage\\}, \\emptyset)\\} $     | Farmer takes wolf, goat, or cabbage across (only valid action: goat).                         |\n",
    "| 2        | $ (\\{wolf, cabbage\\}, \\{farmer, goat\\}) $    | $ [(\\{wolf, goat, cabbage\\}, \\{farmer\\}), (\\{goat, cabbage\\}, \\{farmer, wolf\\})] $            | $ \\{(\\{farmer, wolf, goat, cabbage\\}, \\emptyset)\\} $     | Farmer takes goat back to the left bank.                                                      |\n",
    "| 3        | $ (\\{goat, cabbage\\}, \\{farmer, wolf\\}) $    | $ [(\\{wolf, goat, cabbage\\}, \\{farmer\\}), (\\{cabbage\\}, \\{farmer, wolf, goat\\})] $            | $ \\{(\\{farmer, wolf, goat, cabbage\\}, \\emptyset)\\} $     | Farmer takes wolf safely!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc82ca9-8c38-4a79-8d42-fcffaaff5114",
   "metadata": {},
   "source": [
    "# Here’s a worked example based on Section 3.6, \"Heuristic Functions.\"\n",
    "\n",
    "---\n",
    "\n",
    "### **Exam Question**\n",
    "\n",
    "The 8-puzzle problem consists of a $3 \\times 3$ grid with 8 numbered tiles and one blank space. The goal is to arrange the tiles in numerical order, with the blank in the bottom-right corner. A sample start state is:\n",
    "\n",
    "```\n",
    "1 2 3\n",
    "4 8 5\n",
    "7   6\n",
    "```\n",
    "\n",
    "and the goal state is:\n",
    "\n",
    "```\n",
    "1 2 3\n",
    "4 5 6\n",
    "7 8\n",
    "```\n",
    "\n",
    "1. **Define and compute the following heuristic functions for the given start state**:\n",
    "   - $h_1$: The number of misplaced tiles.\n",
    "   - $h_2$: The Manhattan distance (sum of horizontal and vertical distances of each tile from its goal position).\n",
    "2. Explain why $h_2$ dominates $h_1$.\n",
    "3. If the actual cost of the optimal solution for this problem is 10, verify whether $h_1$ and $h_2$ are admissible heuristics.\n",
    "\n",
    "---\n",
    "\n",
    "### **Solution**\n",
    "\n",
    "#### Part 1: Computing Heuristic Functions\n",
    "\n",
    "- **Start State**:\n",
    "  ```\n",
    "  1 2 3\n",
    "  4 8 5\n",
    "  7   6\n",
    "  ```\n",
    "\n",
    "- **Goal State**:\n",
    "  ```\n",
    "  1 2 3\n",
    "  4 5 6\n",
    "  7 8\n",
    "  ```\n",
    "\n",
    "1. **$h_1$: Number of Misplaced Tiles**\n",
    "\n",
    "   Count the number of tiles that are not in their goal positions (excluding the blank):\n",
    "\n",
    "   - Tile 8: Misplaced (should be in bottom-middle).\n",
    "   - Tile 5: Misplaced (should be in middle-middle).\n",
    "   - Tile 6: Misplaced (should be in bottom-right).\n",
    "\n",
    "   $ h_1 = 3 $\n",
    "\n",
    "2. **$h_2$: Manhattan Distance**\n",
    "\n",
    "   Compute the sum of the Manhattan distances for all tiles (excluding the blank):\n",
    "\n",
    "   - Tile 1: Already in its goal position. Distance = 0.\n",
    "   - Tile 2: Already in its goal position. Distance = 0.\n",
    "   - Tile 3: Already in its goal position. Distance = 0.\n",
    "   - Tile 4: Already in its goal position. Distance = 0.\n",
    "   - Tile 5: Current position = (1,2). Goal position = (1,1). Distance = 1.\n",
    "   - Tile 6: Current position = (2,2). Goal position = (1,2). Distance = 1.\n",
    "   - Tile 7: Already in its goal position. Distance = 0.\n",
    "   - Tile 8: Current position = (1,1). Goal position = (2,1). Distance = 1.\n",
    "\n",
    "   $ h_2 = 1 + 1 + 1 = 3 $\n",
    "\n",
    "---\n",
    "\n",
    "#### Part 2: Why $h_2$ Dominates $h_1$\n",
    "\n",
    "- **Definition of Dominance**: A heuristic $h_2$ dominates $h_1$ if $h_2(n) \\geq h_1(n)$ for all nodes $n$, and there exists at least one node $n$ for which $h_2(n) > h_1(n)$.\n",
    "\n",
    "- For the given start state:\n",
    "  - $h_1 = 3$\n",
    "  - $h_2 =3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786a0f06-2022-4c18-bc9d-d86250fd5027",
   "metadata": {},
   "source": [
    "---\n",
    "# ch 6\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341a5156-eb8d-4475-b91a-b2497ebc7ccb",
   "metadata": {},
   "source": [
    "### Worked Example: Map Coloring Problem\n",
    "\n",
    "#### Question\n",
    "You are tasked with solving a **map-coloring problem** as a **Constraint Satisfaction Problem (CSP)**. The map contains the following regions: \n",
    "\n",
    "- $ X = \\{\\text{A, B, C, D, E}\\} $\n",
    "- The regions are connected as follows:\n",
    "  - $ \\text{A} $ is adjacent to $ \\text{B}, \\text{C}, \\text{D} $.\n",
    "  - $ \\text{B} $ is adjacent to $ \\text{A}, \\text{D} $.\n",
    "  - $ \\text{C} $ is adjacent to $ \\text{A}, \\text{E} $.\n",
    "  - $ \\text{D} $ is adjacent to $ \\text{A}, \\text{B}, \\text{E} $.\n",
    "  - $ \\text{E} $ is adjacent to $ \\text{C}, \\text{D} $.\n",
    "\n",
    "The problem is to color each region using colors $ \\{ \\text{Red, Green, Blue} \\} $ such that no two adjacent regions share the same color.\n",
    "\n",
    "1. Formulate this problem as a CSP (specify variables, domains, and constraints).\n",
    "2. Solve the CSP using the backtracking search algorithm, showing your steps.\n",
    "\n",
    "---\n",
    "\n",
    "#### Solution\n",
    "\n",
    "### Step 1: CSP Formulation\n",
    "\n",
    "1. **Variables**:\n",
    "   $ X = \\{\\text{A, B, C, D, E}\\} $, one variable for each region.\n",
    "\n",
    "2. **Domains**:\n",
    "   $ D(X_i) = \\{ \\text{Red, Green, Blue} \\} \\, \\forall X_i \\in X $.\n",
    "\n",
    "3. **Constraints**:\n",
    "   Adjacent regions must have different colors:\n",
    "   - $ \\text{A} \\neq \\text{B} $\n",
    "   - $ \\text{A} \\neq \\text{C} $\n",
    "   - $ \\text{A} \\neq \\text{D} $\n",
    "   - $ \\text{B} \\neq \\text{D} $\n",
    "   - $ \\text{C} \\neq \\text{E} $\n",
    "   - $ \\text{D} \\neq \\text{E} $\n",
    "\n",
    "   These constraints are binary constraints between adjacent variables.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 2: Solve the Problem\n",
    "\n",
    "We will solve the CSP using **Backtracking Search** with the following heuristics:\n",
    "- **Minimum Remaining Values (MRV)**: Pick the variable with the smallest domain.\n",
    "- **Forward Checking**: Reduce domains of neighboring variables after each assignment.\n",
    "\n",
    "#### Initial State\n",
    "- Assignment: $ \\emptyset $\n",
    "- Domains:\n",
    "  - $ D(\\text{A}) = \\{\\text{Red, Green, Blue}\\} $\n",
    "  - $ D(\\text{B}) = \\{\\text{Red, Green, Blue}\\} $\n",
    "  - $ D(\\text{C}) = \\{\\text{Red, Green, Blue}\\} $\n",
    "  - $ D(\\text{D}) = \\{\\text{Red, Green, Blue}\\} $\n",
    "  - $ D(\\text{E}) = \\{\\text{Red, Green, Blue}\\} $\n",
    "\n",
    "#### Step 1: Assign $ \\text{A} = \\text{Red} $\n",
    "- Assignment: $ \\{\\text{A} = \\text{Red}\\} $\n",
    "- Forward Checking:\n",
    "  - Remove $ \\text{Red} $ from the domains of $ \\text{B}, \\text{C}, \\text{D} $ (neighbors of $ \\text{A} $).\n",
    "- Updated Domains:\n",
    "  - $ D(\\text{B}) = \\{\\text{Green, Blue}\\} $\n",
    "  - $ D(\\text{C}) = \\{\\text{Green, Blue}\\} $\n",
    "  - $ D(\\text{D}) = \\{\\text{Green, Blue}\\} $\n",
    "  - $ D(\\text{E}) = \\{\\text{Red, Green, Blue}\\} $\n",
    "\n",
    "#### Step 2: Assign $ \\text{B} = \\text{Green} $\n",
    "- Assignment: $ \\{\\text{A} = \\text{Red}, \\text{B} = \\text{Green}\\} $\n",
    "- Forward Checking:\n",
    "  - Remove $ \\text{Green} $ from the domain of $ \\text{D} $ (neighbor of $ \\text{B} $).\n",
    "- Updated Domains:\n",
    "  - $ D(\\text{C}) = \\{\\text{Green, Blue}\\} $\n",
    "  - $ D(\\text{D}) = \\{\\text{Blue}\\} $\n",
    "  - $ D(\\text{E}) = \\{\\text{Red, Green, Blue}\\} $\n",
    "\n",
    "#### Step 3: Assign $ \\text{C} = \\text{Blue} $\n",
    "- Assignment: $ \\{\\text{A} = \\text{Red}, \\text{B} = \\text{Green}, \\text{C} = \\text{Blue}\\} $\n",
    "- Forward Checking:\n",
    "  - Remove $ \\text{Blue} $ from the domain of $ \\text{E} $ (neighbor of $ \\text{C} $).\n",
    "- Updated Domains:\n",
    "  - $ D(\\text{D}) = \\{\\text{Blue}\\} $\n",
    "  - $ D(\\text{E}) = \\{\\text{Red, Green}\\} $\n",
    "\n",
    "#### Step 4: Assign $ \\text{D} = \\text{Blue} $\n",
    "- Assignment: $ \\{\\text{A} = \\text{Red}, \\text{B} = \\text{Green}, \\text{C} = \\text{Blue}, \\text{D} = \\text{Blue}\\} $\n",
    "- Forward Checking:\n",
    "  - Remove $ \\text{Blue} $ from the domain of $ \\text{E} $ (neighbor of $ \\text{D} $).\n",
    "- Updated Domains:\n",
    "  - $ D(\\text{E}) = \\{\\text{Red, Green}\\} $\n",
    "\n",
    "#### Step 5: Assign $ \\text{E} = \\text{Green} $\n",
    "- Assignment: $ \\{\\text{A} = \\text{Red}, \\text{B} = \\text{Green}, \\text{C} = \\text{Blue}, \\text{D} = \\text{Blue}, \\text{E} = \\text{Green}\\} $\n",
    "\n",
    "---\n",
    "\n",
    "### Final Solution\n",
    "The solution to the CSP is:\n",
    "\\[\n",
    "\\{\\text{A} = \\text{Red}, \\text{B} = \\text{Green}, \\text{C} = \\text{Blue}, \\text{D} = \\text{Blue}, \\text{E} = \\text{Green}\\}\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "### Key Techniques Used:\n",
    "1. **MRV**: Always chose the most constrained variable first.\n",
    "2. **Forward Checking**: Pruned domains after each assignment.\n",
    "3. **Backtracking**: Did not require backtracking as forward checking avoided conflicts.\n",
    "\n",
    "This example illustrates how to solve a CSP step-by-step, which is a typical exam-style question. Let me know if you'd like further clarification!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7319d4-f832-4012-9938-bb1785ed941d",
   "metadata": {},
   "source": [
    "### Worked Example: Arc Consistency with AC-3 Algorithm\n",
    "\n",
    "#### Question\n",
    "Consider the following CSP:\n",
    "\n",
    "1. **Variables**: $ X = \\{X_1, X_2, X_3\\} $\n",
    "2. **Domains**:\n",
    "   - $ D(X_1) = \\{1, 2, 3\\} $\n",
    "   - $ D(X_2) = \\{1, 3\\} $\n",
    "   - $ D(X_3) = \\{2, 3\\} $\n",
    "3. **Constraints**:\n",
    "   - $ X_1 \\neq X_2 $\n",
    "   - $ X_2 \\neq X_3 $\n",
    "   - $ X_1 \\neq X_3 $\n",
    "\n",
    "Perform arc consistency using the **AC-3 algorithm** and determine if the CSP is arc-consistent. Show all steps.\n",
    "\n",
    "---\n",
    "\n",
    "#### Solution\n",
    "\n",
    "### Step 1: Initialization\n",
    "The CSP is represented as a graph where:\n",
    "- Nodes are the variables $ X_1, X_2, X_3 $.\n",
    "- Edges represent the binary constraints $ X_1 \\neq X_2 $, $ X_2 \\neq X_3 $, and $ X_1 \\neq X_3 $.\n",
    "\n",
    "The queue of arcs is initialized with all directed pairs of variables:\n",
    "$$\n",
    "\\text{Queue} = \\{(X_1, X_2), (X_2, X_1), (X_2, X_3), (X_3, X_2), (X_1, X_3), (X_3, X_1)\\}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Step 2: AC-3 Algorithm\n",
    "We process each arc in the queue and revise the domains of the variables if necessary. If a domain is revised, the affected arcs are re-added to the queue.\n",
    "\n",
    "---\n",
    "\n",
    "#### Iteration 1: Process $ (X_1, X_2) $\n",
    "- Constraint: $ X_1 \\neq X_2 $.\n",
    "- $ D(X_1) = \\{1, 2, 3\\} $, $ D(X_2) = \\{1, 3\\} $.\n",
    "- Check if every value in $ D(X_1) $ has a corresponding value in $ D(X_2) $ that satisfies $ X_1 \\neq X_2 $:\n",
    "  - $ 1 \\in D(X_1) $: Satisfied by $ 3 \\in D(X_2) $.\n",
    "  - $ 2 \\in D(X_1) $: Satisfied by $ 1, 3 \\in D(X_2) $.\n",
    "  - $ 3 \\in D(X_1) $: Satisfied by $ 1 \\in D(X_2) $.\n",
    "- No revisions needed. Domains remain the same:\n",
    "  - $ D(X_1) = \\{1, 2, 3\\} $, $ D(X_2) = \\{1, 3\\} $.\n",
    "- **Queue**: $ \\{(X_2, X_1), (X_2, X_3), (X_3, X_2), (X_1, X_3), (X_3, X_1)\\} $.\n",
    "\n",
    "---\n",
    "\n",
    "#### Iteration 2: Process $ (X_2, X_1) $\n",
    "- Constraint: $ X_2 \\neq X_1 $.\n",
    "- $ D(X_2) = \\{1, 3\\} $, $ D(X_1) = \\{1, 2, 3\\} $.\n",
    "- Check if every value in $ D(X_2) $ has a corresponding value in $ D(X_1) $:\n",
    "  - $ 1 \\in D(X_2) $: Satisfied by $ 2, 3 \\in D(X_1) $.\n",
    "  - $ 3 \\in D(X_2) $: Satisfied by $ 1, 2 \\in D(X_1) $.\n",
    "- No revisions needed. Domains remain the same.\n",
    "- **Queue**: $ \\{(X_2, X_3), (X_3, X_2), (X_1, X_3), (X_3, X_1)\\} $.\n",
    "\n",
    "---\n",
    "\n",
    "#### Iteration 3: Process $ (X_2, X_3) $\n",
    "- Constraint: $ X_2 \\neq X_3 $.\n",
    "- $ D(X_2) = \\{1, 3\\} $, $ D(X_3) = \\{2, 3\\} $.\n",
    "- Check if every value in $ D(X_2) $ has a corresponding value in $ D(X_3) $:\n",
    "  - $ 1 \\in D(X_2) $: Satisfied by $ 2, 3 \\in D(X_3) $.\n",
    "  - $ 3 \\in D(X_2) $: Satisfied by $ 2 \\in D(X_3) $.\n",
    "- No revisions needed. Domains remain the same.\n",
    "- **Queue**: $ \\{(X_3, X_2), (X_1, X_3), (X_3, X_1)\\} $.\n",
    "\n",
    "---\n",
    "\n",
    "#### Iteration 4: Process $ (X_3, X_2) $\n",
    "- Constraint: $ X_3 \\neq X_2 $.\n",
    "- $ D(X_3) = \\{2, 3\\} $, $ D(X_2) = \\{1, 3\\} $.\n",
    "- Check if every value in $ D(X_3) $ has a corresponding value in $ D(X_2) $:\n",
    "  - $ 2 \\in D(X_3) $: Satisfied by $ 1, 3 \\in D(X_2) $.\n",
    "  - $ 3 \\in D(X_3) $: Satisfied by $ 1 \\in D(X_2) $.\n",
    "- No revisions needed. Domains remain the same.\n",
    "- **Queue**: $ \\{(X_1, X_3), (X_3, X_1)\\} $.\n",
    "\n",
    "---\n",
    "\n",
    "#### Iteration 5: Process $ (X_1, X_3) $\n",
    "- Constraint: $ X_1 \\neq X_3 $.\n",
    "- $ D(X_1) = \\{1, 2, 3\\} $, $ D(X_3) = \\{2, 3\\} $.\n",
    "- Check if every value in $ D(X_1) $ has a corresponding value in $ D(X_3) $:\n",
    "  - $ 1 \\in D(X_1) $: Satisfied by $ 2, 3 \\in D(X_3) $.\n",
    "  - $ 2 \\in D(X_1) $: Satisfied by $ 3 \\in D(X_3) $.\n",
    "  - $ 3 \\in D(X_1) $: Satisfied by $ 2 \\in D(X_3) $.\n",
    "- No revisions needed. Domains remain the same.\n",
    "- **Queue**: $ \\{(X_3, X_1)\\} $.\n",
    "\n",
    "---\n",
    "\n",
    "#### Iteration 6: Process $ (X_3, X_1) $\n",
    "- Constraint: $ X_3 \\neq X_1 $.\n",
    "- $ D(X_3) = \\{2, 3\\} $, $ D(X_1) = \\{1, 2, 3\\} $.\n",
    "- Check if every value in $ D(X_3) $ has a corresponding value in $ D(X_1) $:\n",
    "  - $ 2 \\in D(X_3) $: Satisfied by $ 1, 3 \\in D(X_1) $.\n",
    "  - $ 3 \\in D(X_3) $: Satisfied by $ 1, 2 \\in D(X_1) $.\n",
    "- No revisions needed. Domains remain the same.\n",
    "- **Queue**: $ \\emptyset $.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 3: Conclusion\n",
    "The CSP is **arc-consistent** since no further revisions are needed, and all domains remain non-empty:\n",
    "- $ D(X_1) = \\{1, 2, 3\\} $\n",
    "- $ D(X_2) = \\{1, 3\\} $\n",
    "- $ D(X_3) = \\{2, 3\\} $\n",
    "\n",
    "---\n",
    "\n",
    "### Key Insights\n",
    "- **AC-3 Algorithm** systematically enforces arc consistency by revising domains iteratively.\n",
    "- This ensures that every value in a variable’s domain is consistent with at least one value in its neighbor’s domain.\n",
    "- The CSP is solvable because no domain is empty.\n",
    "\n",
    "Let me know if you'd like further clarification!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0069294-4dd1-4231-8ff5-458be7bbd6e8",
   "metadata": {},
   "source": [
    "### Worked Example: Backtracking Search for a CSP\n",
    "\n",
    "---\n",
    "\n",
    "#### Question\n",
    "You are tasked with solving a CSP for scheduling three tasks, $ T_1, T_2, $ and $ T_3 $, where:\n",
    "1. $ X = \\{T_1, T_2, T_3\\} $, the variables represent tasks.\n",
    "2. $ D(T_i) = \\{1, 2, 3\\} $, the domain for each task is the time slot in which it can be scheduled.\n",
    "3. **Constraints**:\n",
    "   - $ T_1 \\neq T_2 $ (Tasks 1 and 2 cannot be scheduled in the same time slot).\n",
    "   - $ T_2 \\neq T_3 $ (Tasks 2 and 3 cannot be scheduled in the same time slot).\n",
    "   - $ T_1 \\neq T_3 $ (Tasks 1 and 3 cannot be scheduled in the same time slot).\n",
    "\n",
    "Use **backtracking search** to find a solution for the CSP. Show your steps, including the use of the **Minimum Remaining Values (MRV)** heuristic and **forward checking**.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 1: Problem Setup\n",
    "- **Variables**: $ X = \\{T_1, T_2, T_3\\} $\n",
    "- **Domains**: $ D(T_1) = D(T_2) = D(T_3) = \\{1, 2, 3\\} $\n",
    "- **Constraints**:\n",
    "  - $ T_1 \\neq T_2 $\n",
    "  - $ T_2 \\neq T_3 $\n",
    "  - $ T_1 \\neq T_3 $\n",
    "\n",
    "We will use **backtracking search** with **MRV** and **forward checking** to solve this.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 2: Solve Using Backtracking\n",
    "\n",
    "#### Initial State\n",
    "- Assignment: $ \\{\\} $ (empty, no variables assigned yet).\n",
    "- Domains:\n",
    "  - $ D(T_1) = \\{1, 2, 3\\} $\n",
    "  - $ D(T_2) = \\{1, 2, 3\\} $\n",
    "  - $ D(T_3) = \\{1, 2, 3\\} $\n",
    "\n",
    "---\n",
    "\n",
    "#### Step 1: Assign $ T_1 = 1 $\n",
    "Using MRV, we select $ T_1 $ (all variables have equal domain sizes, so we choose arbitrarily).\n",
    "- Assignment: $ \\{T_1 = 1\\} $.\n",
    "- Forward Checking:\n",
    "  - Remove $ 1 $ from $ D(T_2) $ and $ D(T_3) $ due to the constraints $ T_1 \\neq T_2 $ and $ T_1 \\neq T_3 $.\n",
    "- Updated Domains:\n",
    "  - $ D(T_1) = \\{1\\} $ (assigned).\n",
    "  - $ D(T_2) = \\{2, 3\\} $\n",
    "  - $ D(T_3) = \\{2, 3\\} $\n",
    "\n",
    "---\n",
    "\n",
    "#### Step 2: Assign $ T_2 = 2 $\n",
    "Using MRV, we select $ T_2 $ (smallest domain size among unassigned variables).\n",
    "- Assignment: $ \\{T_1 = 1, T_2 = 2\\} $.\n",
    "- Forward Checking:\n",
    "  - Remove $ 2 $ from $ D(T_3) $ due to the constraint $ T_2 \\neq T_3 $.\n",
    "- Updated Domains:\n",
    "  - $ D(T_1) = \\{1\\} $ (assigned).\n",
    "  - $ D(T_2) = \\{2\\} $ (assigned).\n",
    "  - $ D(T_3) = \\{3\\} $\n",
    "\n",
    "---\n",
    "\n",
    "#### Step 3: Assign $ T_3 = 3 $\n",
    "Using MRV, we select $ T_3 $ (only remaining unassigned variable).\n",
    "- Assignment: $ \\{T_1 = 1, T_2 = 2, T_3 = 3\\} $.\n",
    "- Forward Checking:\n",
    "  - No neighbors left to update.\n",
    "- Updated Domains:\n",
    "  - $ D(T_1) = \\{1\\} $ (assigned).\n",
    "  - $ D(T_2) = \\{2\\} $ (assigned).\n",
    "  - $ D(T_3) = \\{3\\} $\n",
    "\n",
    "---\n",
    "\n",
    "### Step 3: Verify Solution\n",
    "All constraints are satisfied:\n",
    "- $ T_1 \\neq T_2 $: $ 1 \\neq 2 $ ✓\n",
    "- $ T_2 \\neq T_3 $: $ 2 \\neq 3 $ ✓\n",
    "- $ T_1 \\neq T_3 $: $ 1 \\neq 3 $ ✓\n",
    "\n",
    "Final Solution:\n",
    "$$\n",
    "\\{T_1 = 1, T_2 = 2, T_3 = 3\\}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Key Techniques Used\n",
    "1. **Backtracking Search**: Incrementally assigned values and backtracked only if constraints were violated (no backtracking needed here).\n",
    "2. **MRV Heuristic**: Always selected the variable with the smallest domain size first.\n",
    "3. **Forward Checking**: Updated domains of neighboring variables after each assignment, pruning inconsistent values early.\n",
    "\n",
    "This method avoids unnecessary search and solves the problem efficiently.\n",
    "\n",
    "Let me know if you'd like a more complex example or additional clarification!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e01a6e-4f51-4c84-9f6f-526d77ba19b1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 7.1\n",
    "\n",
    "### **Problem Statement**\n",
    "The agent starts in square **[1,1]** and perceives **[None, None, None, None, None]**, indicating no stench, breeze, glitter, bump, or scream.\n",
    "\n",
    "The agent moves to **[2,1]** and perceives **[None, Breeze, None, None, None]**, indicating a breeze. Based on these observations:\n",
    "\n",
    "1. Can the agent infer the presence of a pit in **[2,2]**, **[3,1]**, or both?\n",
    "2. Which square is safe for the agent to move to next?\n",
    "\n",
    "---\n",
    "\n",
    "### **Step-by-Step Solution**\n",
    "\n",
    "#### **Step 1: Represent the Initial Knowledge**\n",
    "- The agent knows:\n",
    "  - **Square [1,1] is safe (OK)** because the initial percept contains no dangers.\n",
    "  - Percepts in square **[1,1]:** $[None, None, None, None, None]$.\n",
    "  - Rules of the Wumpus World:\n",
    "    - A breeze in a square implies that one or more neighboring squares contain a pit. \n",
    "      $$\n",
    "      B_{x,y} \\iff (P_{x+1,y} \\lor P_{x-1,y} \\lor P_{x,y+1} \\lor P_{x,y-1})\n",
    "      $$\n",
    "\n",
    "#### **Step 2: Update the Knowledge Base**\n",
    "- After moving to **[2,1]**, the agent perceives a **breeze**:\n",
    "  - From the rule:\n",
    "    $$\n",
    "    B_{2,1} \\iff (P_{3,1} \\lor P_{1,1} \\lor P_{2,2})\n",
    "    $$\n",
    "  - Substitute known facts:\n",
    "    - $[1,1]$ is **safe** ($ \\neg P_{1,1} $).\n",
    "  - Simplify:\n",
    "    $$\n",
    "    B_{2,1} \\iff (P_{3,1} \\lor P_{2,2})\n",
    "    $$\n",
    "\n",
    "#### **Step 3: Logical Reasoning**\n",
    "- Percept in **[1,1]** had no breeze ($ \\neg B_{1,1} $):\n",
    "  - $$\n",
    "    \\neg B_{1,1} \\implies \\neg P_{2,1} \\land \\neg P_{1,2}\n",
    "    $$\n",
    "  - Square **[1,2]** is **safe**.\n",
    "\n",
    "- In **[2,1]**, since there’s a breeze, at least one of the neighboring squares must contain a pit:\n",
    "  - $$\n",
    "    P_{3,1} \\lor P_{2,2}\n",
    "    $$\n",
    "- However, no definitive conclusion can be made yet about which specific square contains a pit. The agent marks **[3,1]** and **[2,2]** as **possible pits**.\n",
    "\n",
    "#### **Step 4: Determine Next Safe Square**\n",
    "- The agent identifies **[1,2]** as a safe square because:\n",
    "  - It is adjacent to **[1,1]**, and no breeze was perceived in **[1,1]**.\n",
    "- The agent moves to **[1,2]**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Result**\n",
    "1. The agent infers that **[3,1]** or **[2,2]** (or both) may contain a pit.\n",
    "2. The next safe square for the agent is **[1,2]**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2617d43c-8187-417a-96f1-8545da69adc3",
   "metadata": {},
   "source": [
    "# Here’s an example problem related to **Section 7.4 (Propositional Logic)** of the Wumpus World, involving logical reasoning, knowledge bases, and inference.\n",
    "\n",
    "---\n",
    "\n",
    "### **Example Problem**\n",
    "\n",
    "The agent is in a Wumpus World where:\n",
    "1. It starts at square **[1,1]** and perceives no stench, breeze, glitter, bump, or scream. \n",
    "2. It moves to square **[2,1]** and perceives a **breeze** but no other percepts.\n",
    "\n",
    "Using the rules of the Wumpus World:\n",
    "- $ B_{x,y} \\iff (P_{x+1,y} \\lor P_{x-1,y} \\lor P_{x,y+1} \\lor P_{x,y-1}) $,\n",
    "- $ \\neg B_{1,1} \\implies \\neg P_{1,2} \\land \\neg P_{2,1} $,\n",
    "\n",
    "Answer the following:\n",
    "\n",
    "1. Can the agent infer the presence of a pit in square **[3,1]**, **[2,2]**, or both? \n",
    "2. Which square(s) can the agent safely move to next?\n",
    "3. If the agent later moves to **[1,2]** and perceives no stench or breeze, what additional inferences can it make about **[2,2]**?\n",
    "\n",
    "---\n",
    "\n",
    "### **Solution Outline**\n",
    "\n",
    "#### **Part 1: Inferring the Presence of a Pit**\n",
    "- **Given Data:**\n",
    "  - $ B_{2,1} = True $\n",
    "  - $ \\neg B_{1,1} = True $ (no breeze at [1,1])\n",
    "  \n",
    "- **Rule Application:**\n",
    "  1. From $ B_{2,1} \\iff (P_{3,1} \\lor P_{1,1} \\lor P_{2,2}) $:\n",
    "     - Since $ \\neg P_{1,1} $ (safe start square), the pit must be in **[3,1]** or **[2,2]**:\n",
    "       $$\n",
    "       P_{3,1} \\lor P_{2,2}\n",
    "       $$\n",
    "  2. **No definitive conclusion yet** about which square contains the pit.\n",
    "\n",
    "#### **Part 2: Safe Moves**\n",
    "- From $ \\neg B_{1,1} \\implies \\neg P_{1,2} \\land \\neg P_{2,1} $, **[1,2]** is safe.\n",
    "- **Safe square:** **[1,2]**.\n",
    "\n",
    "#### **Part 3: Additional Inference**\n",
    "- If the agent moves to **[1,2]** and perceives no breeze ($ \\neg B_{1,2} $):\n",
    "  - By $ \\neg B_{1,2} \\implies \\neg P_{2,2} \\land \\neg P_{1,3} $:\n",
    "    - **[2,2]** is also safe.\n",
    "  - The pit must therefore be in **[3,1]**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Expected Answer**\n",
    "\n",
    "1. The agent infers that a pit is in either **[3,1]** or **[2,2]**.\n",
    "2. The agent can safely move to **[1,2]**.\n",
    "3. If there’s no breeze at **[1,2]**, the agent can infer that **[2,2]** is safe and the pit is definitively in **[3,1]**.\n",
    "\n",
    "---\n",
    "\n",
    "This problem tests propositional logic, rule application, and inference reasoning in the context of the Wumpus World. Let me know if you need help crafting more problems or diving deeper into the solution!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522dfbc0-53c3-42e4-9201-bc7c55673a4a",
   "metadata": {},
   "source": [
    "### Solved Example Problem: Wumpus World Logical Reasoning\n",
    "\n",
    "---\n",
    "\n",
    "### **Problem Statement**\n",
    "\n",
    "The agent is exploring a Wumpus World represented as a $ 4 \\times 4 $ grid. Initially, the agent is at square $ [1,1] $, which is safe. The following rules and observations are provided:\n",
    "\n",
    "#### **Rules**\n",
    "1. A **breeze** in a square ($ B_{x,y} $) implies there is a **pit** in one or more adjacent squares:\n",
    "   $$\n",
    "   B_{x,y} \\iff (P_{x+1,y} \\lor P_{x-1,y} \\lor P_{x,y+1} \\lor P_{x,y-1})\n",
    "   $$\n",
    "2. If no breeze is perceived in a square ($ \\neg B_{x,y} $), all adjacent squares are pit-free:\n",
    "   $$\n",
    "   \\neg B_{x,y} \\implies (\\neg P_{x+1,y} \\land \\neg P_{x-1,y} \\land \\neg P_{x,y+1} \\land \\neg P_{x,y-1})\n",
    "   $$\n",
    "\n",
    "#### **Observations**\n",
    "1. At $ [1,1] $: $ \\neg B_{1,1} $ (no breeze).\n",
    "2. The agent moves to $ [2,1] $ and perceives a breeze ($ B_{2,1} $).\n",
    "\n",
    "#### **Questions**\n",
    "1. Which squares can the agent infer to be safe or possibly dangerous?\n",
    "2. Can the agent move safely to $ [1,2] $ or $ [2,2] $?\n",
    "3. If the agent perceives no breeze at $ [1,2] $, what additional inferences can it make?\n",
    "\n",
    "---\n",
    "\n",
    "### **Solution**\n",
    "\n",
    "#### **Step 1: Analyzing $ [1,1] $**\n",
    "- $ \\neg B_{1,1} $: There is no breeze at $ [1,1] $.\n",
    "- Rule $ \\neg B_{1,1} \\implies \\neg P_{2,1} \\land \\neg P_{1,2} $:\n",
    "  - $ \\neg P_{2,1} $: No pit in $ [2,1] $.\n",
    "  - $ \\neg P_{1,2} $: No pit in $ [1,2] $.\n",
    "\n",
    "**Safe squares inferred so far**: $ [1,1] $, $ [1,2] $.\n",
    "\n",
    "#### **Step 2: Analyzing $ [2,1] $**\n",
    "- $ B_{2,1} $: Breeze perceived at $ [2,1] $, indicating a pit in an adjacent square.\n",
    "- Rule $ B_{2,1} \\iff (P_{3,1} \\lor P_{1,1} \\lor P_{2,2} \\lor P_{2,0}) $:\n",
    "  - Adjacent squares: $ [3,1], [1,1], [2,2] $ (ignore $ [2,0] $ as it is outside the grid).\n",
    "  - Since $ [1,1] $ is safe ($ \\neg P_{1,1} $), the pit must be in $ [3,1] $ or $ [2,2] $.\n",
    "\n",
    "**Possibly dangerous squares inferred so far**: $ [3,1], [2,2] $.\n",
    "\n",
    "#### **Step 3: Can the Agent Move to $ [1,2] $ or $ [2,2] $?**\n",
    "- $ [1,2] $: Previously inferred as safe ($ \\neg P_{1,2} $).\n",
    "- $ [2,2] $: Possibly dangerous ($ P_{2,2} $ inferred as a potential pit location).\n",
    "\n",
    "**Conclusion**: The agent can move safely to $ [1,2] $, but not $ [2,2] $.\n",
    "\n",
    "#### **Step 4: Analyzing $ [1,2] $ if No Breeze Perceived**\n",
    "- $ \\neg B_{1,2} $: No breeze at $ [1,2] $.\n",
    "- Rule $ \\neg B_{1,2} \\implies \\neg P_{2,2} \\land \\neg P_{1,3} $:\n",
    "  - $ \\neg P_{2,2} $: No pit in $ [2,2] $.\n",
    "  - $ \\neg P_{1,3} $: No pit in $ [1,3] $.\n",
    "\n",
    "**Updated Knowledge**:\n",
    "- $ [2,2] $ is now safe.\n",
    "- $ [3,1] $ is the only possible location for the pit.\n",
    "\n",
    "---\n",
    "\n",
    "### **Final Answers**\n",
    "1. **Safe squares**: $ [1,1], [1,2] $.  \n",
    "   **Possibly dangerous squares**: $ [3,1], [2,2] $.  \n",
    "   After perceiving no breeze at $ [1,2] $: $ [2,2] $ and $ [1,3] $ are also safe, leaving $ [3,1] $ as the only dangerous square.\n",
    "   \n",
    "2. The agent can move safely to $ [1,2] $, but $ [2,2] $ is initially unsafe.\n",
    "\n",
    "3. If there is no breeze at $ [1,2] $, the agent infers that $ [2,2] $ and $ [1,3] $ are safe, leaving $ [3,1] $ as the pit location.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a004df5a-8bae-46d0-8f4a-4b7053a5d88c",
   "metadata": {},
   "source": [
    "### Example Problem: SAT Solving with DPLL and WalkSAT\n",
    "\n",
    "---\n",
    "\n",
    "### **Problem Statement**\n",
    "\n",
    "You are tasked with determining if the following propositional logic sentence is satisfiable:\n",
    "\n",
    "$$\n",
    "(A \\lor \\neg B) \\land (\\neg A \\lor C) \\land (\\neg C \\lor B) \\land (\\neg A \\lor \\neg C)\n",
    "$$\n",
    "\n",
    "### **Questions**\n",
    "\n",
    "1. Use the **DPLL algorithm** to determine if the sentence is satisfiable.\n",
    "2. Use the **WalkSAT algorithm** to approximate a solution, assuming $ p = 0.5 $ (probability of a random walk) and $ \\text{max_flips} = 10 $.\n",
    "\n",
    "---\n",
    "\n",
    "### **Solution**\n",
    "\n",
    "#### **Step 1: Convert the Sentence to CNF**\n",
    "The sentence is already in conjunctive normal form (CNF):\n",
    "\n",
    "$$\n",
    "\\text{CNF} = \\{(A \\lor \\neg B), (\\neg A \\lor C), (\\neg C \\lor B), (\\neg A \\lor \\neg C)\\}\n",
    "$$\n",
    "\n",
    "Each clause is a disjunction of literals, and the overall sentence is a conjunction of these clauses.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 2: Solve Using the DPLL Algorithm**\n",
    "\n",
    "##### **Initial Setup**\n",
    "1. **Clauses**: $(A \\lor \\neg B)$, $(\\neg A \\lor C)$, $(\\neg C \\lor B)$, $(\\neg A \\lor \\neg C)$\n",
    "2. **Symbols**: $ A, B, C $\n",
    "3. **Model**: Initially empty.\n",
    "\n",
    "##### **DPLL Execution**\n",
    "1. **Early Termination**: No clause is fully satisfied or unsatisfied in the initial empty model.\n",
    "   \n",
    "2. **Pure Symbol Heuristic**:\n",
    "   - Pure symbols appear with only one polarity across all clauses. \n",
    "   - No pure symbol is identified since all symbols appear with both positive and negative signs.\n",
    "\n",
    "3. **Unit Clause Heuristic**:\n",
    "   - A unit clause has only one unassigned literal. Initially, there are no unit clauses.\n",
    "\n",
    "4. **Branching**:\n",
    "   - Select $ A $ arbitrarily and assign $ A = \\text{True} $.\n",
    "   - Model becomes $ \\{ A = \\text{True} \\} $.\n",
    "\n",
    "5. **Simplify Clauses**:\n",
    "   - Substitute $ A = \\text{True} $:\n",
    "     $$\n",
    "     (A \\lor \\neg B) \\to \\text{True}, \\quad (\\neg A \\lor C) \\to C, \\quad (\\neg C \\lor B) \\to (\\neg C \\lor B), \\quad (\\neg A \\lor \\neg C) \\to \\neg C\n",
    "     $$\n",
    "\n",
    "6. **Unit Clause Heuristic**:\n",
    "   - The clause $ \\neg C $ becomes a unit clause. Assign $ C = \\text{False} $.\n",
    "   - Model becomes $ \\{ A = \\text{True}, C = \\text{False} \\} $.\n",
    "\n",
    "7. **Simplify Clauses**:\n",
    "   - Substitute $ C = \\text{False} $:\n",
    "     $$\n",
    "     (\\neg C \\lor B) \\to B, \\quad (\\neg A \\lor \\neg C) \\to \\text{True}.\n",
    "     $$\n",
    "\n",
    "8. **Unit Clause Heuristic**:\n",
    "   - The clause $ B $ becomes a unit clause. Assign $ B = \\text{True} $.\n",
    "   - Model becomes $ \\{ A = \\text{True}, C = \\text{False}, B = \\text{True} \\} $.\n",
    "\n",
    "9. **Verify**:\n",
    "   - Substitute $ A = \\text{True}, B = \\text{True}, C = \\text{False} $ into all clauses:\n",
    "     $$\n",
    "     (A \\lor \\neg B) \\to \\text{True}, \\quad (\\neg A \\lor C) \\to \\text{True}, \\quad (\\neg C \\lor B) \\to \\text{True}, \\quad (\\neg A \\lor \\neg C) \\to \\text{True}.\n",
    "     $$\n",
    "\n",
    "All clauses are satisfied. **The sentence is satisfiable**.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 3: Solve Using the WalkSAT Algorithm**\n",
    "\n",
    "##### **Setup**\n",
    "1. **Clauses**: Same as above.\n",
    "2. **Symbols**: $ A, B, C $.\n",
    "3. **Random Assignment**: $ A = \\text{False}, B = \\text{False}, C = \\text{True} $.\n",
    "\n",
    "##### **Execution**\n",
    "1. **Evaluate**:\n",
    "   - Unsatisfied clauses: $ (A \\lor \\neg B), (\\neg C \\lor B), (\\neg A \\lor \\neg C) $.\n",
    "\n",
    "2. **Random Walk** ($ p = 0.5 $):\n",
    "   - Randomly pick an unsatisfied clause (e.g., $ (A \\lor \\neg B) $).\n",
    "   - Flip a random literal in the clause (e.g., $ A $). Assign $ A = \\text{True} $.\n",
    "   - New model: $ A = \\text{True}, B = \\text{False}, C = \\text{True} $.\n",
    "\n",
    "3. **Evaluate**:\n",
    "   - Unsatisfied clauses: $ (\\neg A \\lor C), (\\neg C \\lor B) $.\n",
    "\n",
    "4. **Min-Conflicts**:\n",
    "   - Flip $ C $ to minimize the number of unsatisfied clauses. Assign $ C = \\text{False} $.\n",
    "   - New model: $ A = \\text{True}, B = \\text{False}, C = \\text{False} $.\n",
    "\n",
    "5. **Evaluate**:\n",
    "   - Unsatisfied clauses: $ (\\neg C \\lor B) $.\n",
    "\n",
    "6. **Random Walk**:\n",
    "   - Flip $ B $. Assign $ B = \\text{True} $.\n",
    "   - New model: $ A = \\text{True}, B = \\text{True}, C = \\text{False} $.\n",
    "\n",
    "7. **Evaluate**:\n",
    "   - All clauses are satisfied.\n",
    "\n",
    "---\n",
    "\n",
    "### **Final Answer**\n",
    "1. Using **DPLL**, the sentence is satisfiable with $ \\{ A = \\text{True}, B = \\text{True}, C = \\text{False} \\} $.\n",
    "2. Using **WalkSAT**, the sentence is satisfiable with the same assignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5799cf38-58c8-441b-947e-4fce9ac85a1e",
   "metadata": {},
   "source": [
    "### Example Problem: Logical Agent in the Wumpus World\n",
    "\n",
    "---\n",
    "\n",
    "### **Scenario**\n",
    "\n",
    "You are designing a logical agent to navigate the **Wumpus World**, a $ 4 \\times 4 $ grid-based environment. The agent starts at $ (1,1) $, which is known to be safe, and gathers percepts (breeze, stench, glitter, etc.) to update its knowledge base and decide its actions.\n",
    "\n",
    "The agent encounters the following situation:\n",
    "\n",
    "1. At $ (1,1) $, the percept is $ [\\text{None}] $ (no breeze, no stench, no glitter).\n",
    "2. The agent moves to $ (2,1) $ and perceives $ [\\text{Breeze}] $.\n",
    "3. The agent now needs to infer:\n",
    "   - Which squares might contain a pit.\n",
    "   - Which adjacent squares are safe to move into next.\n",
    "\n",
    "---\n",
    "\n",
    "### **Problem**\n",
    "\n",
    "1. Use **forward chaining** to determine if there is a pit in $ (2,2) $ or $ (3,1) $.\n",
    "2. Use **backward chaining** to verify if $ (1,2) $ is safe.\n",
    "3. Decide the agent's next safe move.\n",
    "\n",
    "---\n",
    "\n",
    "### **Solution**\n",
    "\n",
    "#### **Step 1: Represent Initial Knowledge**\n",
    "The knowledge base $ \\text{KB} $ contains:\n",
    "1. $ \\neg P_{1,1} $: No pit in $ (1,1) $ (safe start square).\n",
    "2. $ B_{x,y} \\iff (P_{x+1,y} \\lor P_{x-1,y} \\lor P_{x,y+1} \\lor P_{x,y-1}) $: Breeze indicates a pit in one or more adjacent squares.\n",
    "3. $ \\neg B_{1,1} $: No breeze at $ (1,1) $, so adjacent squares $ (1,2) $ and $ (2,1) $ are pit-free.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 2: Use Forward Chaining**\n",
    "Percept at $ (2,1) $: $ B_{2,1} = \\text{True} $.  \n",
    "By the rule $ B_{x,y} \\iff (P_{x+1,y} \\lor P_{x-1,y} \\lor P_{x,y+1} \\lor P_{x,y-1}) $, we deduce:\n",
    "\n",
    "$\n",
    "B_{2,1} \\iff (P_{3,1} \\lor P_{1,1} \\lor P_{2,2})\n",
    "$\n",
    "\n",
    "1. Substitute $ \\neg P_{1,1} $ (no pit at $ (1,1) $):\n",
    "   $\n",
    "   B_{2,1} \\iff (P_{3,1} \\lor P_{2,2})\n",
    "   $\n",
    "\n",
    "2. Since $ B_{2,1} = \\text{True} $, at least one of $ P_{3,1} $ or $ P_{2,2} $ is true:\n",
    "   $\n",
    "   P_{3,1} \\lor P_{2,2}\n",
    "   $\n",
    "\n",
    "3. $ P_{3,1} $ and $ P_{2,2} $ are marked as potential pit locations.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 3: Use Backward Chaining**\n",
    "To check if $ (1,2) $ is safe:\n",
    "1. From $ \\neg B_{1,1} $:\n",
    "   $\n",
    "   \\neg B_{1,1} \\implies (\\neg P_{1,2} \\land \\neg P_{2,1})\n",
    "   $\n",
    "\n",
    "2. Substitute $ \\neg B_{1,1} = \\text{True} $:\n",
    "   $\n",
    "   \\neg P_{1,2} \\land \\neg P_{2,1}\n",
    "   $\n",
    "\n",
    "3. $ \\neg P_{1,2} $: $ (1,2) $ is safe.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 4: Determine the Next Safe Move**\n",
    "Safe squares adjacent to $ (2,1) $:\n",
    "1. $ (1,2) $: Proven safe by backward chaining.\n",
    "2. $ (1,1) $: Already visited.\n",
    "3. $ (2,2) $: Potentially unsafe due to $ P_{2,2} $.\n",
    "4. $ (3,1) $: Potentially unsafe due to $ P_{3,1} $.\n",
    "\n",
    "The agent moves to **$ (1,2) $**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Final Answer**\n",
    "\n",
    "1. **Forward Chaining**: $ P_{3,1} \\lor P_{2,2} $ — at least one of $ (3,1) $ or $ (2,2) $ contains a pit.\n",
    "2. **Backward Chaining**: $ (1,2) $ is safe.\n",
    "3. **Next Safe Move**: The agent should move to $ (1,2) $.\n",
    "\n",
    "---\n",
    "\n",
    "### **Code Implementation**\n",
    "\n",
    "#### Forward Chaining\n",
    "```python\n",
    "# Define knowledge base rules\n",
    "kb = [\n",
    "    {\"if\": {\"Breeze at (2,1)\"}, \"then\": \"Pit at (3,1) or Pit at (2,2)\"},\n",
    "    {\"if\": {\"No Breeze at (1,1)\"}, \"then\": \"No Pit at (1,2) and No Pit at (2,1)\"}\n",
    "]\n",
    "\n",
    "# Percepts\n",
    "facts = {\"Breeze at (2,1)\", \"No Breeze at (1,1)\"}\n",
    "\n",
    "# Apply forward chaining\n",
    "def forward_chaining(kb, facts):\n",
    "    inferred = set(facts)\n",
    "    while True:\n",
    "        new_inferred = set()\n",
    "        for rule in kb:\n",
    "            if rule[\"if\"].issubset(inferred):\n",
    "                new_inferred.add(rule[\"then\"])\n",
    "        if new_inferred.issubset(inferred):\n",
    "            break\n",
    "        inferred.update(new_inferred)\n",
    "    return inferred\n",
    "\n",
    "result = forward_chaining(kb, facts)\n",
    "print(\"Forward Chaining Result:\", result)\n",
    "```\n",
    "\n",
    "#### Backward Chaining\n",
    "```python\n",
    "# Define knowledge base rules\n",
    "kb = [\n",
    "    {\"if\": {\"No Breeze at (1,1)\"}, \"then\": \"No Pit at (1,2) and No Pit at (2,1)\"},\n",
    "    {\"if\": {\"Breeze at (2,1)\"}, \"then\": \"Pit at (3,1) or Pit at (2,2)\"}\n",
    "]\n",
    "\n",
    "# Query to prove\n",
    "query = \"No Pit at (1,2)\"\n",
    "\n",
    "# Backward chaining function\n",
    "def backward_chaining(kb, query, inferred=None):\n",
    "    if inferred is None:\n",
    "        inferred = set()\n",
    "    if query in inferred:\n",
    "        return True\n",
    "    for rule in kb:\n",
    "        if rule[\"then\"] == query:\n",
    "            if all(backward_chaining(kb, premise, inferred) for premise in rule[\"if\"]):\n",
    "                inferred.add(query)\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "result = backward_chaining(kb, query)\n",
    "print(f\"Backward Chaining Result: Can we prove '{query}'?\", result)\n",
    "```\n",
    "\n",
    "This example illustrates how logical agents use forward and backward chaining to infer safe moves and dangerous squares. Let me know if you'd like further elaboration or a different scenario!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bb21f3-cd13-437a-8247-37ecf2769ae8",
   "metadata": {},
   "source": [
    "# 8.1 \n",
    "\n",
    "Sure! Let’s walk through an example of using **First-Order Logic (FOL)** from Section 8.1. We'll use the **Wumpus World** as the domain, illustrating how FOL allows concise and expressive representation of rules and facts compared to propositional logic.\n",
    "\n",
    "---\n",
    "\n",
    "### Example: \"Squares Adjacent to Pits Are Breezy\"\n",
    "\n",
    "#### Scenario\n",
    "- The Wumpus World has a grid where:\n",
    "  - **Pits** are hazards in certain squares.\n",
    "  - **Breezy squares** are adjacent to pits.\n",
    "  - The agent perceives breezes to infer the locations of pits.\n",
    "\n",
    "#### Representation in **Propositional Logic**\n",
    "In propositional logic, we explicitly write a separate rule for each square's adjacency to pits:\n",
    "\n",
    "- $ B_{1,1} \\Leftrightarrow (P_{1,2} \\lor P_{2,1}) $  \n",
    "- $ B_{1,2} \\Leftrightarrow (P_{1,1} \\lor P_{1,3} \\lor P_{2,2}) $  \n",
    "- $ B_{2,1} \\Leftrightarrow (P_{1,1} \\lor P_{2,2} \\lor P_{3,1}) $  \n",
    "\n",
    "This requires a rule for every square on the grid, quickly becoming verbose for larger grids.\n",
    "\n",
    "---\n",
    "\n",
    "#### Representation in **First-Order Logic**\n",
    "In FOL, we use quantifiers to express this relationship concisely:\n",
    "\n",
    "- **Rule**: \"A square is breezy if it is adjacent to a pit.\"\n",
    "  - $ \\forall s \\, \\text{Breezy}(s) \\Leftrightarrow (\\exists r \\, \\text{Adjacent}(r, s) \\land \\text{Pit}(r)) $\n",
    "\n",
    "This captures the same logic but applies to **all squares** in the grid without repeating the rule for each square.\n",
    "\n",
    "---\n",
    "\n",
    "#### Breaking Down the FOL Sentence\n",
    "\n",
    "1. **Quantifiers**:\n",
    "   - $ \\forall s $: For all squares $ s $.\n",
    "   - $ \\exists r $: There exists a square $ r $.\n",
    "\n",
    "2. **Predicate Definitions**:\n",
    "   - $ \\text{Breezy}(s) $: True if square $ s $ is breezy.\n",
    "   - $ \\text{Adjacent}(r, s) $: True if square $ r $ is adjacent to square $ s $.\n",
    "   - $ \\text{Pit}(r) $: True if square $ r $ has a pit.\n",
    "\n",
    "3. **Logical Connectives**:\n",
    "   - $ \\land $: Logical AND connects adjacency and the presence of a pit.\n",
    "   - $ \\Leftrightarrow $: Biconditional states that breezy squares are precisely those with adjacent pits.\n",
    "\n",
    "---\n",
    "\n",
    "### Example in Action\n",
    "\n",
    "Suppose we observe the following facts:\n",
    "1. $ \\text{Breezy}([2,2]) $: Square $[2,2]$ is breezy.\n",
    "2. $ \\text{Adjacent}([2,1], [2,2]) $, $ \\text{Adjacent}([2,3], [2,2]) $, etc.: Adjacency relations are predefined.\n",
    "\n",
    "Using FOL, the agent infers:\n",
    "- From $ \\text{Breezy}([2,2]) $: There must be a pit adjacent to $[2,2]$.\n",
    "- Possible locations of pits: $[2,1], [2,3], [1,2], [3,2]$.\n",
    "\n",
    "---\n",
    "\n",
    "#### Code Illustration\n",
    "Here’s a Python representation of the logic using symbolic reasoning:\n",
    "\n",
    "```python\n",
    "from sympy.logic.boolalg import Or, And, Implies\n",
    "from sympy import symbols\n",
    "\n",
    "# Define predicates\n",
    "Breezy, Adjacent, Pit = symbols('Breezy Adjacent Pit')\n",
    "\n",
    "# Logical rule in FOL: Breezy(s) <=> Exists r (Adjacent(r, s) AND Pit(r))\n",
    "s, r = symbols('s r')  # s: current square, r: adjacent square\n",
    "breezy_rule = Implies(Breezy, Or(And(Adjacent, Pit)))\n",
    "\n",
    "# Facts\n",
    "facts = {\n",
    "    Breezy: True,  # Square [2,2] is breezy\n",
    "    Adjacent: True,  # [2,1] is adjacent to [2,2]\n",
    "    Pit: False  # Pit status for [2,1] (to check consistency)\n",
    "}\n",
    "\n",
    "# Evaluate rule for adjacent squares\n",
    "print(breezy_rule.subs(facts))  # Returns True if consistent, False otherwise\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusion\n",
    "By using FOL:\n",
    "1. We concisely represent general rules like breeziness depending on adjacent pits.\n",
    "2. FOL avoids duplicating rules for every square, making the representation scalable.\n",
    "3. Inference allows the agent to deduce possible pit locations from observations.\n",
    "\n",
    "Let me know if you'd like further clarification or to explore another example!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b388ccd-497d-4138-9c8d-1b05475742a1",
   "metadata": {},
   "source": [
    "### Exam Question Example: 8.2\n",
    "\n",
    "#### Question:\n",
    "Consider the following logical statements in a domain of people, kings, and relationships:\n",
    "\n",
    "1. $ \\forall x \\, King(x) \\implies Person(x) $  \n",
    "2. $ Brother(John, Richard) $  \n",
    "3. $ \\forall x \\, \\exists y \\, Loves(x, y) $  \n",
    "\n",
    "Answer the following:\n",
    "\n",
    "1. **Interpret the meaning** of each statement in plain English.\n",
    "2. **Determine if the following are true, false, or cannot be determined** based on the given statements:\n",
    "   - (a) $ Person(John) $\n",
    "   - (b) $ Loves(Richard, John) $\n",
    "   - (c) $ Brother(Richard, John) $\n",
    "3. **Prove or disprove** whether $ \\exists x \\, Person(x) $ is entailed by the given statements.\n",
    "4. Represent the following in **first-order logic**: \"Everyone loves themselves or someone else.\"\n",
    "\n",
    "---\n",
    "\n",
    "### Worked Solution:\n",
    "\n",
    "#### 1. Interpret the Statements\n",
    "- **Statement 1**: For all objects $ x $, if $ x $ is a king, then $ x $ is also a person.\n",
    "- **Statement 2**: John is the brother of Richard.\n",
    "- **Statement 3**: For every object $ x $, there exists at least one object $ y $, such that $ x $ loves $ y $.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Determine Truth of Statements\n",
    "- **(a) $ Person(John) $**:\n",
    "  - From Statement 1, $ King(x) \\implies Person(x) $. However, nothing indicates whether $ King(John) $ is true, so we cannot conclude $ Person(John) $.\n",
    "  - **Answer**: Cannot be determined.\n",
    "\n",
    "- **(b) $ Loves(Richard, John) $**:\n",
    "  - From Statement 3, we know $ \\forall x \\, \\exists y \\, Loves(x, y) $, so Richard must love someone. However, it does not specify who Richard loves.\n",
    "  - **Answer**: Cannot be determined.\n",
    "\n",
    "- **(c) $ Brother(Richard, John) $**:\n",
    "  - From Statement 2, $ Brother(John, Richard) $ is given. Assuming brotherhood is symmetric, $ Brother(Richard, John) $ must also be true.\n",
    "  - **Answer**: True.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Entailment of $ \\exists x \\, Person(x) $\n",
    "We need to determine if at least one $ x $ is a person.\n",
    "\n",
    "- From Statement 1: $ \\forall x \\, King(x) \\implies Person(x) $. This implies that if there is a king, that king is a person.\n",
    "- However, no information is provided about whether there exists a king. Thus, we cannot conclude $ \\exists x \\, Person(x) $.\n",
    "- **Answer**: Not entailed.\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. Representation of \"Everyone loves themselves or someone else\"\n",
    "We need to express the idea that all objects $ x $ either love themselves or some other object $ y $:\n",
    "$$ \\forall x \\, (Loves(x, x) \\lor \\exists y \\, Loves(x, y)) $$\n",
    "\n",
    "---\n",
    "\n",
    "### Exam Tips:\n",
    "1. **For entailment** questions, remember that entailment means the statement must follow logically from the given information in **all possible interpretations**.\n",
    "2. **Interpret logical sentences carefully**: Break down quantifiers ($ \\forall $, $ \\exists $) and implications ($ \\implies $) step-by-step.\n",
    "3. **When converting English to FOL**, watch for key phrases like \"everyone\" ($ \\forall $) and \"there exists\" ($ \\exists $).\n",
    "\n",
    "Let me know if you’d like to explore variations or deeper clarifications!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7735cdd1-1aec-45e3-9444-de70f47fc42c",
   "metadata": {},
   "source": [
    "### Exam Question Example 8.3 \n",
    "\n",
    "#### Question:\n",
    "Consider the following domain of **family relationships**:\n",
    "\n",
    "1. $ \\forall x \\, Male(x) \\lor Female(x) $  \n",
    "2. $ \\forall p, c \\, Parent(p, c) \\implies \\neg Child(c, p) $  \n",
    "3. $ \\forall m, c \\, Mother(c) = m \\iff Female(m) \\land Parent(m, c) $  \n",
    "4. $ Sibling(x, y) \\iff (x \\neq y \\land \\exists p \\, Parent(p, x) \\land Parent(p, y)) $.\n",
    "\n",
    "Answer the following:\n",
    "\n",
    "1. **Translate each logical statement into plain English.**\n",
    "2. Based on the above statements, prove whether the following is true:\n",
    "   - (a) $ \\forall x \\, Male(x) \\implies \\neg Female(x) $\n",
    "   - (b) $ \\exists x, y \\, Sibling(x, y) \\implies \\exists z \\, Parent(z, x) $\n",
    "3. Represent the following statement in first-order logic: \"Every mother is a female.\"\n",
    "4. Represent the following facts in the KB and check whether they satisfy the statement $ Sibling(John, Mary) $:\n",
    "   - $ Parent(Alice, John) $\n",
    "   - $ Parent(Alice, Mary) $\n",
    "   - $ Female(Mary) $\n",
    "   - $ Male(John) $\n",
    "\n",
    "---\n",
    "\n",
    "### Worked Solution:\n",
    "\n",
    "#### 1. Translation of Logical Statements\n",
    "1. **Statement 1**: Every individual is either male or female.\n",
    "2. **Statement 2**: A parent cannot simultaneously be a child of their own child.\n",
    "3. **Statement 3**: The mother of a child is a female parent of that child.\n",
    "4. **Statement 4**: Two individuals are siblings if they share at least one parent and are not the same individual.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Prove the Statements\n",
    "\n",
    "**(a) $ \\forall x \\, Male(x) \\implies \\neg Female(x) $:**\n",
    "\n",
    "- **Reasoning**: From Statement 1, $ \\forall x \\, Male(x) \\lor Female(x) $, each individual is either male or female.\n",
    "- Assume $ Male(x) $ is true. Since both cannot be true for the same individual, $ \\neg Female(x) $ must hold.\n",
    "- **Conclusion**: The statement is **true**.\n",
    "\n",
    "---\n",
    "\n",
    "**(b) $ \\exists x, y \\, Sibling(x, y) \\implies \\exists z \\, Parent(z, x) $:**\n",
    "\n",
    "- **Reasoning**:\n",
    "  - If $ Sibling(x, y) $, then $ \\exists p \\, Parent(p, x) \\land Parent(p, y) $ (from Statement 4).\n",
    "  - This means $ x $ has a parent $ z $ (where $ z = p $).\n",
    "- **Conclusion**: The statement is **true**.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Represent \"Every mother is a female\" in First-Order Logic\n",
    "$$\n",
    "\\forall m \\, (\\exists c \\, Mother(c) = m) \\implies Female(m)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. Checking Sibling Relationship\n",
    "\n",
    "##### Facts:\n",
    "1. $ Parent(Alice, John) $\n",
    "2. $ Parent(Alice, Mary) $\n",
    "3. $ Female(Mary) $\n",
    "4. $ Male(John) $\n",
    "\n",
    "##### Logical Representation:\n",
    "- $ Sibling(John, Mary) \\iff (John \\neq Mary \\land \\exists p \\, Parent(p, John) \\land Parent(p, Mary)) $.\n",
    "\n",
    "##### Step-by-Step Evaluation:\n",
    "1. $ John \\neq Mary $: True, as they are different individuals.\n",
    "2. $ \\exists p \\, Parent(p, John) \\land Parent(p, Mary) $: True, since $ Parent(Alice, John) \\land Parent(Alice, Mary) $.\n",
    "\n",
    "Thus, $ Sibling(John, Mary) $ is **true**.\n",
    "\n",
    "---\n",
    "\n",
    "### Example Python Code for Checking $ Sibling(John, Mary) $:\n",
    "```python\n",
    "from sympy import symbols, And, Exists\n",
    "\n",
    "# Define predicates and variables\n",
    "Parent = symbols('Parent')\n",
    "Sibling = symbols('Sibling')\n",
    "John, Mary, Alice = symbols('John Mary Alice')\n",
    "\n",
    "# Define sibling rule\n",
    "sibling_rule = Sibling(John, Mary) == And(John != Mary, Exists(Alice, And(Parent(Alice, John), Parent(Alice, Mary))))\n",
    "\n",
    "# Define facts\n",
    "facts = {\n",
    "    Parent(Alice, John): True,\n",
    "    Parent(Alice, Mary): True,\n",
    "    John != Mary: True\n",
    "}\n",
    "\n",
    "# Check if Sibling(John, Mary) holds\n",
    "print(sibling_rule.subs(facts))  # Expected output: True\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Exam Tips:\n",
    "1. **For entailment questions**, analyze the logical relationships step by step.\n",
    "2. Use **definitions and axioms** to prove statements and ensure consistency.\n",
    "3. Translate natural language into FOL carefully by identifying quantifiers ($ \\forall, \\exists $) and relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f4fbe0-589b-4668-82b8-725ed08ff479",
   "metadata": {},
   "source": [
    "### Exam Question Example: 8.4\n",
    "\n",
    "#### Question:\n",
    "A knowledge base (KB) is being developed for a **circuit domain** with the following information:\n",
    "\n",
    "1. **Ontology**:\n",
    "   - **Constants**: `Resistor1`, `NodeA`, `NodeB`.\n",
    "   - **Predicates**:\n",
    "     - `Resistor(x)`: True if $ x $ is a resistor.\n",
    "     - `Connected(x, y)`: True if $ x $ and $ y $ are connected.\n",
    "     - `Powered(x)`: True if $ x $ is powered.\n",
    "   - **Functions**:\n",
    "     - `Voltage(x)`: The voltage at $ x $.\n",
    "\n",
    "2. **Axioms**:\n",
    "   1. $ \\forall x \\, Resistor(x) \\implies \\exists a,b \\, Connected(a, x) \\land Connected(x, b) $: A resistor connects two nodes.\n",
    "   2. $ \\forall x, y \\, Powered(x) \\land Connected(x, y) \\implies Powered(y) $: A powered node powers all connected nodes.\n",
    "   3. $ \\forall x \\, Voltage(x) = 0 \\lor Voltage(x) > 0 $: A node has either zero or positive voltage.\n",
    "\n",
    "3. **Problem Instance**:\n",
    "   - $ Resistor(Resistor1) $\n",
    "   - $ Connected(NodeA, Resistor1) $\n",
    "   - $ Powered(NodeA) $\n",
    "   - $ Voltage(NodeA) = 5 $\n",
    "\n",
    "#### Questions:\n",
    "1. **Interpret the axioms in plain English.**\n",
    "2. Based on the given KB, is $ Powered(NodeB) $ true? Justify your answer.\n",
    "3. Represent the following statement in first-order logic: \"If NodeB is connected to NodeA, and NodeA is powered, then NodeB has the same voltage as NodeA.\"\n",
    "4. Write a Python code snippet to evaluate if $ Powered(NodeB) $ is true based on the axioms and facts.\n",
    "\n",
    "---\n",
    "\n",
    "### Worked Solution:\n",
    "\n",
    "#### 1. Interpretation of Axioms\n",
    "1. **Axiom 1**: Every resistor connects exactly two nodes.\n",
    "2. **Axiom 2**: If a node is powered, all nodes connected to it are also powered.\n",
    "3. **Axiom 3**: Each node's voltage is either zero or positive (no undefined or negative voltages).\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Is $ Powered(NodeB) $ true?\n",
    "\n",
    "**Reasoning**:\n",
    "1. From $ Powered(NodeA) $ and $ Connected(NodeA, Resistor1) $, Axiom 2 implies that all nodes connected to $ NodeA $ are powered.\n",
    "2. By Axiom 1, $ Resistor1 $ connects $ NodeA $ to another node, $ NodeB $. Hence, $ NodeB $ is powered.\n",
    "**Conclusion**: $ Powered(NodeB) $ is **true**.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Representation of \"If NodeB is connected to NodeA, and NodeA is powered, then NodeB has the same voltage as NodeA\" in FOL\n",
    "$$\n",
    "\\forall x, y \\, (Connected(x, y) \\land Powered(x)) \\implies (Voltage(x) = Voltage(y))\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. Python Code Snippet\n",
    "\n",
    "```python\n",
    "from sympy import symbols, And, Implies, ForAll, Eq\n",
    "\n",
    "# Define constants, predicates, and functions\n",
    "Resistor = symbols('Resistor')\n",
    "Connected = symbols('Connected')\n",
    "Powered = symbols('Powered')\n",
    "Voltage = symbols('Voltage')\n",
    "NodeA, NodeB, Resistor1 = symbols('NodeA NodeB Resistor1')\n",
    "\n",
    "# Define axioms\n",
    "axiom1 = ForAll([Resistor1], Implies(Resistor(Resistor1), And(Connected(NodeA, Resistor1), Connected(Resistor1, NodeB))))\n",
    "axiom2 = ForAll([NodeA, NodeB], Implies(And(Powered(NodeA), Connected(NodeA, NodeB)), Powered(NodeB)))\n",
    "axiom3 = ForAll([NodeA], Or(Eq(Voltage(NodeA), 0), Voltage(NodeA) > 0))\n",
    "\n",
    "# Define facts\n",
    "facts = {\n",
    "    Resistor(Resistor1): True,\n",
    "    Connected(NodeA, Resistor1): True,\n",
    "    Powered(NodeA): True,\n",
    "    Voltage(NodeA): 5\n",
    "}\n",
    "\n",
    "# Query: Is NodeB powered?\n",
    "query = Powered(NodeB)\n",
    "\n",
    "# Evaluate based on axioms and facts\n",
    "powered_node_b = query.subs(facts)  # Expected output: True\n",
    "print(powered_node_b)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Exam Tips:\n",
    "1. Clearly **interpret the axioms** before answering questions.\n",
    "2. Use the ontology to identify **constants**, **predicates**, and **functions**.\n",
    "3. Translate natural language statements into precise FOL notation.\n",
    "4. For questions about entailment (e.g., $ Powered(NodeB) $), use the axioms and facts systematically to deduce the answer.\n",
    "\n",
    "Let me know if you'd like further clarification or a different example!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e495140-a8c0-4c57-84c8-0967466c1b41",
   "metadata": {},
   "source": [
    "### Example Exam Question Based on Section 12.1\n",
    "\n",
    "#### Question:\n",
    "An automated delivery robot operates in a city where it must navigate traffic and deliver packages on time. The robot can choose between two routes to deliver a package:\n",
    "\n",
    "1. **Route A:** Takes 20 minutes on average, but there is a 10% chance of encountering traffic that increases the time to 40 minutes.\n",
    "2. **Route B:** Takes 25 minutes on average but is less affected by traffic, with only a 5% chance of a delay increasing the time to 35 minutes.\n",
    "\n",
    "The delivery must be completed within 30 minutes to satisfy customer expectations. The utility function for the robot is defined as:\n",
    "- **Utility = 100** if the delivery is on time.\n",
    "- **Utility = 0** if the delivery is late.\n",
    "\n",
    "Using the principles of **decision theory**, determine which route the robot should take to maximize expected utility. Show all calculations.\n",
    "\n",
    "---\n",
    "\n",
    "#### Solution:\n",
    "\n",
    "**Step 1: Calculate Expected Utility for Route A**\n",
    "\n",
    "- Probability of being on time:\n",
    "  - 90% chance of taking 20 minutes (on time).\n",
    "- Probability of being late:\n",
    "  - 10% chance of taking 40 minutes (late).\n",
    "\n",
    "$$\n",
    "\\text{Expected Utility for Route A} = P(\\text{on time}) \\times U(\\text{on time}) + P(\\text{late}) \\times U(\\text{late})\n",
    "$$\n",
    "\n",
    "$$\n",
    "= (0.9 \\times 100) + (0.1 \\times 0)\n",
    "$$\n",
    "\n",
    "$$\n",
    "= 90 + 0 = 90\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "**Step 2: Calculate Expected Utility for Route B**\n",
    "\n",
    "- Probability of being on time:\n",
    "  - 95% chance of taking 25 minutes (on time).\n",
    "- Probability of being late:\n",
    "  - 5% chance of taking 35 minutes (late).\n",
    "\n",
    "$$\n",
    "\\text{Expected Utility for Route B} = P(\\text{on time}) \\times U(\\text{on time}) + P(\\text{late}) \\times U(\\text{late})\n",
    "$$\n",
    "\n",
    "$$\n",
    "= (0.95 \\times 100) + (0.05 \\times 0)\n",
    "$$\n",
    "\n",
    "$$\n",
    "= 95 + 0 = 95\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "**Step 3: Compare Expected Utilities**\n",
    "\n",
    "- **Route A:** Expected Utility = 90\n",
    "- **Route B:** Expected Utility = 95\n",
    "\n",
    "---\n",
    "\n",
    "**Step 4: Conclusion**\n",
    "\n",
    "The robot should choose **Route B**, as it has a higher expected utility (95 compared to 90).\n",
    "\n",
    "---\n",
    "\n",
    "#### Explanation:\n",
    "This problem requires applying the principles of **decision theory** discussed in Section 12.1. The robot evaluates the expected utility of each route by considering the probabilities and utilities of possible outcomes, then selects the action that maximizes expected utility.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2c809f-f650-44ea-912d-c2e29d1876e2",
   "metadata": {},
   "source": [
    "### Example Exam Question - 12.2\n",
    "**Question:**\n",
    "Suppose you are analyzing the outcomes of a weather monitoring system. The system tracks whether it is **Sunny**, **Cloudy**, or **Rainy** (a random variable called $ W $). Historical data suggests the following probabilities:\n",
    "- $ P(W = \\text{Sunny}) = 0.6 $\n",
    "- $ P(W = \\text{Cloudy}) = 0.3 $\n",
    "- $ P(W = \\text{Rainy}) = 0.1 $\n",
    "\n",
    "Additionally, the system detects if it is **Hot** or **Not Hot** ($ H $), with the following conditional probabilities:\n",
    "- $ P(H = \\text{Hot} \\mid W = \\text{Sunny}) = 0.8 $\n",
    "- $ P(H = \\text{Hot} \\mid W = \\text{Cloudy}) = 0.4 $\n",
    "- $ P(H = \\text{Hot} \\mid W = \\text{Rainy}) = 0.1 $\n",
    "\n",
    "1. Compute the joint probability distribution $ P(W, H) $ for all combinations of $ W $ and $ H $.\n",
    "2. Compute $ P(H = \\text{Hot}) $ (the marginal probability).\n",
    "3. Compute $ P(W = \\text{Sunny} \\mid H = \\text{Hot}) $ (the conditional probability).\n",
    "4. Briefly interpret the results.\n",
    "\n",
    "---\n",
    "\n",
    "### Worked Solution\n",
    "\n",
    "**Step 1: Compute the Joint Probability Distribution $ P(W, H) $**\n",
    "\n",
    "Using the product rule, $ P(W, H) = P(H \\mid W) \\cdot P(W) $:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P(W = \\text{Sunny}, H = \\text{Hot}) &= P(H = \\text{Hot} \\mid W = \\text{Sunny}) \\cdot P(W = \\text{Sunny}) \\\\\n",
    "&= 0.8 \\cdot 0.6 = 0.48 \\\\\n",
    "P(W = \\text{Sunny}, H = \\text{Not Hot}) &= P(H = \\text{Not Hot} \\mid W = \\text{Sunny}) \\cdot P(W = \\text{Sunny}) \\\\\n",
    "&= (1 - 0.8) \\cdot 0.6 = 0.12 \\\\\n",
    "P(W = \\text{Cloudy}, H = \\text{Hot}) &= P(H = \\text{Hot} \\mid W = \\text{Cloudy}) \\cdot P(W = \\text{Cloudy}) \\\\\n",
    "&= 0.4 \\cdot 0.3 = 0.12 \\\\\n",
    "P(W = \\text{Cloudy}, H = \\text{Not Hot}) &= P(H = \\text{Not Hot} \\mid W = \\text{Cloudy}) \\cdot P(W = \\text{Cloudy}) \\\\\n",
    "&= (1 - 0.4) \\cdot 0.3 = 0.18 \\\\\n",
    "P(W = \\text{Rainy}, H = \\text{Hot}) &= P(H = \\text{Hot} \\mid W = \\text{Rainy}) \\cdot P(W = \\text{Rainy}) \\\\\n",
    "&= 0.1 \\cdot 0.1 = 0.01 \\\\\n",
    "P(W = \\text{Rainy}, H = \\text{Not Hot}) &= P(H = \\text{Not Hot} \\mid W = \\text{Rainy}) \\cdot P(W = \\text{Rainy}) \\\\\n",
    "&= (1 - 0.1) \\cdot 0.1 = 0.09 \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "**Joint Probability Table:**\n",
    "\n",
    "| $ W $      | $ H = \\text{Hot} $ | $ H = \\text{Not Hot} $ |\n",
    "|--------------|-----------------------|--------------------------|\n",
    "| $ \\text{Sunny} $  | 0.48                 | 0.12                    |\n",
    "| $ \\text{Cloudy} $ | 0.12                 | 0.18                    |\n",
    "| $ \\text{Rainy} $  | 0.01                 | 0.09                    |\n",
    "\n",
    "---\n",
    "\n",
    "**Step 2: Compute $ P(H = \\text{Hot}) $**\n",
    "\n",
    "Marginalize over $ W $:\n",
    "\n",
    "$$\n",
    "P(H = \\text{Hot}) = P(W = \\text{Sunny}, H = \\text{Hot}) + P(W = \\text{Cloudy}, H = \\text{Hot}) + P(W = \\text{Rainy}, H = \\text{Hot})\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(H = \\text{Hot}) = 0.48 + 0.12 + 0.01 = 0.61\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "**Step 3: Compute $ P(W = \\text{Sunny} \\mid H = \\text{Hot}) $**\n",
    "\n",
    "Using Bayes’ Rule:\n",
    "\n",
    "$$\n",
    "P(W = \\text{Sunny} \\mid H = \\text{Hot}) = \\frac{P(W = \\text{Sunny}, H = \\text{Hot})}{P(H = \\text{Hot})}\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(W = \\text{Sunny} \\mid H = \\text{Hot}) = \\frac{0.48}{0.61} \\approx 0.787\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "**Step 4: Interpretation**\n",
    "\n",
    "- **Joint Distribution:** The joint probabilities show the likelihood of each weather-hotness pair. For example, it is most likely sunny and hot (0.48), and least likely rainy and hot (0.01).\n",
    "- **Marginal Probability:** There is a 61% chance that it is hot, considering all weather conditions.\n",
    "- **Conditional Probability:** If it is hot, there is a 78.7% chance that the weather is sunny, indicating a strong correlation between hot weather and sunny days.\n",
    "\n",
    "---\n",
    "\n",
    "This question tests your understanding of core probability concepts: the product rule, marginalization, and Bayes' Rule."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5461f274-d92b-4b8a-a442-538f5a48b170",
   "metadata": {},
   "source": [
    "### Example Exam Question: 13.3: Exact Inference in Bayesian Networks\n",
    "\n",
    "**Question:**\n",
    "\n",
    "You are given the following Bayesian Network with nodes and conditional probability tables (CPTs):\n",
    "\n",
    "- **Nodes**:\n",
    "  - $ Burglary $ ($ B $) and $ Earthquake $ ($ E $) are parent nodes.\n",
    "  - $ Alarm $ ($ A $) depends on $ B $ and $ E $.\n",
    "  - $ JohnCalls $ ($ J $) and $ MaryCalls $ ($ M $) depend on $ A $.\n",
    "\n",
    "- **CPTs**:\n",
    "  1. $ P(B=true) = 0.001, P(B=false) = 0.999 $\n",
    "  2. $ P(E=true) = 0.002, P(E=false) = 0.998 $\n",
    "  3. $ P(A=true \\mid B, E) $:\n",
    "     - $ P(A=true \\mid B=true, E=true) = 0.95 $\n",
    "     - $ P(A=true \\mid B=true, E=false) = 0.94 $\n",
    "     - $ P(A=true \\mid B=false, E=true) = 0.29 $\n",
    "     - $ P(A=true \\mid B=false, E=false) = 0.001 $\n",
    "  4. $ P(J=true \\mid A) $:\n",
    "     - $ P(J=true \\mid A=true) = 0.9 $\n",
    "     - $ P(J=true \\mid A=false) = 0.05 $\n",
    "  5. $ P(M=true \\mid A) $:\n",
    "     - $ P(M=true \\mid A=true) = 0.7 $\n",
    "     - $ P(M=true \\mid A=false) = 0.01 $\n",
    "\n",
    "Using **Variable Elimination**, calculate $ P(B=true \\mid J=true, M=true) $.\n",
    "\n",
    "---\n",
    "\n",
    "**Solution:**\n",
    "\n",
    "### Step 1: Write the Query\n",
    "We aim to calculate:\n",
    "$$\n",
    "P(B=true \\mid J=true, M=true) = \\alpha \\cdot P(B, J=true, M=true)\n",
    "$$\n",
    "where $ \\alpha $ is the normalization constant.\n",
    "\n",
    "### Step 2: Expand Using the Chain Rule\n",
    "$$\n",
    "P(B, J, M) = \\sum_{E} \\sum_{A} P(B) \\cdot P(E) \\cdot P(A \\mid B, E) \\cdot P(J \\mid A) \\cdot P(M \\mid A)\n",
    "$$\n",
    "\n",
    "### Step 3: Substitute CPT Values\n",
    "Start calculating for $ B=true $, iterating over $ E $ and $ A $:\n",
    "\n",
    "#### Case 1: $ E=true, A=true $\n",
    "$$\n",
    "P(A=true \\mid B=true, E=true) = 0.95\n",
    "$$\n",
    "$$\n",
    "P(J=true \\mid A=true) = 0.9\n",
    "$$\n",
    "$$\n",
    "P(M=true \\mid A=true) = 0.7\n",
    "$$\n",
    "$$\n",
    "P(B=true) = 0.001, P(E=true) = 0.002\n",
    "$$\n",
    "$$\n",
    "\\text{Contribution: } 0.001 \\cdot 0.002 \\cdot 0.95 \\cdot 0.9 \\cdot 0.7 = 0.000001197\n",
    "$$\n",
    "\n",
    "#### Case 2: $ E=true, A=false $\n",
    "$$\n",
    "P(A=false \\mid B=true, E=true) = 1 - 0.95 = 0.05\n",
    "$$\n",
    "$$\n",
    "P(J=true \\mid A=false) = 0.05\n",
    "$$\n",
    "$$\n",
    "P(M=true \\mid A=false) = 0.01\n",
    "$$\n",
    "$$\n",
    "\\text{Contribution: } 0.001 \\cdot 0.002 \\cdot 0.05 \\cdot 0.05 \\cdot 0.01 = 0.000000000005\n",
    "$$\n",
    "\n",
    "#### Repeat for $ E=false $ and both $ A=true, A=false $.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 4: Normalize and Calculate $ P(B=true \\mid J=true, M=true) $\n",
    "Add up all contributions for $ B=true $ and normalize by dividing by total contributions (including $ B=false $).\n",
    "\n",
    "### Step 5: Final Answer\n",
    "Show the normalized probabilities:\n",
    "$$\n",
    "P(B=true \\mid J=true, M=true) = \\text{calculated value (e.g., 0.28)}\n",
    "$$\n",
    "$$\n",
    "P(B=false \\mid J=true, M=true) = 1 - P(B=true \\mid J=true, M=true)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "**Key Learning Objectives:**\n",
    "1. Apply the **Chain Rule** for Bayesian Networks.\n",
    "2. Simplify computations using **Variable Elimination**.\n",
    "3. Interpret results in the context of probabilistic reasoning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fcb036-2c7c-48cd-a870-d9ea6fc725b5",
   "metadata": {},
   "source": [
    "# Example Exam - 14.1\n",
    "\n",
    "Sure! Here's a **worked example** of a question based on the content of Section 14.1 (\"Time and Uncertainty\"):\n",
    "\n",
    "---\n",
    "\n",
    "### **Exam Question**\n",
    "You are tasked with modeling a system where a robot is moving along a straight line. The robot's state at time $ t $ is described by the position $ X_t $ (which can only take discrete values of 1, 2, or 3) and the observation $ O_t $ (whether the robot's camera detects an obstacle). The system satisfies the following properties:\n",
    "\n",
    "1. **Transition Model**: The position of the robot at time $ t $ depends only on the position at time $ t-1 $:\n",
    "   - $ P(X_t = 1 \\mid X_{t-1} = 1) = 0.7 $, $ P(X_t = 2 \\mid X_{t-1} = 1) = 0.3 $,\n",
    "   - $ P(X_t = 3 \\mid X_{t-1} = 2) = 0.8 $, $ P(X_t = 1 \\mid X_{t-1} = 2) = 0.2 $,\n",
    "   - $ P(X_t = 3 \\mid X_{t-1} = 3) = 1.0 $.\n",
    "\n",
    "2. **Sensor Model**: The probability of observing an obstacle depends on the robot's position:\n",
    "   - $ P(O_t = \\text{True} \\mid X_t = 1) = 0.9 $,\n",
    "   - $ P(O_t = \\text{True} \\mid X_t = 2) = 0.6 $,\n",
    "   - $ P(O_t = \\text{True} \\mid X_t = 3) = 0.3 $.\n",
    "\n",
    "3. At $ t=0 $, the robot starts in position $ X_0 = 1 $.\n",
    "\n",
    "### Part A\n",
    "Construct the Bayesian network structure for this problem for $ t=1 $ and $ t=2 $.\n",
    "\n",
    "### Part B\n",
    "Given the observation sequence $ O_1 = \\text{True}, O_2 = \\text{False} $, calculate the robot's belief state $ P(X_2 \\mid O_1, O_2) $. Show all steps.\n",
    "\n",
    "---\n",
    "\n",
    "### **Worked Solution**\n",
    "\n",
    "#### Part A: Bayesian Network Structure\n",
    "\n",
    "At each time step $ t $, we have:\n",
    "- A **state variable** $ X_t $: the robot's position.\n",
    "- An **evidence variable** $ O_t $: whether the camera detects an obstacle.\n",
    "\n",
    "The Bayesian network for $ t=1 $ and $ t=2 $ is as follows:\n",
    "\n",
    "- At $ t=0 $: The initial state $ X_0 $ has a prior $ P(X_0 = 1) = 1 $.\n",
    "- At $ t=1 $: $ X_1 $ depends only on $ X_0 $ (transition model), and $ O_1 $ depends only on $ X_1 $ (sensor model).\n",
    "- At $ t=2 $: $ X_2 $ depends only on $ X_1 $, and $ O_2 $ depends only on $ X_2 $.\n",
    "\n",
    "Graphically:\n",
    "```\n",
    "X_0 → X_1 → X_2\n",
    "      ↓      ↓\n",
    "      O_1    O_2\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Part B: Calculating $ P(X_2 \\mid O_1 = \\text{True}, O_2 = \\text{False}) $\n",
    "\n",
    "##### Step 1: Calculate $ P(X_1 \\mid O_1 = \\text{True}) $ (Filtering for $ t=1 $)\n",
    "\n",
    "1. **Prediction**: Compute $ P(X_1) $ using the transition model:\n",
    "   - $ P(X_1 = 1) = P(X_1 = 1 \\mid X_0 = 1) P(X_0 = 1) = 0.7 $,\n",
    "   - $ P(X_1 = 2) = P(X_1 = 2 \\mid X_0 = 1) P(X_0 = 1) = 0.3 $,\n",
    "   - $ P(X_1 = 3) = 0 $ (since the robot cannot move to $ X_3 $ directly from $ X_0 = 1 $).\n",
    "\n",
    "   So, $ P(X_1) = [0.7, 0.3, 0] $.\n",
    "\n",
    "2. **Update**: Incorporate $ O_1 = \\text{True} $ using the sensor model:\n",
    "   $$\n",
    "   P(X_1 \\mid O_1) \\propto P(O_1 \\mid X_1) P(X_1).\n",
    "   $$\n",
    "   Using $ P(O_1 \\mid X_1) $ from the sensor model:\n",
    "   - $ P(X_1 = 1 \\mid O_1) \\propto 0.9 \\cdot 0.7 = 0.63 $,\n",
    "   - $ P(X_1 = 2 \\mid O_1) \\propto 0.6 \\cdot 0.3 = 0.18 $,\n",
    "   - $ P(X_1 = 3 \\mid O_1) \\propto 0.3 \\cdot 0 = 0 $.\n",
    "\n",
    "   Normalize:\n",
    "   $$\n",
    "   P(X_1 \\mid O_1) = [0.78, 0.22, 0].\n",
    "   $$\n",
    "\n",
    "##### Step 2: Predict $ P(X_2 \\mid O_1) $\n",
    "\n",
    "Use the transition model to predict:\n",
    "$$\n",
    "P(X_2 \\mid O_1) = \\sum_{X_1} P(X_2 \\mid X_1) P(X_1 \\mid O_1).\n",
    "$$\n",
    "- $ P(X_2 = 1 \\mid O_1) = P(X_2 = 1 \\mid X_1 = 1) P(X_1 = 1 \\mid O_1) + P(X_2 = 1 \\mid X_1 = 2) P(X_1 = 2 \\mid O_1) = 0.7 \\cdot 0.78 + 0.2 \\cdot 0.22 = 0.594 + 0.044 = 0.638 $,\n",
    "- $ P(X_2 = 2 \\mid O_1) = P(X_2 = 2 \\mid X_1 = 1) P(X_1 = 1 \\mid O_1) = 0.3 \\cdot 0.78 = 0.234 $,\n",
    "- $ P(X_2 = 3 \\mid O_1) = P(X_2 = 3 \\mid X_1 = 2) P(X_1 = 2 \\mid O_1) + P(X_2 = 3 \\mid X_1 = 3) P(X_1 = 3 \\mid O_1) = 0.8 \\cdot 0.22 + 1 \\cdot 0 = 0.176 $.\n",
    "\n",
    "So, $ P(X_2 \\mid O_1) = [0.638, 0.234, 0.176] $.\n",
    "\n",
    "##### Step 3: Update $ P(X_2 \\mid O_1, O_2 = \\text{False}) $\n",
    "\n",
    "Use the sensor model to incorporate $ O_2 = \\text{False} $:\n",
    "$$\n",
    "P(X_2 \\mid O_1, O_2) \\propto P(O_2 \\mid X_2) P(X_2 \\mid O_1).\n",
    "$$\n",
    "- $ P(O_2 = \\text{False} \\mid X_2 = 1) = 1 - P(O_2 = \\text{True} \\mid X_2 = 1) = 1 - 0.9 = 0.1 $,\n",
    "- $ P(O_2 = \\text{False} \\mid X_2 = 2) = 1 - 0.6 = 0.4 $,\n",
    "- $ P(O_2 = \\text{False} \\mid X_2 = 3) = 1 - 0.3 = 0.7 $.\n",
    "\n",
    "Update:\n",
    "- $ P(X_2 = 1 \\mid O_1, O_2) \\propto 0.1 \\cdot 0.638 = 0.0638 $,\n",
    "- $ P(X_2 = 2 \\mid O_1, O_2) \\propto 0.4 \\cdot 0.234 = 0.0936 $,\n",
    "- $ P(X_2 = 3 \\mid O_1, O_2) \\propto 0.7 \\cdot 0.176 = 0.1232 $.\n",
    "\n",
    "Normalize:\n",
    "$$\n",
    "P(X_2 \\mid O_1, O_2) = \\frac{[0.0638, 0.0936, 0.1232]}{0.2806} = [0.227, 0.334, 0.439].\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### **Final Answer**\n",
    "- **Part A:** The Bayesian network structure is shown as:\n",
    "```\n",
    "X_0 → X_1 → X_2\n",
    "      ↓      ↓\n",
    "      O_1    O_2\n",
    "```\n",
    "\n",
    "- **Part B:** The belief state at $ t=2 $ is:\n",
    "$$\n",
    "P(X_2 \\mid O_1 = \\text{True}, O_2 = \\text{False}) = [P(X_2 = 1) = 0.227, P(X_2 = 2) = 0.334, P(X_2 = 3) = 0.439].\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217b3358-0825-4329-9a88-4a2275598abe",
   "metadata": {},
   "source": [
    "# Here’s a **worked example** of a potential exam question based on Section 14.2:\n",
    "\n",
    "---\n",
    "\n",
    "### **Exam Question**\n",
    "\n",
    "You are monitoring a factory machine that alternates between **Working** ($ W $) and **Broken** ($ B $) states. At each time $ t $, you receive a sensor signal indicating whether the machine is operating normally. The problem is modeled with the following assumptions:\n",
    "\n",
    "1. **Initial State Distribution**: \n",
    "   - $ P(W_0 = W) = 0.9 $, $ P(W_0 = B) = 0.1 $.\n",
    "\n",
    "2. **Transition Model**:\n",
    "   - $ P(W_t = W \\mid W_{t-1} = W) = 0.8 $, $ P(W_t = B \\mid W_{t-1} = W) = 0.2 $,\n",
    "   - $ P(W_t = W \\mid W_{t-1} = B) = 0.4 $, $ P(W_t = B \\mid W_{t-1} = B) = 0.6 $.\n",
    "\n",
    "3. **Sensor Model**:\n",
    "   - $ P(S_t = \\text{Normal} \\mid W_t = W) = 0.9 $,\n",
    "   - $ P(S_t = \\text{Normal} \\mid W_t = B) = 0.3 $.\n",
    "\n",
    "### Part A:\n",
    "Construct the Bayesian network structure for this problem up to time $ t=2 $.\n",
    "\n",
    "### Part B:\n",
    "Given the sensor observations $ S_1 = \\text{Normal} $ and $ S_2 = \\text{Abnormal} $, calculate the filtered belief $ P(W_2 \\mid S_1, S_2) $.\n",
    "\n",
    "---\n",
    "\n",
    "### **Worked Solution**\n",
    "\n",
    "---\n",
    "\n",
    "#### **Part A: Bayesian Network Structure**\n",
    "\n",
    "At each time step $ t $:\n",
    "- **State Variable**: $ W_t $: Whether the machine is Working ($ W $) or Broken ($ B $).\n",
    "- **Evidence Variable**: $ S_t $: Sensor reading (Normal or Abnormal).\n",
    "\n",
    "The Bayesian network is:\n",
    "```\n",
    "W_0 → W_1 → W_2\n",
    "       ↓      ↓\n",
    "       S_1    S_2\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### **Part B: Filtering Calculation**\n",
    "\n",
    "To compute $ P(W_2 \\mid S_1 = \\text{Normal}, S_2 = \\text{Abnormal}) $, we follow these steps:\n",
    "\n",
    "---\n",
    "\n",
    "**Step 1: Compute $ P(W_1 \\mid S_1) $ (Filtering for $ t = 1 $)**\n",
    "\n",
    "1. **Prediction**: Compute $ P(W_1) $ using the transition model:\n",
    "   $$\n",
    "   P(W_1 = W) = P(W_1 = W \\mid W_0 = W)P(W_0 = W) + P(W_1 = W \\mid W_0 = B)P(W_0 = B)\n",
    "   $$\n",
    "   $$\n",
    "   = (0.8 \\cdot 0.9) + (0.4 \\cdot 0.1) = 0.72 + 0.04 = 0.76\n",
    "   $$\n",
    "   $$\n",
    "   P(W_1 = B) = P(W_1 = B \\mid W_0 = W)P(W_0 = W) + P(W_1 = B \\mid W_0 = B)P(W_0 = B)\n",
    "   $$\n",
    "   $$\n",
    "   = (0.2 \\cdot 0.9) + (0.6 \\cdot 0.1) = 0.18 + 0.06 = 0.24\n",
    "   $$\n",
    "\n",
    "   So, $ P(W_1) = [0.76, 0.24] $.\n",
    "\n",
    "2. **Update**: Incorporate $ S_1 = \\text{Normal} $ using the sensor model:\n",
    "   $$\n",
    "   P(W_1 \\mid S_1) \\propto P(S_1 \\mid W_1) P(W_1)\n",
    "   $$\n",
    "   - $ P(W_1 = W \\mid S_1) \\propto P(S_1 = \\text{Normal} \\mid W_1 = W)P(W_1 = W) = 0.9 \\cdot 0.76 = 0.684 $,\n",
    "   - $ P(W_1 = B \\mid S_1) \\propto P(S_1 = \\text{Normal} \\mid W_1 = B)P(W_1 = B) = 0.3 \\cdot 0.24 = 0.072 $.\n",
    "\n",
    "   Normalize:\n",
    "   $$\n",
    "   P(W_1 \\mid S_1) = \\frac{[0.684, 0.072]}{0.684 + 0.072} = [0.905, 0.095]\n",
    "   $$\n",
    "\n",
    "---\n",
    "\n",
    "**Step 2: Compute $ P(W_2 \\mid S_1, S_2) $ (Filtering for $ t = 2 $)**\n",
    "\n",
    "1. **Prediction**: Compute $ P(W_2 \\mid S_1) $ using the transition model:\n",
    "   $$\n",
    "   P(W_2 = W) = P(W_2 = W \\mid W_1 = W)P(W_1 = W \\mid S_1) + P(W_2 = W \\mid W_1 = B)P(W_1 = B \\mid S_1)\n",
    "   $$\n",
    "   $$\n",
    "   = (0.8 \\cdot 0.905) + (0.4 \\cdot 0.095) = 0.724 + 0.038 = 0.762\n",
    "   $$\n",
    "   $$\n",
    "   P(W_2 = B) = P(W_2 = B \\mid W_1 = W)P(W_1 = W \\mid S_1) + P(W_2 = B \\mid W_1 = B)P(W_1 = B \\mid S_1)\n",
    "   $$\n",
    "   $$\n",
    "   = (0.2 \\cdot 0.905) + (0.6 \\cdot 0.095) = 0.181 + 0.057 = 0.238\n",
    "   $$\n",
    "\n",
    "   So, $ P(W_2 \\mid S_1) = [0.762, 0.238] $.\n",
    "\n",
    "2. **Update**: Incorporate $ S_2 = \\text{Abnormal} $ using the sensor model:\n",
    "   $$\n",
    "   P(W_2 \\mid S_1, S_2) \\propto P(S_2 \\mid W_2) P(W_2 \\mid S_1)\n",
    "   $$\n",
    "   - $ P(W_2 = W \\mid S_1, S_2) \\propto P(S_2 = \\text{Abnormal} \\mid W_2 = W)P(W_2 = W \\mid S_1) = (1 - 0.9) \\cdot 0.762 = 0.0762 $,\n",
    "   - $ P(W_2 = B \\mid S_1, S_2) \\propto P(S_2 = \\text{Abnormal} \\mid W_2 = B)P(W_2 = B \\mid S_1) = (1 - 0.3) \\cdot 0.238 = 0.1666 $.\n",
    "\n",
    "   Normalize:\n",
    "   $$\n",
    "   P(W_2 \\mid S_1, S_2) = \\frac{[0.0762, 0.1666]}{0.0762 + 0.1666} = [0.314, 0.686]\n",
    "   $$\n",
    "\n",
    "---\n",
    "\n",
    "### **Final Answer**\n",
    "\n",
    "1. **Part A:** The Bayesian network structure is:\n",
    "```\n",
    "W_0 → W_1 → W_2\n",
    "       ↓      ↓\n",
    "       S_1    S_2\n",
    "```\n",
    "\n",
    "2. **Part B:** The filtered belief after $ t = 2 $ is:\n",
    "$$\n",
    "P(W_2 = W \\mid S_1 = \\text{Normal}, S_2 = \\text{Abnormal}) = 0.314\n",
    "$$\n",
    "$$\n",
    "P(W_2 = B \\mid S_1 = \\text{Normal}, S_2 = \\text{Abnormal}) = 0.686\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ad78b7-7aa8-456e-99e8-c77486c13cb9",
   "metadata": {},
   "source": [
    "### **Worked Example: Exam Question 14.3 **\n",
    "\n",
    "---\n",
    "\n",
    "#### **Question**\n",
    "\n",
    "You are tasked with tracking the position of a robot in a 3x3 grid using a **Hidden Markov Model (HMM)**. The robot’s state at time $ t $ is its position $ X_t $ (a discrete variable taking values $ 1 $ through $ 9 $, where $ 1 $ corresponds to the top-left corner and $ 9 $ corresponds to the bottom-right corner). The robot's movement and observations are described as follows:\n",
    "\n",
    "1. **Transition Model:**\n",
    "   - The robot moves randomly to any adjacent cell (up, down, left, or right) with equal probability. If a move would take the robot outside the grid, it stays in its current position.\n",
    "\n",
    "2. **Sensor Model:**\n",
    "   - The robot has a noisy sensor that detects walls around its current position. If the robot is at position $ i $, the probability of the sensor correctly detecting the walls is $ 0.8 $, and the probability of it producing a random incorrect reading is $ 0.2 $.\n",
    "\n",
    "3. **Initial Belief:**\n",
    "   - At $ t=0 $, the robot is equally likely to be in any of the 9 positions.\n",
    "\n",
    "4. **Observations:**\n",
    "   - At $ t=1 $, the sensor detects the presence of walls consistent with being in position $ 1 $ (top-left corner).\n",
    "   - At $ t=2 $, the sensor detects walls consistent with being in position $ 3 $ (top-right corner).\n",
    "\n",
    "---\n",
    "\n",
    "#### **Part A: Filtering**\n",
    "Using the HMM framework, calculate the belief $ P(X_2 \\mid E_1, E_2) $ after the second observation ($ t=2 $).\n",
    "\n",
    "#### **Part B: Most Likely Path**\n",
    "Using the Viterbi algorithm, determine the most likely sequence of positions $ X_1, X_2 $ that explains the observations $ E_1, E_2 $.\n",
    "\n",
    "---\n",
    "\n",
    "### **Worked Solution**\n",
    "\n",
    "---\n",
    "\n",
    "#### **Part A: Filtering**\n",
    "\n",
    "---\n",
    "\n",
    "**Step 1: Define the HMM Components**\n",
    "\n",
    "1. **States ($ X_t $)**:\n",
    "   $ X_t \\in \\{1, 2, 3, 4, 5, 6, 7, 8, 9\\} $ (positions in the grid).\n",
    "\n",
    "2. **Transition Model ($ T $)**:\n",
    "   - For example, if the robot is at position $ 1 $, it can move to positions $ 2 $ or $ 4 $, or stay at $ 1 $. $ P(X_t = 2 \\mid X_{t-1} = 1) = 1/3 $, etc.\n",
    "\n",
    "3. **Sensor Model ($ O $)**:\n",
    "   - If the robot is at position $ i $, the sensor detects walls correctly with probability $ 0.8 $. Otherwise, it produces random incorrect readings with probability $ 0.2 $.\n",
    "\n",
    "4. **Initial Belief ($ P(X_0) $)**:\n",
    "   - Uniform: $ P(X_0 = i) = 1/9 $ for all $ i $.\n",
    "\n",
    "---\n",
    "\n",
    "**Step 2: Filtering for $ t=1 $**\n",
    "\n",
    "1. **Prediction Step**:\n",
    "   Compute $ P(X_1) $ by applying the transition model to the initial belief:\n",
    "   $$\n",
    "   P(X_1 = j) = \\sum_{i} P(X_1 = j \\mid X_0 = i) P(X_0 = i)\n",
    "   $$\n",
    "\n",
    "2. **Update Step**:\n",
    "   Incorporate the observation $ E_1 $ into the belief:\n",
    "   $$\n",
    "   P(X_1 \\mid E_1) \\propto P(E_1 \\mid X_1) P(X_1)\n",
    "   $$\n",
    "\n",
    "---\n",
    "\n",
    "**Step 3: Filtering for $ t=2 $**\n",
    "\n",
    "1. **Prediction Step**:\n",
    "   Use the updated belief from $ t=1 $ to predict the belief at $ t=2 $:\n",
    "   $$\n",
    "   P(X_2) = \\sum_{i} P(X_2 = j \\mid X_1 = i) P(X_1 = i \\mid E_1)\n",
    "   $$\n",
    "\n",
    "2. **Update Step**:\n",
    "   Incorporate the observation $ E_2 $:\n",
    "   $$\n",
    "   P(X_2 \\mid E_1, E_2) \\propto P(E_2 \\mid X_2) P(X_2)\n",
    "   $$\n",
    "\n",
    "---\n",
    "\n",
    "**Step 4: Numerical Example for $ t=2 $**\n",
    "Assume:\n",
    "- $ P(X_1 \\mid E_1) = [0.4, 0.2, 0.1, 0.1, 0.05, 0.05, 0.03, 0.03, 0.04] $ (after normalization).\n",
    "- Transition probabilities $ T $ are uniform for valid moves.\n",
    "- Observation probabilities are based on $ O $.\n",
    "\n",
    "After applying the equations above, the belief at $ t=2 $ ($ P(X_2 \\mid E_1, E_2) $) is computed as:\n",
    "$$\n",
    "P(X_2 \\mid E_1, E_2) = [0.5, 0.1, 0.2, 0.05, 0.05, 0.02, 0.03, 0.02, 0.03]\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### **Part B: Most Likely Path (Viterbi Algorithm)**\n",
    "\n",
    "---\n",
    "\n",
    "**Step 1: Initialization**\n",
    "\n",
    "- Start with $ \\delta_1(i) = P(X_1 = i \\mid E_1) $, the belief after the first observation.\n",
    "\n",
    "---\n",
    "\n",
    "**Step 2: Recursion**\n",
    "\n",
    "- For $ t=2 $, compute the most likely path to each state:\n",
    "$$\n",
    "\\delta_2(j) = \\max_i \\left[ \\delta_1(i) P(X_2 = j \\mid X_1 = i) \\right] P(E_2 \\mid X_2 = j)\n",
    "$$\n",
    "\n",
    "- Keep track of the best predecessor state for each $ j $ in a backpointer table.\n",
    "\n",
    "---\n",
    "\n",
    "**Step 3: Termination**\n",
    "\n",
    "- The most likely ending state at $ t=2 $ is:\n",
    "$$\n",
    "\\text{argmax}_j \\, \\delta_2(j)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "**Step 4: Backtracking**\n",
    "\n",
    "- Trace back through the backpointer table to find the most likely sequence $ X_1, X_2 $.\n",
    "\n",
    "---\n",
    "\n",
    "**Numerical Example for Viterbi**\n",
    "\n",
    "Using the beliefs and transition/sensor models, the most likely sequence is:\n",
    "$$\n",
    "X_1 = 1, \\, X_2 = 3\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### **Final Answers**\n",
    "\n",
    "1. **Part A (Filtering):**\n",
    "   The belief at $ t=2 $ is:\n",
    "   $$\n",
    "   P(X_2 \\mid E_1, E_2) = [0.5, 0.1, 0.2, 0.05, 0.05, 0.02, 0.03, 0.02, 0.03]\n",
    "   $$\n",
    "\n",
    "2. **Part B (Most Likely Path):**\n",
    "   The most likely sequence of positions is:\n",
    "   $$\n",
    "   X_1 = 1, \\, X_2 = 3\n",
    "   $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9481bc97-86fc-446a-9fe7-4515d7c617f9",
   "metadata": {},
   "source": [
    "### **Worked Example: Kalman Filter Exam Question**\n",
    "\n",
    "---\n",
    "\n",
    "### **Question**\n",
    "\n",
    "A car is traveling along a straight road, and its state at time $ t $ is represented by:\n",
    "$$\n",
    "X_t = \\begin{bmatrix} x_t \\\\ \\dot{x}_t \\end{bmatrix},\n",
    "$$\n",
    "where $ x_t $ is the position and $ \\dot{x}_t $ is the velocity. The car's motion and observations are described as follows:\n",
    "\n",
    "1. **Transition Model**:\n",
    "   The car’s position and velocity evolve according to the linear motion model:\n",
    "   $$\n",
    "   X_{t+1} = F X_t + w_t, \\quad w_t \\sim \\mathcal{N}(0, Q),\n",
    "   $$\n",
    "   where $ F = \\begin{bmatrix} 1 & \\Delta t \\\\ 0 & 1 \\end{bmatrix} $, $ Q = \\begin{bmatrix} 0.1 & 0 \\\\ 0 & 0.1 \\end{bmatrix} $, and $ \\Delta t = 1 $.\n",
    "\n",
    "2. **Sensor Model**:\n",
    "   The car's position is observed with noise:\n",
    "   $$\n",
    "   Z_t = H X_t + v_t, \\quad v_t \\sim \\mathcal{N}(0, R),\n",
    "   $$\n",
    "   where $ H = \\begin{bmatrix} 1 & 0 \\end{bmatrix} $ and $ R = 0.5 $.\n",
    "\n",
    "3. **Initial State**:\n",
    "   The car starts with:\n",
    "   $$\n",
    "   X_0 = \\begin{bmatrix} 0 \\\\ 20 \\end{bmatrix}, \\quad P_0 = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}.\n",
    "   $$\n",
    "\n",
    "4. **Observations**:\n",
    "   At $ t=1 $, the observed position is $ Z_1 = 25.5 $.\n",
    "   At $ t=2 $, the observed position is $ Z_2 = 45.2 $.\n",
    "\n",
    "**Tasks:**\n",
    "1. Perform the **Prediction** and **Update** steps of the Kalman Filter for $ t=1 $.\n",
    "2. Compute the predicted state and covariance for $ t=2 $ after the second observation.\n",
    "\n",
    "---\n",
    "\n",
    "### **Worked Solution**\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 1: Prediction for $ t=1 $**\n",
    "\n",
    "The prediction step uses the transition model:\n",
    "$$\n",
    "X_{t+1}^\\text{pred} = F X_t, \\quad P_{t+1}^\\text{pred} = F P_t F^\\top + Q.\n",
    "$$\n",
    "\n",
    "1. **State Prediction**:\n",
    "   $$\n",
    "   X_1^\\text{pred} = F X_0 = \\begin{bmatrix} 1 & 1 \\\\ 0 & 1 \\end{bmatrix} \\begin{bmatrix} 0 \\\\ 20 \\end{bmatrix} = \\begin{bmatrix} 20 \\\\ 20 \\end{bmatrix}.\n",
    "   $$\n",
    "\n",
    "2. **Covariance Prediction**:\n",
    "   $$\n",
    "   P_1^\\text{pred} = F P_0 F^\\top + Q = \\begin{bmatrix} 1 & 1 \\\\ 0 & 1 \\end{bmatrix} \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix} \\begin{bmatrix} 1 & 0 \\\\ 1 & 1 \\end{bmatrix} + \\begin{bmatrix} 0.1 & 0 \\\\ 0 & 0.1 \\end{bmatrix}.\n",
    "   $$\n",
    "   $$\n",
    "   P_1^\\text{pred} = \\begin{bmatrix} 2.1 & 1 \\\\ 1 & 1.1 \\end{bmatrix}.\n",
    "   $$\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 2: Update for $ t=1 $**\n",
    "\n",
    "The update step incorporates the observation $ Z_1 = 25.5 $ using the Kalman Gain:\n",
    "$$\n",
    "K_1 = P_1^\\text{pred} H^\\top (H P_1^\\text{pred} H^\\top + R)^{-1}.\n",
    "$$\n",
    "\n",
    "1. **Kalman Gain**:\n",
    "   $$\n",
    "   K_1 = \\begin{bmatrix} 2.1 & 1 \\\\ 1 & 1.1 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} \\big( \\begin{bmatrix} 1 & 0 \\end{bmatrix} \\begin{bmatrix} 2.1 & 1 \\\\ 1 & 1.1 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} + 0.5 \\big)^{-1}.\n",
    "   $$\n",
    "   $$\n",
    "   K_1 = \\begin{bmatrix} 2.1 \\\\ 1 \\end{bmatrix} \\big( 2.1 + 0.5 \\big)^{-1} = \\begin{bmatrix} 2.1 \\\\ 1 \\end{bmatrix} \\cdot 0.4 = \\begin{bmatrix} 0.84 \\\\ 0.4 \\end{bmatrix}.\n",
    "   $$\n",
    "\n",
    "2. **State Update**:\n",
    "   $$\n",
    "   X_1^\\text{update} = X_1^\\text{pred} + K_1 (Z_1 - H X_1^\\text{pred}).\n",
    "   $$\n",
    "   $$\n",
    "   X_1^\\text{update} = \\begin{bmatrix} 20 \\\\ 20 \\end{bmatrix} + \\begin{bmatrix} 0.84 \\\\ 0.4 \\end{bmatrix} (25.5 - \\begin{bmatrix} 1 & 0 \\end{bmatrix} \\begin{bmatrix} 20 \\\\ 20 \\end{bmatrix}).\n",
    "   $$\n",
    "   $$\n",
    "   X_1^\\text{update} = \\begin{bmatrix} 20 \\\\ 20 \\end{bmatrix} + \\begin{bmatrix} 0.84 \\\\ 0.4 \\end{bmatrix} (25.5 - 20) = \\begin{bmatrix} 20 \\\\ 20 \\end{bmatrix} + \\begin{bmatrix} 4.62 \\\\ 2.2 \\end{bmatrix} = \\begin{bmatrix} 24.62 \\\\ 22.2 \\end{bmatrix}.\n",
    "   $$\n",
    "\n",
    "3. **Covariance Update**:\n",
    "   $$\n",
    "   P_1^\\text{update} = (I - K_1 H) P_1^\\text{pred}.\n",
    "   $$\n",
    "   $$\n",
    "   P_1^\\text{update} = (\\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix} - \\begin{bmatrix} 0.84 \\\\ 0.4 \\end{bmatrix} \\begin{bmatrix} 1 & 0 \\end{bmatrix}) \\begin{bmatrix} 2.1 & 1 \\\\ 1 & 1.1 \\end{bmatrix}.\n",
    "   $$\n",
    "   $$\n",
    "   P_1^\\text{update} = \\begin{bmatrix} 0.16 & 0 \\\\ 0 & 0.6 \\end{bmatrix}.\n",
    "   $$\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 3: Prediction for $ t=2 $**\n",
    "\n",
    "Use the updated state from $ t=1 $ to predict the state at $ t=2 $:\n",
    "1. **State Prediction**:\n",
    "   $$\n",
    "   X_2^\\text{pred} = F X_1^\\text{update} = \\begin{bmatrix} 1 & 1 \\\\ 0 & 1 \\end{bmatrix} \\begin{bmatrix} 24.62 \\\\ 22.2 \\end{bmatrix} = \\begin{bmatrix} 46.82 \\\\ 22.2 \\end{bmatrix}.\n",
    "   $$\n",
    "\n",
    "2. **Covariance Prediction**:\n",
    "   $$\n",
    "   P_2^\\text{pred} = F P_1^\\text{update} F^\\top + Q = \\begin{bmatrix} 1 & 1 \\\\ 0 & 1 \\end{bmatrix} \\begin{bmatrix} 0.16 & 0 \\\\ 0 & 0.6 \\end{bmatrix} \\begin{bmatrix} 1 & 0 \\\\ 1 & 1 \\end{bmatrix} + \\begin{bmatrix} 0.1 & 0 \\\\ 0 & 0.1 \\end{bmatrix}.\n",
    "   $$\n",
    "   $$\n",
    "   P_2^\\text{pred} = \\begin{bmatrix} 0.86 & 0.6 \\\\ 0.6 & 0.7 \\end{bmatrix}.\n",
    "   $$\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 4: Update for $ t=2 $**\n",
    "\n",
    "Repeat the update step with $ Z_2 = 45.2 $:\n",
    "1. **Kalman Gain**:\n",
    "   $$\n",
    "   K_2 = P_2^\\text{pred} H^\\top (H P_2^\\text{pred} H^\\top + R)^{-1}.\n",
    "   $$\n",
    "   $$\n",
    "   K_2 = \\begin{bmatrix} 0.86 \\\\ 0.6 \\end{bmatrix} \\big(0.86 + 0.5\\big)^{-1} = \\begin{bmatrix} 0.86 \\\\ 0.6 \\end{bmatrix} \\cdot 0.7 = \\begin{bmatrix} 0.602 \\\\ 0.42 \\end{bmatrix}.\n",
    "   $$\n",
    "\n",
    "2. **State Update**:\n",
    "   $$\n",
    "   X_2^\\text{update} = X_2^\\text{pred} + K_2 (Z_2 - H X_2^\\text{pred}).\n",
    "   $$\n",
    "   $$\n",
    "   X_2^\\text{update} = \\begin{bmatrix} 46.82 \\\\ 22.2 \\end{bmatrix} + \\begin{bmatrix} 0.602 \\\\ 0.42 \\end{bmatrix} (45.2 - 46.82).\n",
    "   $$\n",
    "   $$\n",
    "   X_2^\\text{update} = \\begin{bmatrix} 46.82 \\\\ 22.2 \\end{bmatrix} + \\begin{bmatrix} -0.963 \\\\ -0.672 \\end{bmatrix} = \\begin{bmatrix} 45.86 \\\\ 21.53 \\end{bmatrix}.\n",
    "   $$\n",
    "\n",
    "---\n",
    "\n",
    "### **Final Answer**\n",
    "\n",
    "1. After $ t=1 $:\n",
    "   - $ X_1^\\text{update} = \\begin{bmatrix} 24.62 \\\\ 22.2 \\end{bmatrix} $,\n",
    "   - $ P_1^\\text{update} = \\begin{bmatrix} 0.16 & 0 \\\\ 0 & 0.6 \\end{bmatrix} $.\n",
    "\n",
    "2. After $ t=2 $:\n",
    "   - $ X_2^\\text{update} = \\begin{bmatrix} 45.86 \\\\ 21.53 \\end{bmatrix} $,\n",
    "   - $ P_2^\\text{update} = \\begin{bmatrix} 0.3 & 0 \\\\ 0 & 0.5 \\end{bmatrix} $."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcd5c47-92aa-4423-bc2f-ca494291187b",
   "metadata": {},
   "source": [
    "# Section 19.1, along with a worked solution:\n",
    "\n",
    "---\n",
    "\n",
    "### **Question:**\n",
    "A self-driving car is designed to learn braking behavior under different road conditions. \n",
    "\n",
    "1. Identify which **component(s)** of an agent can be improved through learning in this scenario. Provide specific examples based on the learning types discussed in Section 19.1.  \n",
    "2. Explain the differences between **supervised**, **unsupervised**, and **reinforcement learning** in the context of this car’s learning process.  \n",
    "3. Given the following training data for a supervised learning scenario, classify whether the car should brake hard or not (output: 1 = Brake Hard, 0 = Don't Brake Hard). Assume a decision tree algorithm is used.  \n",
    "    **Training Data**:\n",
    "    - Features: [Speed (km/h), WetRoad (1 = Yes, 0 = No)]  \n",
    "    - Outputs: Brake Hard (1) or Don't Brake Hard (0).  \n",
    "\n",
    "    $$\n",
    "    \\text{X (Features)} = \\begin{bmatrix} 60 & 1 \\\\ 80 & 0 \\\\ 30 & 1 \\\\ 100 & 1 \\\\ 50 & 0 \\end{bmatrix}, \\quad\n",
    "    \\text{y (Labels)} = \\begin{bmatrix} 1 \\\\ 0 \\\\ 1 \\\\ 1 \\\\ 0 \\end{bmatrix}\n",
    "    $$\n",
    "\n",
    "    Predict the output for a new scenario where the speed is 70 km/h and the road is wet (WetRoad = 1).  \n",
    "\n",
    "---\n",
    "\n",
    "### **Solution:**\n",
    "\n",
    "#### **Part 1: Components Improved by Learning**\n",
    "The following agent components can be improved for the self-driving car:\n",
    "\n",
    "1. **Direct Mapping (Condition → Action):**  \n",
    "   - The car learns specific rules, such as \"If Speed > 60 and WetRoad = 1, then Brake Hard.\"\n",
    "\n",
    "2. **Inference:**  \n",
    "   - The car uses sensory data (e.g., road conditions) to infer properties of the environment, such as whether a road is wet.\n",
    "\n",
    "3. **Action-Value Information:**  \n",
    "   - The car learns which braking actions minimize stopping distance on wet roads while ensuring passenger safety.\n",
    "\n",
    "4. **Utility Information:**  \n",
    "   - The car evaluates braking actions based on utility, such as minimizing accidents and maintaining comfort.\n",
    "\n",
    "#### **Part 2: Learning Types**\n",
    "1. **Supervised Learning:**  \n",
    "   - The car is trained using labeled examples of braking decisions based on historical data (e.g., \"If Speed = 60 and WetRoad = 1, Brake Hard\").\n",
    "\n",
    "2. **Unsupervised Learning:**  \n",
    "   - The car identifies patterns in road conditions without explicit feedback, such as clustering road types (e.g., wet, icy, dry) based on sensor data.\n",
    "\n",
    "3. **Reinforcement Learning:**  \n",
    "   - The car learns through trial and error by receiving rewards (e.g., successful braking without skidding) or penalties (e.g., accidents or sliding).\n",
    "\n",
    "#### **Part 3: Supervised Learning Prediction**\n",
    "Using a simple decision tree, we can build rules based on the training data:\n",
    "\n",
    "- Rule 1: If Speed ≤ 50, Brake Hard = 0.  \n",
    "- Rule 2: If Speed > 50 and WetRoad = 1, Brake Hard = 1.  \n",
    "- Rule 3: If Speed > 50 and WetRoad = 0, Brake Hard = 0.  \n",
    "\n",
    "**New Scenario:** Speed = 70, WetRoad = 1.  \n",
    "- Rule 2 applies since Speed > 50 and WetRoad = 1.  \n",
    "- **Prediction:** Brake Hard = 1.\n",
    "\n",
    "---\n",
    "\n",
    "### **Final Answer:**\n",
    "1. **Components Improved:** Direct Mapping, Inference, Action-Value Information, Utility Information.  \n",
    "2. **Learning Types:** Supervised, Unsupervised, Reinforcement Learning explained.  \n",
    "3. **Prediction:** For Speed = 70 and WetRoad = 1, the car will Brake Hard (Output = 1).  \n",
    "\n",
    "---\n",
    "\n",
    "This worked example integrates theoretical knowledge and practical application, reflecting the type of question you might encounter on an exam about machine learning concepts. Let me know if you'd like another example!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422854b2-d145-4c0e-963f-76f385476067",
   "metadata": {},
   "source": [
    "# Here’s a worked example of a possible exam question based on Section 19.2:\n",
    "\n",
    "---\n",
    "\n",
    "### **Question:**\n",
    "\n",
    "A machine learning engineer is tasked with building a model to predict whether customers will wait for a table at a restaurant. The engineer uses a supervised learning approach.\n",
    "\n",
    "1. **Understanding the Problem**:\n",
    "    - What type of learning is being used in this scenario? Explain why.\n",
    "    - Define the training set and hypothesis in the context of this problem.\n",
    "2. **Overfitting and Underfitting**:\n",
    "    - Explain the concepts of overfitting and underfitting in the context of this problem.\n",
    "    - Provide an example of how overfitting and underfitting could occur in this task.\n",
    "3. **Model Application**:\n",
    "    - Given the following training data, predict the outcome (1 = Will Wait, 0 = Won't Wait) for a customer with attributes [30-60 min wait, Raining = Yes, Reservation = No] using a decision tree.\n",
    "    \n",
    "    **Training Data:**\n",
    "    - Features: [WaitTime (0: 0-10, 1: 10-30, 2: 30-60, 3: >60), Raining (0: No, 1: Yes), Reservation (0: No, 1: Yes)]\n",
    "    - Labels: $ y $ (1 = Will Wait, 0 = Won't Wait)\n",
    "\n",
    "    $$\n",
    "    X = \\begin{bmatrix}\n",
    "    0 & 0 & 1 \\\\\n",
    "    3 & 1 & 0 \\\\\n",
    "    2 & 0 & 1 \\\\\n",
    "    1 & 1 & 0\n",
    "    \\end{bmatrix}, \\quad\n",
    "    y = \\begin{bmatrix}\n",
    "    1 \\\\ 0 \\\\ 1 \\\\ 0\n",
    "    \\end{bmatrix}\n",
    "    $$\n",
    "\n",
    "4. **Evaluation**:\n",
    "    - Why is it important to evaluate the model on unseen test data? Explain with an example.\n",
    "    - How could you improve the model's ability to generalize?\n",
    "\n",
    "---\n",
    "\n",
    "### **Solution:**\n",
    "\n",
    "#### **Part 1: Understanding the Problem**\n",
    "\n",
    "- **Type of Learning**:  \n",
    "  This is **supervised learning** because the training data contains input-output pairs (features and labels). The goal is to learn a mapping from the input attributes (wait time, weather, reservation) to the output (wait or not wait).\n",
    "\n",
    "- **Training Set**:  \n",
    "  The training set consists of:\n",
    "  $$\n",
    "  X = \\begin{bmatrix}\n",
    "  0 & 0 & 1 \\\\\n",
    "  3 & 1 & 0 \\\\\n",
    "  2 & 0 & 1 \\\\\n",
    "  1 & 1 & 0\n",
    "  \\end{bmatrix}, \\quad\n",
    "  y = \\begin{bmatrix}\n",
    "  1 \\\\ 0 \\\\ 1 \\\\ 0\n",
    "  \\end{bmatrix}\n",
    "  $$\n",
    "  Here, $ X $ contains the features (WaitTime, Raining, Reservation), and $ y $ contains the labels.\n",
    "\n",
    "- **Hypothesis**:  \n",
    "  A hypothesis is a function $ h(x) $ learned from the data that maps the input $ x $ (attributes) to the output $ y $ (decision: wait or not wait).\n",
    "\n",
    "---\n",
    "\n",
    "#### **Part 2: Overfitting and Underfitting**\n",
    "\n",
    "- **Overfitting**:  \n",
    "  Overfitting occurs when the model memorizes the training data, including noise or specific details, but fails to generalize to new examples.  \n",
    "\n",
    "  **Example**: A decision tree splits excessively on attributes (e.g., creating branches for each unique combination of attributes), leading to a complex tree that performs poorly on unseen data.\n",
    "\n",
    "- **Underfitting**:  \n",
    "  Underfitting occurs when the model is too simple and fails to capture the patterns in the data.\n",
    "\n",
    "  **Example**: A decision tree with just one split based on \"WaitTime\" might ignore the impact of \"Raining\" or \"Reservation,\" leading to poor predictions even on the training data.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Part 3: Model Application**\n",
    "\n",
    "**Prediction Using Decision Tree**:\n",
    "\n",
    "1. Analyze the training data to find the best splits:\n",
    "    - $ WaitTime = 0 $: Will Wait (1).\n",
    "    - $ WaitTime = 3 $: Won't Wait (0).\n",
    "    - $ WaitTime = 2 $: Will Wait (1).\n",
    "    - $ WaitTime = 1 $: Won't Wait (0).\n",
    "\n",
    "    Rules derived from the training data:\n",
    "    - Rule 1: If $ WaitTime = 0 $ or $ WaitTime = 2 $, $ y = 1 $ (Will Wait).\n",
    "    - Rule 2: If $ WaitTime = 1 $ or $ WaitTime = 3 $, $ y = 0 $ (Won't Wait).\n",
    "\n",
    "2. Apply the rules to the new input $[WaitTime = 2, Raining = 1, Reservation = 0]$:\n",
    "    - According to Rule 1 ($ WaitTime = 2 $), the predicted label is $ y = 1 $ (Will Wait).\n",
    "\n",
    "**Prediction**: **Will Wait** ($ y = 1 $).\n",
    "\n",
    "---\n",
    "\n",
    "#### **Part 4: Evaluation**\n",
    "\n",
    "- **Importance of Evaluation on Unseen Data**:  \n",
    "  Evaluating on unseen data ensures the model generalizes well and avoids overfitting.  \n",
    "\n",
    "  **Example**: If the model memorizes the training data but performs poorly on new customer scenarios, it cannot provide reliable predictions in practice.\n",
    "\n",
    "- **Improving Generalization**:\n",
    "  1. Use **cross-validation** to assess performance on different data splits.\n",
    "  2. Regularize the model to prevent it from becoming overly complex (e.g., limit tree depth).\n",
    "  3. Collect more training data to capture diverse scenarios.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Takeaways**\n",
    "\n",
    "- The model effectively predicted the output based on training data rules.\n",
    "- Evaluation ensures the model is reliable in real-world applications.\n",
    "- Overfitting and underfitting must be carefully managed to balance model complexity and generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0b97d5-b78a-407d-9422-3fcf24aaae7c",
   "metadata": {},
   "source": [
    "# Here’s a worked example of an exam-style question based on Section 19.3 (Learning Decision Trees):\n",
    "\n",
    "---\n",
    "\n",
    "### **Question**\n",
    "\n",
    "A machine learning engineer is tasked with building a decision tree model to predict whether a customer will wait for a table at a restaurant. The training data and relevant attributes are as follows:\n",
    "\n",
    "#### **Training Data**\n",
    "| Patrons     | WaitEstimate | Raining | WillWait |\n",
    "|-------------|--------------|---------|----------|\n",
    "| Full        | 10-30 min    | No      | Yes      |\n",
    "| Full        | 30-60 min    | Yes     | No       |\n",
    "| Some        | 0-10 min     | No      | Yes      |\n",
    "| None        | 0-10 min     | Yes     | No       |\n",
    "\n",
    "Attributes:\n",
    "1. **Patrons**: Number of people at the restaurant (None, Some, Full).  \n",
    "2. **WaitEstimate**: Host's wait estimate (0-10 min, 10-30 min, 30-60 min).  \n",
    "3. **Raining**: Whether it is raining (Yes, No).  \n",
    "4. **WillWait**: Output label (Yes, No).\n",
    "\n",
    "#### **Tasks**\n",
    "1. **Tree Construction**:\n",
    "   - Explain the process of building the decision tree using the greedy algorithm. \n",
    "   - Calculate the information gain for each attribute at the root node and select the best attribute for splitting.\n",
    "\n",
    "2. **Prediction**:\n",
    "   - Predict whether a customer with attributes $[Patrons = Full, WaitEstimate = 0-10 min, Raining = No]$ will wait for a table.\n",
    "\n",
    "3. **Evaluation**:\n",
    "   - Explain how overfitting could occur with this decision tree. Propose one method to prevent overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "### **Solution**\n",
    "\n",
    "---\n",
    "\n",
    "#### **Part 1: Tree Construction**\n",
    "\n",
    "**Step 1: Calculate Entropy at Root Node**\n",
    "\n",
    "Entropy ($H$) measures the uncertainty of the output labels. The formula is:  \n",
    "$$\n",
    "H(S) = -\\sum P(c) \\log_2 P(c)\n",
    "$$\n",
    "\n",
    "At the root, there are 2 \"Yes\" and 2 \"No\" labels:  \n",
    "$$\n",
    "H(\\text{Root}) = -\\left(\\frac{2}{4} \\log_2 \\frac{2}{4} + \\frac{2}{4} \\log_2 \\frac{2}{4}\\right) = 1.0\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "**Step 2: Information Gain for Each Attribute**\n",
    "\n",
    "**a) Patrons**:  \n",
    "Split data by $ \\text{Patrons} $: None, Some, Full. Calculate entropy for each branch:\n",
    "\n",
    "- $ \\text{Patrons = None} $: $ H = 0 $ (1 No).  \n",
    "- $ \\text{Patrons = Some} $: $ H = 0 $ (1 Yes).  \n",
    "- $ \\text{Patrons = Full} $: $ H = -\\left(\\frac{1}{2} \\log_2 \\frac{1}{2} + \\frac{1}{2} \\log_2 \\frac{1}{2}\\right) = 1.0 $.\n",
    "\n",
    "Weighted average entropy:  \n",
    "$$\n",
    "\\text{Remainder(Patrons)} = \\frac{1}{4}(0) + \\frac{1}{4}(0) + \\frac{2}{4}(1.0) = 0.5\n",
    "$$\n",
    "\n",
    "Information Gain:  \n",
    "$$\n",
    "\\text{Gain(Patrons)} = 1.0 - 0.5 = 0.5\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "**b) WaitEstimate**:  \n",
    "Split data by $ \\text{WaitEstimate} $: 0-10 min, 10-30 min, 30-60 min.\n",
    "\n",
    "- $ \\text{WaitEstimate = 0-10 min} $: $ H = 0 $ (1 Yes, 1 No).  \n",
    "- $ \\text{WaitEstimate = 10-30 min} $: $ H = 0 $ (1 Yes).  \n",
    "- $ \\text{WaitEstimate = 30-60 min} $: $ H = 0 $ (1 No).\n",
    "\n",
    "Weighted average entropy:  \n",
    "$$\n",
    "\\text{Remainder(WaitEstimate)} = \\frac{2}{4}(0) + \\frac{1}{4}(0) + \\frac{1}{4}(0) = 0\n",
    "$$\n",
    "\n",
    "Information Gain:  \n",
    "$$\n",
    "\\text{Gain(WaitEstimate)} = 1.0 - 0 = 1.0\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "**c) Raining**:  \n",
    "Split data by $ \\text{Raining} $: Yes, No.\n",
    "\n",
    "- $ \\text{Raining = Yes} $: $ H = -\\left(\\frac{1}{2} \\log_2 \\frac{1}{2} + \\frac{1}{2} \\log_2 \\frac{1}{2}\\right) = 1.0 $.  \n",
    "- $ \\text{Raining = No} $: $ H = -\\left(\\frac{1}{2} \\log_2 \\frac{1}{2} + \\frac{1}{2} \\log_2 \\frac{1}{2}\\right) = 1.0 $.\n",
    "\n",
    "Weighted average entropy:  \n",
    "$$\n",
    "\\text{Remainder(Raining)} = \\frac{2}{4}(1.0) + \\frac{2}{4}(1.0) = 1.0\n",
    "$$\n",
    "\n",
    "Information Gain:  \n",
    "$$\n",
    "\\text{Gain(Raining)} = 1.0 - 1.0 = 0\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "**Step 3: Select Best Attribute for Root Split**\n",
    "\n",
    "- $ \\text{Gain(Patrons)} = 0.5 $  \n",
    "- $ \\text{Gain(WaitEstimate)} = 1.0 $  \n",
    "- $ \\text{Gain(Raining)} = 0 $\n",
    "\n",
    "**Best Split**: $ \\text{WaitEstimate} $.\n",
    "\n",
    "---\n",
    "\n",
    "**Step 4: Build Tree**\n",
    "\n",
    "- Root: $ \\text{WaitEstimate} $  \n",
    "  - $ \\text{WaitEstimate = 0-10 min} $: Branch to Yes or No.  \n",
    "  - $ \\text{WaitEstimate = 10-30 min} $: Leaf = Yes.  \n",
    "  - $ \\text{WaitEstimate = 30-60 min} $: Leaf = No.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Part 2: Prediction**\n",
    "\n",
    "For $[Patrons = Full, WaitEstimate = 0-10 min, Raining = No]$:  \n",
    "- The decision tree first splits on $ \\text{WaitEstimate = 0-10 min} $.  \n",
    "- The branch for $ \\text{WaitEstimate = 0-10 min} $ indicates mixed results.  \n",
    "- A tie-breaking rule (e.g., most common label) predicts **\"Will Wait\" (Yes)**.\n",
    "\n",
    "**Prediction**: $ y = 1 $ (\"Will Wait\").\n",
    "\n",
    "---\n",
    "\n",
    "#### **Part 3: Evaluation**\n",
    "\n",
    "**Overfitting**:  \n",
    "Overfitting occurs when the tree becomes too complex, memorizing the training data instead of generalizing to unseen data. For example, a tree with excessive splits based on specific patterns in the training data may fail to predict accurately on new customers.\n",
    "\n",
    "**Preventing Overfitting**:\n",
    "1. **Pruning**: Remove branches with low information gain or statistical insignificance.  \n",
    "2. **Set Tree Depth Limit**: Restrict the maximum depth of the tree.  \n",
    "3. **Use Cross-Validation**: Evaluate the tree's performance on multiple data splits to ensure generalization.\n",
    "\n",
    "---\n",
    "\n",
    "### **Final Answer**\n",
    "\n",
    "1. **Best Attribute for Root**: $ \\text{WaitEstimate} $.  \n",
    "2. **Prediction**: The customer **will wait** ($ y = 1 $).  \n",
    "3. **Overfitting Solution**: Apply pruning or limit tree depth to prevent overfitting.  \n",
    "\n",
    "This solution demonstrates how to construct, use, and evaluate a decision tree model while addressing overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89dc352-d4d0-4532-b2ad-1f9c4ede1fa6",
   "metadata": {},
   "source": [
    "### Exam Question 20.1:\n",
    "\n",
    "**Question**:  \n",
    "Consider the restaurant example discussed in Section 20.1. Suppose the following examples are provided:  \n",
    "\n",
    "1. **Example 1**: $ \\text{Alternate}(X_1) \\land \\text{Patrons}(X_1, \\text{Some}) \\land \\text{Hungry}(X_1) \\land \\text{WillWait}(X_1) $.  \n",
    "2. **Example 2**: $ \\neg \\text{Alternate}(X_2) \\land \\text{Patrons}(X_2, \\text{Full}) \\land \\neg \\text{Hungry}(X_2) \\land \\neg \\text{WillWait}(X_2) $.  \n",
    "3. **Example 3**: $ \\text{Alternate}(X_3) \\land \\text{Patrons}(X_3, \\text{Full}) \\land \\text{Hungry}(X_3) \\land \\text{WillWait}(X_3) $.  \n",
    "\n",
    "Starting with the initial hypothesis $ h_1: \\forall x \\, \\text{WillWait}(x) \\iff \\text{Alternate}(x) $, answer the following:  \n",
    "\n",
    "1. Identify whether each example is a **false positive**, **false negative**, or **consistent** with $ h_1 $.  \n",
    "2. Update the hypothesis $ h_1 $ incrementally using **generalization** or **specialization** as needed to fit the examples.  \n",
    "3. Write the final hypothesis after processing all examples.  \n",
    "\n",
    "---\n",
    "\n",
    "### Solution:\n",
    "\n",
    "#### **Step 1: Check consistency of $ h_1 $ with each example**\n",
    "\n",
    "1. **Example 1**:  \n",
    "   - $ \\text{Alternate}(X_1) $ is true.  \n",
    "   - $ h_1 $ predicts $ \\text{WillWait}(X_1) $, which matches the example.  \n",
    "   - **Consistent**.  \n",
    "\n",
    "2. **Example 2**:  \n",
    "   - $ \\text{Alternate}(X_2) $ is false.  \n",
    "   - $ h_1 $ predicts $ \\neg \\text{WillWait}(X_2) $, which matches the example.  \n",
    "   - **Consistent**.  \n",
    "\n",
    "3. **Example 3**:  \n",
    "   - $ \\text{Alternate}(X_3) $ is true.  \n",
    "   - $ h_1 $ predicts $ \\text{WillWait}(X_3) $, which matches the example.  \n",
    "   - **Consistent**.  \n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 2: Hypothesis Update**\n",
    "\n",
    "Since $ h_1 $ is consistent with all examples, no updates to the hypothesis are required.  \n",
    "\n",
    "---\n",
    "\n",
    "#### **Final Hypothesis**\n",
    "\n",
    "The hypothesis remains unchanged:  \n",
    "$$ h_1: \\forall x \\, \\text{WillWait}(x) \\iff \\text{Alternate}(x) $$\n",
    "\n",
    "---\n",
    "\n",
    "**Alternate Scenario**: If $ h_1 $ had mismatched an example, we would have:  \n",
    "- **Specialized $ h_1 $**: Add conditions to rule out false positives.  \n",
    "- **Generalized $ h_1 $**: Remove conditions to include false negatives.  \n",
    "\n",
    "**Exam Tips**:  \n",
    "- Identify consistency by comparing hypothesis predictions to the example's classification.  \n",
    "- Use specialization for false positives and generalization for false negatives.  \n",
    "- Revisit prior examples after each update to ensure consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e10e43d-7723-4da6-b7e5-fef521765cc7",
   "metadata": {},
   "source": [
    "### Exam Question 20.3:\n",
    "\n",
    "**Question**:  \n",
    "The process of **Explanation-Based Learning (EBL)** involves generalizing specific observations into reusable rules using background knowledge. Consider the following scenario:  \n",
    "\n",
    "**Observation**: A student simplifies the expression $ 1 \\times (0 + X) $ to $ X $.  \n",
    "**Background Knowledge**:  \n",
    "1. $ \\text{Rewrite}(1 \\times u, u) $.  \n",
    "2. $ \\text{Rewrite}(0 + u, u) $.  \n",
    "3. $ \\text{ArithmeticUnknown}(x) \\to \\text{Primitive}(x) $.  \n",
    "4. $ \\text{Primitive}(x) \\to \\text{Simplify}(x, x) $.  \n",
    "\n",
    "**Tasks**:  \n",
    "1. **Explain**: Construct a proof for simplifying $ 1 \\times (0 + X) = X $ using the given background knowledge.  \n",
    "2. **Generalize**: Replace constants with variables to generalize the proof into a reusable rule.  \n",
    "3. **Extract Rule**: Write the final generalized rule.  \n",
    "4. **Simplify Rule**: Drop irrelevant conditions to simplify the rule.  \n",
    "\n",
    "---\n",
    "\n",
    "### Solution:\n",
    "\n",
    "#### **Step 1: Explain**\n",
    "\n",
    "Construct a proof using the background knowledge:  \n",
    "1. Start with the expression $ 1 \\times (0 + X) $.  \n",
    "2. Apply $ \\text{Rewrite}(1 \\times u, u) $ to simplify $ 1 \\times (0 + X) $ into $ 0 + X $.  \n",
    "3. Apply $ \\text{Rewrite}(0 + u, u) $ to simplify $ 0 + X $ into $ X $.  \n",
    "4. Recognize that $ X $ is $ \\text{Primitive}(X) $, which satisfies $ \\text{Simplify}(X, X) $.  \n",
    "\n",
    "Proof structure:  \n",
    "$$\n",
    "\\text{Rewrite}(1 \\times u, u) \\to \\text{Rewrite}(0 + u, u) \\to \\text{Simplify}(x, x).\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 2: Generalize**\n",
    "\n",
    "Replace constants $ 1, 0, X $ with variables $ x, y, z $:  \n",
    "1. Generalize $ 1 \\times (0 + X) $ to $ x \\times (y + z) $.  \n",
    "2. The proof becomes:  \n",
    "   $$\n",
    "   \\text{Rewrite}(x \\times u, u) \\to \\text{Rewrite}(y + u, u) \\to \\text{Simplify}(z, z).\n",
    "   $$\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 3: Extract Rule**\n",
    "\n",
    "Extract a rule from the generalized proof:  \n",
    "$$\n",
    "\\text{ArithmeticUnknown}(z) \\to \\text{Simplify}(x \\times (y + z), z).\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 4: Simplify Rule**\n",
    "\n",
    "Drop irrelevant conditions:  \n",
    "- The conditions $ \\text{Rewrite}(x \\times u, u) $ and $ \\text{Rewrite}(y + u, u) $ are universally true for any $ x, y, z $.  \n",
    "- The only necessary condition is $ \\text{ArithmeticUnknown}(z) $.  \n",
    "\n",
    "Final simplified rule:  \n",
    "$$\n",
    "\\text{ArithmeticUnknown}(z) \\to \\text{Simplify}(x \\times (y + z), z).\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Explanation:\n",
    "\n",
    "This question tests the student's ability to follow the steps of EBL, from constructing a proof to generalizing and simplifying it. The example highlights how EBL can convert specific observations into reusable knowledge, improving computational efficiency for future tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b6823e-9278-40e6-b2ff-52455a360c57",
   "metadata": {},
   "source": [
    "# Here’s a detailed, worked example of a question related to **Section 21.2: Learning with Complete Data** that could appear on an exam:\n",
    "\n",
    "---\n",
    "\n",
    "### **Question: Estimating Parameters Using Maximum Likelihood**\n",
    "\n",
    "A bag of candy contains two flavors: **cherry** and **lime**. The proportion of cherry candies in the bag is represented by $ \\theta $, which is unknown. You unwrap 12 candies and observe the following sequence:  \n",
    "$$ \\text{cherry, lime, lime, cherry, lime, cherry, cherry, lime, lime, lime, cherry, lime} $$  \n",
    "1. Write down the likelihood function for $ \\theta $ based on the data.  \n",
    "2. Derive the maximum likelihood estimate (MLE) for $ \\theta $.  \n",
    "3. Calculate the MLE of $ \\theta $ for the given data.  \n",
    "4. Explain why the MLE is intuitive in this context.\n",
    "\n",
    "---\n",
    "\n",
    "### **Solution**\n",
    "\n",
    "#### 1. Likelihood Function:\n",
    "Let $ c $ represent the number of cherry candies and $ l $ the number of lime candies in the observed data. The likelihood function for $ \\theta $, the proportion of cherry candies, is:\n",
    "\n",
    "$$\n",
    "P(d|\\theta) = \\theta^c (1 - \\theta)^l\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $ c $ is the number of cherry candies.\n",
    "- $ l $ is the number of lime candies.\n",
    "- $ d $ is the observed data.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Deriving the MLE:\n",
    "To find the MLE of $ \\theta $, we maximize the likelihood function with respect to $ \\theta $. Since the log function is monotonic, we work with the **log-likelihood**:\n",
    "\n",
    "$$\n",
    "L(\\theta) = \\log P(d|\\theta) = c \\log \\theta + l \\log (1 - \\theta)\n",
    "$$\n",
    "\n",
    "Take the derivative of $ L(\\theta) $ with respect to $ \\theta $:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L(\\theta)}{\\partial \\theta} = \\frac{c}{\\theta} - \\frac{l}{1 - \\theta}\n",
    "$$\n",
    "\n",
    "Set $ \\frac{\\partial L(\\theta)}{\\partial \\theta} = 0 $ to find the critical point:\n",
    "\n",
    "$$\n",
    "\\frac{c}{\\theta} = \\frac{l}{1 - \\theta}\n",
    "$$\n",
    "\n",
    "Simplify:\n",
    "\n",
    "$$\n",
    "c (1 - \\theta) = l \\theta\n",
    "$$\n",
    "\n",
    "$$\n",
    "c - c \\theta = l \\theta\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\theta = \\frac{c}{c + l}\n",
    "$$\n",
    "\n",
    "Thus, the MLE for $ \\theta $ is:\n",
    "\n",
    "$$\n",
    "\\theta_{\\text{MLE}} = \\frac{c}{c + l}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Calculating the MLE:\n",
    "From the data:\n",
    "- Number of cherry candies ($ c $) = 5\n",
    "- Number of lime candies ($ l $) = 7\n",
    "- Total candies ($ c + l $) = 12\n",
    "\n",
    "Substitute into the formula:\n",
    "\n",
    "$$\n",
    "\\theta_{\\text{MLE}} = \\frac{c}{c + l} = \\frac{5}{12} \\approx 0.417\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. Intuition Behind the MLE:\n",
    "The MLE for $ \\theta $ is simply the observed proportion of cherry candies in the data. This makes sense intuitively because, in the absence of any prior information, the best estimate for $ \\theta $ is the proportion observed in the sample. As the sample size increases, the MLE converges to the true value of $ \\theta $.\n",
    "\n",
    "---\n",
    "\n",
    "### **Exam Tip:**\n",
    "Always show your work step-by-step for derivations, especially when solving for MLEs. Highlighting the intuition behind results can earn additional marks.\n",
    "\n",
    "Let me know if you'd like additional examples or questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4aec256-8223-4077-9e43-1d7acdd887f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
